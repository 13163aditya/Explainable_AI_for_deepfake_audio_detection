{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac3433f2bf5b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import shap\n",
    "\n",
    "# Configuration\n",
    "PROCESSED_DIR = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/processed_audio/\"\n",
    "RESULTS_DIR = \"model_results_large_with_shap\"\n",
    "SR = 22050\n",
    "FEATURE_COUNT = 76  # Number of audio features\n",
    "N_SPLITS = 10  # Number of folds for cross-validation\n",
    "N_REPEATS = 5  # Reduced repeats due to larger model\n",
    "BACKGROUND_SAMPLES = 100  # Number of samples for SHAP background\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# [Previous extract_features() and load_processed_dataset() functions remain the same]\n",
    "\n",
    "def create_large_model():\n",
    "    \"\"\"Create a larger neural network model with regularization\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(FEATURE_COUNT,), kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0005)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def generate_shap_explanations(model, background_data, X_test, feature_names=None):\n",
    "    \"\"\"Generate and save SHAP explanations for model predictions\"\"\"\n",
    "    try:\n",
    "        print(\"\\nGenerating SHAP explanations...\")\n",
    "\n",
    "        # Create explainer\n",
    "        explainer = shap.DeepExplainer(model, background_data)\n",
    "\n",
    "        # Calculate SHAP values\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "        # Plot summary plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values[1], X_test, feature_names=feature_names, show=False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{RESULTS_DIR}/shap_summary.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Save SHAP values\n",
    "        joblib.dump(shap_values, f'{RESULTS_DIR}/shap_values.joblib')\n",
    "        print(\"SHAP analysis completed and saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in SHAP explanation: {str(e)}\")\n",
    "\n",
    "def save_background_data(X_scaled, y, n_samples=BACKGROUND_SAMPLES):\n",
    "    \"\"\"Save representative background data for SHAP analysis\"\"\"\n",
    "    try:\n",
    "        # Create stratified background data\n",
    "        if len(X_scaled) > n_samples * 2:\n",
    "            background, _ = train_test_split(\n",
    "                X_scaled,\n",
    "                train_size=n_samples,\n",
    "                stratify=y,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            # If dataset is small, use all available data\n",
    "            background = X_scaled\n",
    "\n",
    "        joblib.dump(background, f'{RESULTS_DIR}/background_data.joblib')\n",
    "        print(f\"\\nSaved background data ({background.shape[0]} samples)\")\n",
    "\n",
    "        # Generate feature names for SHAP plots\n",
    "        feature_names = [\n",
    "            *[f\"MFCC_mean_{i}\" for i in range(20)],\n",
    "            *[f\"MFCC_std_{i}\" for i in range(20)],\n",
    "            \"Chroma_mean\", \"Chroma_std\",\n",
    "            \"SpectralCentroid_mean\", \"SpectralCentroid_std\",\n",
    "            \"SpectralBandwidth_mean\", \"SpectralBandwidth_std\",\n",
    "            \"SpectralRolloff_mean\", \"SpectralRolloff_std\",\n",
    "            \"ZCR_mean\", \"ZCR_std\",\n",
    "            \"RMS_mean\", \"RMS_std\",\n",
    "            *[f\"SpectralContrast_mean_{i}\" for i in range(6)],\n",
    "            *[f\"SpectralContrast_std_{i}\" for i in range(6)],\n",
    "            *[f\"Tonnetz_mean_{i}\" for i in range(6)],\n",
    "            *[f\"Tonnetz_std_{i}\" for i in range(6)]\n",
    "        ]\n",
    "\n",
    "        joblib.dump(feature_names, f'{RESULTS_DIR}/feature_names.joblib')\n",
    "\n",
    "        return background, feature_names\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving background data: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    X, y = load_processed_dataset()\n",
    "    if len(X) == 0:\n",
    "        print(\"No valid samples found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Save background data and scaler\n",
    "    background_data, feature_names = save_background_data(X_scaled, y)\n",
    "    joblib.dump(scaler, f'{RESULTS_DIR}/scaler.joblib')\n",
    "\n",
    "    # Cross-validation setup\n",
    "    all_accuracies = []\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_X_test = None\n",
    "    best_y_test = None\n",
    "\n",
    "    print(f\"\\nStarting {N_REPEATS}×{N_SPLITS}-fold cross-validation with larger model...\")\n",
    "\n",
    "    for repeat in range(N_REPEATS):\n",
    "        kfold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=repeat)\n",
    "        repeat_accuracies = []\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(kfold.split(X_scaled, y)):\n",
    "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            # Train larger model\n",
    "            model = create_large_model()\n",
    "\n",
    "            callbacks = [\n",
    "                EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss'),\n",
    "                ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)\n",
    "            ]\n",
    "\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=100,\n",
    "                batch_size=64,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=callbacks,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            # Evaluate\n",
    "            _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "            repeat_accuracies.append(accuracy)\n",
    "\n",
    "            # Save metrics\n",
    "            y_pred = model.predict(X_test).argmax(axis=1)\n",
    "            y_probs = model.predict(X_test)\n",
    "            save_evaluation_metrics(y_test, y_pred, y_probs, repeat, fold)\n",
    "\n",
    "            # Track best model and corresponding test data\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = model\n",
    "                best_X_test = X_test\n",
    "                best_y_test = y_test\n",
    "                save_model(model, f'{RESULTS_DIR}/best_model.h5')\n",
    "\n",
    "            print(f\"Repeat {repeat+1}, Fold {fold+1}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "        # Repeat statistics\n",
    "        mean_acc = np.mean(repeat_accuracies)\n",
    "        all_accuracies.extend(repeat_accuracies)\n",
    "        print(f\"Repeat {repeat+1} complete. Mean accuracy: {mean_acc:.4f}\")\n",
    "\n",
    "    # Generate SHAP explanations for best model\n",
    "    if best_model is not None and background_data is not None:\n",
    "        print(\"\\nGenerating SHAP explanations for best model...\")\n",
    "        generate_shap_explanations(best_model, background_data, best_X_test[:100], feature_names)\n",
    "\n",
    "        # Save example predictions with explanations\n",
    "        example_idx = np.random.choice(len(best_X_test), size=min(10, len(best_X_test)), replace=False)\n",
    "        example_data = {\n",
    "            'X': best_X_test[example_idx],\n",
    "            'y_true': best_y_test[example_idx],\n",
    "            'y_pred': best_model.predict(best_X_test[example_idx]).argmax(axis=1),\n",
    "            'feature_names': feature_names\n",
    "        }\n",
    "        joblib.dump(example_data, f'{RESULTS_DIR}/example_predictions.joblib')\n",
    "\n",
    "    # Final results\n",
    "    joblib.dump(all_accuracies, f\"{RESULTS_DIR}/all_accuracies.joblib\")\n",
    "\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} (±{np.std(all_accuracies):.4f})\")\n",
    "    print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "    print(f\"Worst Accuracy: {np.min(all_accuracies):.4f}\")\n",
    "\n",
    "    # Save comprehensive report\n",
    "    with open(f\"{RESULTS_DIR}/final_report.txt\", \"w\") as f:\n",
    "        f.write(f\"5×10-Fold Cross Validation Results\\n\")\n",
    "        f.write(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} (±{np.std(all_accuracies):.4f})\\n\")\n",
    "        f.write(f\"Best Accuracy: {best_accuracy:.4f}\\n\")\n",
    "        f.write(f\"Worst Accuracy: {np.min(all_accuracies):.4f}\\n\")\n",
    "\n",
    "    print(f\"\\nAll results saved in '{RESULTS_DIR}' directory\")\n",
    "\n",
    "if __name__ == \"__main__\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e579fee470bab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T21:08:20.012462Z",
     "start_time": "2025-04-29T21:07:37.956225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 fake samples, using 180 for testing (10.0%)\n",
      "Found 1800 real samples, using 180 for testing (10.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total test samples loaded: 360\n",
      "Class distribution: Real=180, Fake=180\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\n",
      "Test Accuracy: 0.8028\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.77      0.87      0.82       180\n",
      "        Fake       0.85      0.73      0.79       180\n",
      "\n",
      "    accuracy                           0.80       360\n",
      "   macro avg       0.81      0.80      0.80       360\n",
      "weighted avg       0.81      0.80      0.80       360\n",
      "\n",
      "\n",
      "Test results saved in 'test_results' directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "RESULTS_DIR = \"test_results\"\n",
    "SR = 22050  # Sample rate\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "FEATURE_COUNT = 76  # Must match your training setup\n",
    "TEST_SIZE = 0.1  # 10% of data for testing\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"Extract audio features matching your training setup\"\"\"\n",
    "    try:\n",
    "        audio, _ = librosa.load(file_path, sr=SR)\n",
    "        features = []\n",
    "\n",
    "        # 1. MFCCs (40 features: 20 means + 20 std)\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=SR, n_mfcc=20,\n",
    "                                  n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend(np.mean(mfcc, axis=1))\n",
    "        features.extend(np.std(mfcc, axis=1))\n",
    "\n",
    "        # 2. Chroma (2 features)\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=SR,\n",
    "                                          n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend([np.mean(chroma), np.std(chroma)])\n",
    "\n",
    "        # 3. Spectral Features (6 features)\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=SR)\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=SR)\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=SR)\n",
    "        features.extend([\n",
    "            np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "            np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "            np.mean(spectral_rolloff), np.std(spectral_rolloff)\n",
    "        ])\n",
    "\n",
    "        # 4. Zero Crossing Rate (2 features)\n",
    "        zcr = librosa.feature.zero_crossing_rate(audio,\n",
    "                                              frame_length=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend([np.mean(zcr), np.std(zcr)])\n",
    "\n",
    "        # 5. RMS Energy (2 features)\n",
    "        rms = librosa.feature.rms(y=audio,\n",
    "                               frame_length=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend([np.mean(rms), np.std(rms)])\n",
    "\n",
    "        # 6. Spectral Contrast (12 features: 6 means + 6 std)\n",
    "        contrast = librosa.feature.spectral_contrast(y=audio, sr=SR,\n",
    "                                                  n_bands=6,\n",
    "                                                  n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        contrast_mean = np.mean(contrast[:6], axis=1)\n",
    "        contrast_std = np.std(contrast[:6], axis=1)\n",
    "        features.extend(contrast_mean)\n",
    "        features.extend(contrast_std)\n",
    "\n",
    "        # 7. Tonnetz (12 features: 6 means + 6 std)\n",
    "        tonnetz = librosa.feature.tonnetz(y=audio, sr=SR)\n",
    "        features.extend(np.mean(tonnetz, axis=1))\n",
    "        features.extend(np.std(tonnetz, axis=1))\n",
    "\n",
    "        features = np.array(features)\n",
    "        if len(features) != FEATURE_COUNT:\n",
    "            raise ValueError(f\"Expected {FEATURE_COUNT} features, got {len(features)}\")\n",
    "        return features.reshape(1, -1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"Load 10% of data from the directory structure\"\"\"\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    # Process Fake audio files\n",
    "    fake_path = os.path.join(DATA_DIR, \"Fake\")\n",
    "    if os.path.exists(fake_path):\n",
    "        fake_files = [f for f in os.listdir(fake_path) if f.endswith(\".wav\")]\n",
    "        # Ensure at least 1 file is selected\n",
    "        sample_size = max(1, int(len(fake_files) * TEST_SIZE))\n",
    "        fake_files_sample = random.sample(fake_files, sample_size)\n",
    "        print(f\"Found {len(fake_files)} fake samples, using {len(fake_files_sample)} for testing ({TEST_SIZE*100}%)\")\n",
    "\n",
    "        for file in fake_files_sample:\n",
    "            file_path = os.path.join(fake_path, file)\n",
    "            features = extract_features(file_path)\n",
    "            if features is not None:\n",
    "                X_test.append(features[0])\n",
    "                y_test.append(1)  # Label 1 for fake\n",
    "\n",
    "    # Process Real audio files\n",
    "    real_path = os.path.join(DATA_DIR, \"Real\")\n",
    "    if os.path.exists(real_path):\n",
    "        real_files = [f for f in os.listdir(real_path) if f.endswith(\".wav\")]\n",
    "        # Ensure at least 1 file is selected\n",
    "        sample_size = max(1, int(len(real_files) * TEST_SIZE))\n",
    "        real_files_sample = random.sample(real_files, sample_size)\n",
    "        print(f\"Found {len(real_files)} real samples, using {len(real_files_sample)} for testing ({TEST_SIZE*100}%)\")\n",
    "\n",
    "        for file in real_files_sample:\n",
    "            file_path = os.path.join(real_path, file)\n",
    "            features = extract_features(file_path)\n",
    "            if features is not None:\n",
    "                X_test.append(features[0])\n",
    "                y_test.append(0)  # Label 0 for real\n",
    "\n",
    "    print(f\"\\nTotal test samples loaded: {len(X_test)}\")\n",
    "    print(f\"Class distribution: Real={sum(np.array(y_test)==0)}, Fake={sum(np.array(y_test)==1)}\")\n",
    "    return np.array(X_test), np.array(y_test)\n",
    "\n",
    "def evaluate_model(model, scaler, X_test, y_test):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    # Scale test data\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled).argmax(axis=1)\n",
    "    y_probs = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Real', 'Fake'],\n",
    "                yticklabels=['Real', 'Fake'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(f'{RESULTS_DIR}/confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(y_test, y_pred, target_names=['Real', 'Fake'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    with open(f'{RESULTS_DIR}/classification_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "\n",
    "    # Save predictions for analysis\n",
    "    np.save(f'{RESULTS_DIR}/test_predictions.npy', {\n",
    "        'true_labels': y_test,\n",
    "        'pred_labels': y_pred,\n",
    "        'pred_probs': y_probs\n",
    "    })\n",
    "\n",
    "def main():\n",
    "    # Load test data (10% of available data)\n",
    "    X_test, y_test = load_test_data()\n",
    "    if len(X_test) == 0:\n",
    "        print(\"No valid test samples found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Load model and scaler\n",
    "    try:\n",
    "        model = load_model('model_results_large_with_shap/best_model.h5')  # Update path if needed\n",
    "        scaler = joblib.load('model_results_large_with_shap/scaler.joblib')  # Update path if needed\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or scaler: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate_model(model, scaler, X_test, y_test)\n",
    "    print(f\"\\nTest results saved in '{RESULTS_DIR}' directory\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937b82edb43b129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T21:13:10.393592Z",
     "start_time": "2025-04-29T21:12:27.620766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 180/1800 fake samples\n",
      "Using 180/1800 real samples\n",
      "\n",
      "Total test samples: 360 (Real=180, Fake=180)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "Test Accuracy: 0.8278\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.78      0.91      0.84       180\n",
      "        Fake       0.89      0.75      0.81       180\n",
      "\n",
      "    accuracy                           0.83       360\n",
      "   macro avg       0.84      0.83      0.83       360\n",
      "weighted avg       0.84      0.83      0.83       360\n",
      "\n",
      "\n",
      "All results saved to test_results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                            roc_curve, auc, precision_recall_curve, average_precision_score)\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "RESULTS_DIR = \"test_results\"\n",
    "SR = 22050\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "FEATURE_COUNT = 76\n",
    "TEST_SIZE = 0.1  # 10% of data for testing\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"Extract audio features matching training setup\"\"\"\n",
    "    try:\n",
    "        audio, _ = librosa.load(file_path, sr=SR)\n",
    "        features = []\n",
    "\n",
    "        # MFCCs\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=SR, n_mfcc=20,\n",
    "                                  n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend(np.mean(mfcc, axis=1))\n",
    "        features.extend(np.std(mfcc, axis=1))\n",
    "\n",
    "        # Chroma\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=SR,\n",
    "                                          n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend([np.mean(chroma), np.std(chroma)])\n",
    "\n",
    "        # Spectral Features\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=SR)\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=SR)\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=SR)\n",
    "        features.extend([\n",
    "            np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "            np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "            np.mean(spectral_rolloff), np.std(spectral_rolloff)\n",
    "        ])\n",
    "\n",
    "        # Zero Crossing Rate\n",
    "        zcr = librosa.feature.zero_crossing_rate(audio,\n",
    "                                              frame_length=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend([np.mean(zcr), np.std(zcr)])\n",
    "\n",
    "        # RMS Energy\n",
    "        rms = librosa.feature.rms(y=audio,\n",
    "                               frame_length=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend([np.mean(rms), np.std(rms)])\n",
    "\n",
    "        # Spectral Contrast\n",
    "        contrast = librosa.feature.spectral_contrast(y=audio, sr=SR,\n",
    "                                                  n_bands=6,\n",
    "                                                  n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        contrast_mean = np.mean(contrast[:6], axis=1)\n",
    "        contrast_std = np.std(contrast[:6], axis=1)\n",
    "        features.extend(contrast_mean)\n",
    "        features.extend(contrast_std)\n",
    "\n",
    "        # Tonnetz\n",
    "        tonnetz = librosa.feature.tonnetz(y=audio, sr=SR)\n",
    "        features.extend(np.mean(tonnetz, axis=1))\n",
    "        features.extend(np.std(tonnetz, axis=1))\n",
    "\n",
    "        features = np.array(features)\n",
    "        if len(features) != FEATURE_COUNT:\n",
    "            raise ValueError(f\"Expected {FEATURE_COUNT} features, got {len(features)}\")\n",
    "        return features.reshape(1, -1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"Load 10% of data with stratified sampling\"\"\"\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    # Process Fake audio files\n",
    "    fake_path = os.path.join(DATA_DIR, \"Fake\")\n",
    "    if os.path.exists(fake_path):\n",
    "        fake_files = [f for f in os.listdir(fake_path) if f.endswith(\".wav\")]\n",
    "        sample_size = max(1, int(len(fake_files) * TEST_SIZE))\n",
    "        fake_files_sample = random.sample(fake_files, sample_size)\n",
    "        print(f\"Using {len(fake_files_sample)}/{len(fake_files)} fake samples\")\n",
    "\n",
    "        for file in fake_files_sample:\n",
    "            features = extract_features(os.path.join(fake_path, file))\n",
    "            if features is not None:\n",
    "                X_test.append(features[0])\n",
    "                y_test.append(1)\n",
    "\n",
    "    # Process Real audio files\n",
    "    real_path = os.path.join(DATA_DIR, \"Real\")\n",
    "    if os.path.exists(real_path):\n",
    "        real_files = [f for f in os.listdir(real_path) if f.endswith(\".wav\")]\n",
    "        sample_size = max(1, int(len(real_files) * TEST_SIZE))\n",
    "        real_files_sample = random.sample(real_files, sample_size)\n",
    "        print(f\"Using {len(real_files_sample)}/{len(real_files)} real samples\")\n",
    "\n",
    "        for file in real_files_sample:\n",
    "            features = extract_features(os.path.join(real_path, file))\n",
    "            if features is not None:\n",
    "                X_test.append(features[0])\n",
    "                y_test.append(0)\n",
    "\n",
    "    print(f\"\\nTotal test samples: {len(X_test)} (Real={y_test.count(0)}, Fake={y_test.count(1)})\")\n",
    "    return np.array(X_test), np.array(y_test)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Generate and save enhanced confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Real', 'Fake'],\n",
    "                yticklabels=['Real', 'Fake'],\n",
    "                annot_kws={\"size\": 16})\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.savefig(f'{RESULTS_DIR}/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_curve(y_true, y_scores):\n",
    "    \"\"\"Generate and save ROC curve\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('Receiver Operating Characteristic', fontsize=14)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'{RESULTS_DIR}/roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_precision_recall(y_true, y_scores):\n",
    "    \"\"\"Generate and save Precision-Recall curve\"\"\"\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores[:, 1])\n",
    "    avg_precision = average_precision_score(y_true, y_scores[:, 1])\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(recall, precision, color='blue', lw=2,\n",
    "             label=f'Precision-Recall (AP = {avg_precision:.2f})')\n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title('Precision-Recall Curve', fontsize=14)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(f'{RESULTS_DIR}/precision_recall.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_model(model, scaler, X_test, y_test):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    # Scale and predict\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_pred = model.predict(X_test_scaled).argmax(axis=1)\n",
    "    y_scores = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(y_test, y_pred, target_names=['Real', 'Fake'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    with open(f'{RESULTS_DIR}/classification_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "\n",
    "    # Generate plots\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "    plot_roc_curve(y_test, y_scores)\n",
    "    plot_precision_recall(y_test, y_scores)\n",
    "\n",
    "    # Save raw predictions\n",
    "    np.savez(f'{RESULTS_DIR}/predictions.npz',\n",
    "             y_true=y_test,\n",
    "             y_pred=y_pred,\n",
    "             y_scores=y_scores)\n",
    "\n",
    "def main():\n",
    "    # Load data and model\n",
    "    X_test, y_test = load_test_data()\n",
    "    if len(X_test) == 0:\n",
    "        print(\"No test samples found!\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        model = load_model('model_results_large_with_shap/best_model.h5')\n",
    "        scaler = joblib.load('model_results_large_with_shap/scaler.joblib')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate_model(model, scaler, X_test, y_test)\n",
    "    print(f\"\\nAll results saved to {RESULTS_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c210864238a3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f835cdd4af5143b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718ae1ae263028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Configuration\n",
    "PROCESSED_DIR = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/processed_audio/\"\n",
    "SR = 22050\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "FEATURE_COUNT = 76\n",
    "RESULTS_DIR = \"processed_audio_test_results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"Feature extraction that matches your training setup\"\"\"\n",
    "    try:\n",
    "        audio, _ = librosa.load(file_path, sr=SR)\n",
    "        features = []\n",
    "\n",
    "        # 1. MFCCs (40 features: 20 means + 20 std)\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=SR, n_mfcc=20,\n",
    "                                  n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend(np.mean(mfcc, axis=1))\n",
    "        features.extend(np.std(mfcc, axis=1))\n",
    "\n",
    "        # 2. Chroma (2 features)\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=SR,\n",
    "                                          n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend([np.mean(chroma), np.std(chroma)])\n",
    "\n",
    "        # 3. Spectral Features (6 features)\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=SR)\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=SR)\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=SR)\n",
    "        features.extend([\n",
    "            np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "            np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "            np.mean(spectral_rolloff), np.std(spectral_rolloff)\n",
    "        ])\n",
    "\n",
    "        # 4. Zero Crossing Rate (2 features)\n",
    "        zcr = librosa.feature.zero_crossing_rate(audio,\n",
    "                                              frame_length=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend([np.mean(zcr), np.std(zcr)])\n",
    "\n",
    "        # 5. RMS Energy (2 features)\n",
    "        rms = librosa.feature.rms(y=audio,\n",
    "                               frame_length=N_FFT, hop_length=HOP_LENGTH)\n",
    "        features.extend([np.mean(rms), np.std(rms)])\n",
    "\n",
    "        # 6. Spectral Contrast (12 features: 6 means + 6 std)\n",
    "        contrast = librosa.feature.spectral_contrast(y=audio, sr=SR,\n",
    "                                                  n_bands=6,\n",
    "                                                  n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        contrast_mean = np.mean(contrast[:6], axis=1)\n",
    "        contrast_std = np.std(contrast[:6], axis=1)\n",
    "        features.extend(contrast_mean)\n",
    "        features.extend(contrast_std)\n",
    "\n",
    "        # 7. Tonnetz (12 features: 6 means + 6 std)\n",
    "        tonnetz = librosa.feature.tonnetz(y=audio, sr=SR)\n",
    "        features.extend(np.mean(tonnetz, axis=1))\n",
    "        features.extend(np.std(tonnetz, axis=1))\n",
    "\n",
    "        features = np.array(features)\n",
    "        if len(features) != FEATURE_COUNT:\n",
    "            raise ValueError(f\"Expected {FEATURE_COUNT} features, got {len(features)}\")\n",
    "        return features.reshape(1, -1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"Load data from processed_audio folder\"\"\"\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    # Process Fake audio files\n",
    "    fake_path = os.path.join(PROCESSED_DIR, \"Fake\")\n",
    "    if os.path.exists(fake_path):\n",
    "        fake_files = [f for f in os.listdir(fake_path) if f.endswith(\".wav\")]\n",
    "        print(f\"Found {len(fake_files)} fake test samples\")\n",
    "\n",
    "        for file in fake_files:\n",
    "            file_path = os.path.join(fake_path, file)\n",
    "            features = extract_features(file_path)\n",
    "            if features is not None:\n",
    "                X_test.append(features[0])\n",
    "                y_test.append(1)  # Label 1 for fake\n",
    "\n",
    "    # Process Real audio files\n",
    "    real_path = os.path.join(PROCESSED_DIR, \"Real\")\n",
    "    if os.path.exists(real_path):\n",
    "        real_files = [f for f in os.listdir(real_path) if f.endswith(\".wav\")]\n",
    "        print(f\"Found {len(real_files)} real test samples\")\n",
    "\n",
    "        for file in real_files:\n",
    "            file_path = os.path.join(real_path, file)\n",
    "            features = extract_features(file_path)\n",
    "            if features is not None:\n",
    "                X_test.append(features[0])\n",
    "                y_test.append(0)  # Label 0 for real\n",
    "\n",
    "    print(f\"\\nTotal test samples loaded: {len(X_test)}\")\n",
    "    print(f\"Class distribution: Real={sum(np.array(y_test)==0)}, Fake={sum(np.array(y_test)==1)}\")\n",
    "    return np.array(X_test), np.array(y_test)\n",
    "\n",
    "def evaluate_model(model, scaler, X_test, y_test):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    # Scale test data\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled).argmax(axis=1)\n",
    "    y_probs = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Real', 'Fake'],\n",
    "                yticklabels=['Real', 'Fake'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(f'{RESULTS_DIR}/confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(y_test, y_pred, target_names=['Real', 'Fake'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    with open(f'{RESULTS_DIR}/classification_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "\n",
    "def main():\n",
    "    # Load test data\n",
    "    X_test, y_test = load_test_data()\n",
    "    if len(X_test) == 0:\n",
    "        print(\"No valid test samples found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Load model and scaler\n",
    "    try:\n",
    "        model = load_model('audio_model_nn_32.h5')\n",
    "        scaler = joblib.load('scaler_nn_32.joblib')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or scaler: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate_model(model, scaler, X_test, y_test)\n",
    "    print(f\"\\nTest results saved in '{RESULTS_DIR}' directory\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
