{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30403f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\losses.py:2664: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\anaconda3\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "c:\\Users\\adity\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "c:\\Users\\adity\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m lime_image\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtf_explain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgrad_cam\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradCAM\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtf_explain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mintegrated_gradients\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IntegratedGradients\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01malibi\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexplainers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CounterfactualProto\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tf_explain\\__init__.py:23\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m     20\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTF-explain requires TensorFlow 2.0 or higher. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     21\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInstall TensorFlow via `pip install tensorflow`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     22\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m core\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m callbacks\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tf_explain\\core\\__init__.py:8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExtractActivations\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgrad_cam\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradCAM\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgradients_inputs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradientsInputs\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvanilla_gradients\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VanillaGradients\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mintegrated_gradients\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IntegratedGradients\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tf_explain\\core\\gradients_inputs.py:6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mCore Module for Gradients*Inputs\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtf_explain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvanilla_gradients\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VanillaGradients\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mGradientsInputs\u001B[39;00m(VanillaGradients):\n\u001B[0;32m     11\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03m    Perform Gradients*Inputs algorithm (gradients ponderated by the input values).\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tf_explain\\core\\vanilla_gradients.py:19\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtf_explain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaver\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m save_grayscale\n\u001B[0;32m     12\u001B[0m UNSUPPORTED_ARCHITECTURE_WARNING \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsupported model architecture for VanillaGradients. The last two layers of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe model should be: a layer which computes class scores with no activation, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfollowed by an activation layer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     16\u001B[0m )\n\u001B[0;32m     18\u001B[0m ACTIVATION_LAYER_CLASSES \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m---> 19\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mActivation,\n\u001B[0;32m     20\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mLeakyReLU,\n\u001B[0;32m     21\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mPReLU,\n\u001B[0;32m     22\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mReLU,\n\u001B[0;32m     23\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mSoftmax,\n\u001B[0;32m     24\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mThresholdedReLU,\n\u001B[0;32m     25\u001B[0m )\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mVanillaGradients\u001B[39;00m:\n\u001B[0;32m     30\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;124;03m    Perform gradients backpropagation for a given input\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03m    Paper: [Deep Inside Convolutional Networks: Visualising Image Classification\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;124;03m        Models and Saliency Maps](https://arxiv.org/abs/1312.6034)\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:181\u001B[0m, in \u001B[0;36mKerasLazyLoader.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    179\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m(types\u001B[38;5;241m.\u001B[39mModuleType, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(item)\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_initialized:\n\u001B[1;32m--> 181\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize()\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_keras_version \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_3\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    183\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    184\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    185\u001B[0m       \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_submodule\n\u001B[0;32m    186\u001B[0m       \u001B[38;5;129;01mand\u001B[39;00m item\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompat.v1.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    187\u001B[0m   ):\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:147\u001B[0m, in \u001B[0;36mKerasLazyLoader._initialize\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    146\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 147\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top\u001B[39;00m\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m keras\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3.\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    150\u001B[0m       \u001B[38;5;66;03m# This is the Keras 3.x case.\u001B[39;00m\n\u001B[0;32m    151\u001B[0m       keras_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_3\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\__init__.py:21\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minput_layer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Input\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\models\\__init__.py:18\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Functional\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\engine\\functional.py:34\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m input_spec\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m node \u001B[38;5;28;01mas\u001B[39;00m node_module\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m training \u001B[38;5;28;01mas\u001B[39;00m training_lib\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m training_utils\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialization\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:40\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optimizer_v1\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pickle_utils\n\u001B[1;32m---> 40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m saving_api\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m saving_lib\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialization_lib\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\saving\\saving_api.py:24\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtf_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m saving_lib\n\u001B[1;32m---> 24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m save \u001B[38;5;28;01mas\u001B[39;00m legacy_sm_saving_lib\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m io_utils\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\saving\\legacy\\save.py:27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialization\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaved_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load \u001B[38;5;28;01mas\u001B[39;00m saved_model_load\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaved_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_context\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaved_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m save \u001B[38;5;28;01mas\u001B[39;00m saved_model_save\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaved_model\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_option_scope\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\saving\\legacy\\saved_model\\load_context.py:68\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns whether under a load context.\"\"\"\u001B[39;00m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_context\u001B[38;5;241m.\u001B[39min_load_context()\n\u001B[1;32m---> 68\u001B[0m tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mregister_load_context_function(in_load_context)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'"
     ]
    }
   ],
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from glob import glob\n",
    "\n",
    "# Input/Output paths\n",
    "input_root = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Dataset/\"\n",
    "output_root = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "\n",
    "# Target duration (3 seconds)\n",
    "TARGET_DURATION = 3.0\n",
    "\n",
    "def process_audio(file_path, output_path):\n",
    "    # Load audio\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)  # Preserve native sample rate\n",
    "\n",
    "        # Current duration\n",
    "        current_duration = len(y) / sr\n",
    "\n",
    "        # Case 1: Audio is longer than 3s → trim middle 3s\n",
    "        if current_duration > TARGET_DURATION:\n",
    "            start = int((len(y) - TARGET_DURATION * sr) // 2)\n",
    "            y_processed = y[start : start + int(TARGET_DURATION * sr)]\n",
    "\n",
    "        # Case 2: Audio is shorter than 3s → pad with silence\n",
    "        else:\n",
    "            silence_needed = int((TARGET_DURATION - current_duration) * sr)\n",
    "            pad_left = silence_needed // 2\n",
    "            pad_right = silence_needed - pad_left\n",
    "            y_processed = np.concatenate([\n",
    "                np.zeros(pad_left),\n",
    "                y,\n",
    "                np.zeros(pad_right)\n",
    "            ])\n",
    "\n",
    "        # Save processed file\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        sf.write(output_path, y_processed, sr)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Initialize counters\n",
    "real_count = 0\n",
    "fake_count = 0\n",
    "\n",
    "# Process all speaker directories\n",
    "for speaker_dir in glob(os.path.join(input_root, \"S*\")):\n",
    "    # Process Real files\n",
    "    real_files = glob(os.path.join(speaker_dir, \"Real\", \"*.wav\"))\n",
    "    for file in real_files:\n",
    "        output_filename = f\"real_{real_count + 1}.wav\"\n",
    "        output_path = os.path.join(output_root, \"Real\", output_filename)\n",
    "        if process_audio(file, output_path):\n",
    "            real_count += 1\n",
    "\n",
    "    # Process Fake files\n",
    "    fake_files = glob(os.path.join(speaker_dir, \"Fake\", \"*.wav\"))\n",
    "    for file in fake_files:\n",
    "        output_filename = f\"fake_{fake_count + 1}.wav\"\n",
    "        output_path = os.path.join(output_root, \"Fake\", output_filename)\n",
    "        if process_audio(file, output_path):\n",
    "            fake_count += 1\n",
    "\n",
    "print(f\"Processing complete! Saved {real_count} real files and {fake_count} fake files to: {output_root}\")"
   ],
   "id": "755c3bdfcd6f01be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T05:13:38.344754Z",
     "start_time": "2025-04-22T04:46:54.215473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from lime import lime_image\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. Feature Extraction (Mel-spectrogram)\n",
    "def extract_mel_spectrogram(file_path, n_mels=128, target_length=128):\n",
    "    \"\"\"Extract normalized mel-spectrogram with fixed size\"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=22050)  # Resample to 22.05kHz\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "    # Pad/Cut to fixed size\n",
    "    if mel_spec_db.shape[1] < target_length:\n",
    "        pad_width = target_length - mel_spec_db.shape[1]\n",
    "        mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mel_spec_db = mel_spec_db[:, :target_length]\n",
    "\n",
    "    # Normalize to [0,1]\n",
    "    mel_spec_db = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min())\n",
    "    return mel_spec_db\n",
    "\n",
    "# 2. Load and preprocess data\n",
    "def load_dataset(data_path):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for label in ['Real', 'Fake']:\n",
    "        class_path = os.path.join(data_path, label)\n",
    "        for file in os.listdir(class_path):\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(class_path, file)\n",
    "                features = extract_mel_spectrogram(file_path)\n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Add channel dimension for CNN\n",
    "    X = X[..., np.newaxis]\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)  # Real=1, Fake=0\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# 3. CNN Model Architecture\n",
    "def create_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 4. Training with Callbacks\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=50):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1),\n",
    "        ModelCheckpoint('best_model1.h5', monitor='val_accuracy', save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history\n",
    "\n",
    "# 5. LIME Explanation Wrapper\n",
    "class AudioExplainer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict_proba(self, images):\n",
    "        # Convert LIME's RGB images back to grayscale\n",
    "        if images.ndim == 4 and images.shape[3] == 3:\n",
    "            images = images[..., 0]\n",
    "\n",
    "        # Add channel dimension if needed\n",
    "        if images.ndim == 3:\n",
    "            images = images[..., np.newaxis]\n",
    "\n",
    "        return self.model.predict(images)\n",
    "\n",
    "# 6. Visualization Functions\n",
    "def plot_spectrogram(spectrogram, title=\"\"):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(spectrogram.squeeze(), aspect='auto', cmap='magma', origin='lower')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.xlabel('Time Frames')\n",
    "    plt.ylabel('Mel Bands')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "    X, y = load_dataset(data_path)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = create_model(input_shape)\n",
    "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=50)\n",
    "\n",
    "    # Evaluate best model\n",
    "    model = models.load_model('best_model1.h5')\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Plot training history\n",
    "    plot_history(history)\n",
    "\n",
    "    # LIME Explanations\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    model_wrapper = AudioExplainer(model)\n",
    "\n",
    "    # Explain 3 random samples\n",
    "    for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "        # Get sample and prediction\n",
    "        sample = X_test[i]\n",
    "        pred = model.predict(sample[np.newaxis, ...])[0][0]\n",
    "        pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "        true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"  True: {true_class}\")\n",
    "        print(f\"  Predicted: {pred_class} ({pred:.4f})\")\n",
    "\n",
    "        # Show original spectrogram\n",
    "        plot_spectrogram(sample, f\"Original Spectrogram\\nTrue: {true_class}, Predicted: {pred_class}\")\n",
    "\n",
    "        # Generate explanation\n",
    "        explanation = explainer.explain_instance(\n",
    "            sample.squeeze(),\n",
    "            model_wrapper.predict_proba,\n",
    "            top_labels=1,\n",
    "            hide_color=0,\n",
    "            num_samples=1000,\n",
    "            batch_size=32\n",
    "        )\n",
    "\n",
    "        # Visualize explanation\n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            explanation.top_labels[0],\n",
    "            positive_only=True,\n",
    "            num_features=5,\n",
    "            hide_rest=False\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.imshow(mask, cmap='coolwarm', origin='lower')\n",
    "        plt.title('LIME Explanation\\nRed: Supports prediction, Blue: Contradicts')\n",
    "        plt.colorbar()\n",
    "        plt.xlabel('Time Frames')\n",
    "        plt.ylabel('Mel Bands')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "id": "a920d8d1333ded4d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580ms/step - accuracy: 0.9030 - loss: 0.2555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m80s\u001B[0m 621ms/step - accuracy: 0.9034 - loss: 0.2547 - val_accuracy: 0.4956 - val_loss: 2.8194 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m71s\u001B[0m 629ms/step - accuracy: 0.9877 - loss: 0.0481 - val_accuracy: 0.4956 - val_loss: 3.6016 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m79s\u001B[0m 601ms/step - accuracy: 0.9925 - loss: 0.0257 - val_accuracy: 0.4956 - val_loss: 2.3731 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582ms/step - accuracy: 0.9930 - loss: 0.0206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m91s\u001B[0m 678ms/step - accuracy: 0.9930 - loss: 0.0205 - val_accuracy: 0.7078 - val_loss: 0.7566 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 836ms/step - accuracy: 0.9975 - loss: 0.0079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m106s\u001B[0m 887ms/step - accuracy: 0.9975 - loss: 0.0079 - val_accuracy: 0.9878 - val_loss: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 852ms/step - accuracy: 0.9997 - loss: 0.0027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m144s\u001B[0m 904ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9900 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 785ms/step - accuracy: 0.9973 - loss: 0.0102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m95s\u001B[0m 835ms/step - accuracy: 0.9973 - loss: 0.0101 - val_accuracy: 0.9933 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 448ms/step - accuracy: 1.0000 - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m101s\u001B[0m 466ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0010 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 398ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9956 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m50s\u001B[0m 439ms/step - accuracy: 0.9990 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 6.0096e-04 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 419ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9989 - val_loss: 0.0017 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m53s\u001B[0m 473ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9500 - val_loss: 0.1597 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m52s\u001B[0m 459ms/step - accuracy: 1.0000 - loss: 9.3239e-04 - val_accuracy: 1.0000 - val_loss: 4.4664e-05 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m59s\u001B[0m 520ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9644 - val_loss: 0.1111 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m67s\u001B[0m 591ms/step - accuracy: 1.0000 - loss: 4.1690e-04 - val_accuracy: 0.9989 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 456ms/step - accuracy: 0.9989 - loss: 0.0033\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m54s\u001B[0m 481ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 6.2330e-05 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m52s\u001B[0m 457ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 8.3587e-05 - learning_rate: 2.0000e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m53s\u001B[0m 468ms/step - accuracy: 1.0000 - loss: 3.8211e-04 - val_accuracy: 1.0000 - val_loss: 2.6139e-05 - learning_rate: 2.0000e-04\n",
      "Epoch 19/50\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 434ms/step - accuracy: 0.9985 - loss: 0.0016\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m51s\u001B[0m 456ms/step - accuracy: 0.9985 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 1.5024e-05 - learning_rate: 2.0000e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m 69/113\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m20s\u001B[0m 462ms/step - accuracy: 1.0000 - loss: 1.9480e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 156\u001B[39m\n\u001B[32m    154\u001B[39m input_shape = X_train.shape[\u001B[32m1\u001B[39m:]\n\u001B[32m    155\u001B[39m model = create_model(input_shape)\n\u001B[32m--> \u001B[39m\u001B[32m156\u001B[39m history = \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    158\u001B[39m \u001B[38;5;66;03m# Evaluate best model\u001B[39;00m\n\u001B[32m    159\u001B[39m model = models.load_model(\u001B[33m'\u001B[39m\u001B[33mbest_model1.h5\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 87\u001B[39m, in \u001B[36mtrain_model\u001B[39m\u001B[34m(model, X_train, y_train, X_val, y_val, epochs)\u001B[39m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtrain_model\u001B[39m(model, X_train, y_train, X_val, y_val, epochs=\u001B[32m50\u001B[39m):\n\u001B[32m     81\u001B[39m     callbacks = [\n\u001B[32m     82\u001B[39m         EarlyStopping(monitor=\u001B[33m'\u001B[39m\u001B[33mval_loss\u001B[39m\u001B[33m'\u001B[39m, patience=\u001B[32m5\u001B[39m, verbose=\u001B[32m1\u001B[39m, restore_best_weights=\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m     83\u001B[39m         ReduceLROnPlateau(monitor=\u001B[33m'\u001B[39m\u001B[33mval_loss\u001B[39m\u001B[33m'\u001B[39m, factor=\u001B[32m0.2\u001B[39m, patience=\u001B[32m3\u001B[39m, min_lr=\u001B[32m1e-6\u001B[39m, verbose=\u001B[32m1\u001B[39m),\n\u001B[32m     84\u001B[39m         ModelCheckpoint(\u001B[33m'\u001B[39m\u001B[33mbest_model.h5\u001B[39m\u001B[33m'\u001B[39m, monitor=\u001B[33m'\u001B[39m\u001B[33mval_accuracy\u001B[39m\u001B[33m'\u001B[39m, save_best_only=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     85\u001B[39m     ]\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m     history = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     88\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[43m        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     90\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     91\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     93\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\n\u001B[32m     94\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m history\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001B[39m, in \u001B[36mTensorFlowTrainer.fit\u001B[39m\u001B[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[39m\n\u001B[32m    369\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[32m    370\u001B[39m     callbacks.on_train_batch_begin(step)\n\u001B[32m--> \u001B[39m\u001B[32m371\u001B[39m     logs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    372\u001B[39m     callbacks.on_train_batch_end(step, logs)\n\u001B[32m    373\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stop_training:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001B[39m, in \u001B[36mTensorFlowTrainer._make_function.<locals>.function\u001B[39m\u001B[34m(iterator)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfunction\u001B[39m(iterator):\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[32m    217\u001B[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001B[32m    218\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m219\u001B[39m         opt_outputs = \u001B[43mmulti_step_on_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    220\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs.has_value():\n\u001B[32m    221\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    875\u001B[39m \u001B[38;5;28mself\u001B[39m._lock.release()\n\u001B[32m    876\u001B[39m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[32m    877\u001B[39m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m878\u001B[39m results = \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[32m    880\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    881\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._created_variables:\n\u001B[32m    882\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mCreating variables on a non-first call to a function\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    883\u001B[39m                    \u001B[33m\"\u001B[39m\u001B[33m decorated with tf.function.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[39m, in \u001B[36mcall_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    137\u001B[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001B[32m    138\u001B[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[39m, in \u001B[36mConcreteFunction._call_flat\u001B[39m\u001B[34m(self, tensor_inputs, captured_inputs)\u001B[39m\n\u001B[32m   1318\u001B[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001B[32m   1319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001B[32m   1320\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[32m   1321\u001B[39m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_inference_function\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1323\u001B[39m forward_backward = \u001B[38;5;28mself\u001B[39m._select_forward_and_backward_functions(\n\u001B[32m   1324\u001B[39m     args,\n\u001B[32m   1325\u001B[39m     possible_gradient_type,\n\u001B[32m   1326\u001B[39m     executing_eagerly)\n\u001B[32m   1327\u001B[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[39m, in \u001B[36mAtomicFunction.call_preflattened\u001B[39m\u001B[34m(self, args)\u001B[39m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core.Tensor]) -> Any:\n\u001B[32m    215\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m   flat_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.function_type.pack_output(flat_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[39m, in \u001B[36mAtomicFunction.call_flat\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m record.stop_recording():\n\u001B[32m    250\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._bound_context.executing_eagerly():\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_bound_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    256\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    257\u001B[39m     outputs = make_call_op_in_graph(\n\u001B[32m    258\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    259\u001B[39m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[32m    260\u001B[39m         \u001B[38;5;28mself\u001B[39m._bound_context.function_call_options.as_attrs(),\n\u001B[32m    261\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001B[39m, in \u001B[36mContext.call_function\u001B[39m\u001B[34m(self, name, tensor_inputs, num_outputs)\u001B[39m\n\u001B[32m   1686\u001B[39m cancellation_context = cancellation.context()\n\u001B[32m   1687\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1688\u001B[39m   outputs = \u001B[43mexecute\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1689\u001B[39m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1690\u001B[39m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1691\u001B[39m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1692\u001B[39m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1693\u001B[39m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1694\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1695\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1696\u001B[39m   outputs = execute.execute_with_cancellation(\n\u001B[32m   1697\u001B[39m       name.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   1698\u001B[39m       num_outputs=num_outputs,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1702\u001B[39m       cancellation_manager=cancellation_context,\n\u001B[32m   1703\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[39m, in \u001B[36mquick_execute\u001B[39m\u001B[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     52\u001B[39m   ctx.ensure_initialized()\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m   tensors = \u001B[43mpywrap_tfe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     56\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a3cf68aafc365b31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19236d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded in comparison",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRecursionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 87\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# ---------------------------\u001B[39;00m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;66;03m# Main Run\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# ---------------------------\u001B[39;00m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;66;03m# Load pre-trained model\u001B[39;00m\n\u001B[1;32m---> 87\u001B[0m     model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mapplications\u001B[38;5;241m.\u001B[39mVGG16(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     88\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrainable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;66;03m# Load and preprocess image\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:182\u001B[0m, in \u001B[0;36mKerasLazyLoader.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_initialized:\n\u001B[0;32m    181\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize()\n\u001B[1;32m--> 182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_keras_version \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_3\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    183\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    184\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    185\u001B[0m       \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_submodule\n\u001B[0;32m    186\u001B[0m       \u001B[38;5;129;01mand\u001B[39;00m item\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompat.v1.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    187\u001B[0m   ):\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    189\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.compat.v1.keras` is not available with Keras 3. Keras 3 has \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    190\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno support for TF 1 APIs. You can install the `tf_keras` package \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    193\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.compat.v1.keras` to `tf_keras`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    194\u001B[0m     )\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:182\u001B[0m, in \u001B[0;36mKerasLazyLoader.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_initialized:\n\u001B[0;32m    181\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize()\n\u001B[1;32m--> 182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_keras_version \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_3\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    183\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    184\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    185\u001B[0m       \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_submodule\n\u001B[0;32m    186\u001B[0m       \u001B[38;5;129;01mand\u001B[39;00m item\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompat.v1.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    187\u001B[0m   ):\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    189\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.compat.v1.keras` is not available with Keras 3. Keras 3 has \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    190\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno support for TF 1 APIs. You can install the `tf_keras` package \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    193\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.compat.v1.keras` to `tf_keras`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    194\u001B[0m     )\n",
      "    \u001B[1;31m[... skipping similar frames: KerasLazyLoader.__getattr__ at line 182 (1488 times)]\u001B[0m\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:182\u001B[0m, in \u001B[0;36mKerasLazyLoader.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_initialized:\n\u001B[0;32m    181\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize()\n\u001B[1;32m--> 182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_keras_version \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras_3\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    183\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    184\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    185\u001B[0m       \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_submodule\n\u001B[0;32m    186\u001B[0m       \u001B[38;5;129;01mand\u001B[39;00m item\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompat.v1.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    187\u001B[0m   ):\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    189\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.compat.v1.keras` is not available with Keras 3. Keras 3 has \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    190\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno support for TF 1 APIs. You can install the `tf_keras` package \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    193\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.compat.v1.keras` to `tf_keras`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    194\u001B[0m     )\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:178\u001B[0m, in \u001B[0;36mKerasLazyLoader.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, item):\n\u001B[1;32m--> 178\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_tfll_mode\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_tfll_initialized\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_tfll_name\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m(types\u001B[38;5;241m.\u001B[39mModuleType, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(item)\n\u001B[0;32m    180\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfll_initialized:\n",
      "\u001B[1;31mRecursionError\u001B[0m: maximum recursion depth exceeded in comparison"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# ---------------------------\n",
    "# Preprocessing\n",
    "# ---------------------------\n",
    "def preprocess_image(img_path, target_size=(224, 224)):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.vgg16.preprocess_input(img_array)\n",
    "\n",
    "# ---------------------------\n",
    "# Grad-CAM\n",
    "# ---------------------------\n",
    "def compute_gradcam(model, image, last_conv_layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], \n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(image)\n",
    "        class_idx = tf.argmax(predictions[0])\n",
    "        class_output = predictions[:, class_idx]\n",
    "\n",
    "    grads = tape.gradient(class_output, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def display_gradcam(image, heatmap, alpha=0.4):\n",
    "    img = image[0]\n",
    "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap_color * alpha + img\n",
    "    plt.imshow(np.uint8(superimposed_img))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Grad-CAM\")\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# Integrated Gradients\n",
    "# ---------------------------\n",
    "def interpolate_images(baseline, image, steps=50):\n",
    "    alphas = tf.linspace(0.0, 1.0, steps+1)\n",
    "    alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "    delta = image - baseline\n",
    "    return baseline + alphas_x * delta\n",
    "\n",
    "def compute_integrated_gradients(model, image, baseline=None, steps=50):\n",
    "    if baseline is None:\n",
    "        baseline = tf.zeros_like(image)\n",
    "    interpolated_images = interpolate_images(baseline, image, steps)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_images)\n",
    "        preds = model(interpolated_images)\n",
    "        pred_index = tf.argmax(preds[-1])\n",
    "        target = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(target, interpolated_images)\n",
    "    avg_grads = tf.reduce_mean(grads, axis=0)\n",
    "    integrated_grads = (image - baseline) * avg_grads\n",
    "    return integrated_grads\n",
    "\n",
    "def display_integrated_gradients(integrated_grads):\n",
    "    attributions = tf.reduce_sum(tf.math.abs(integrated_grads), axis=-1)[0]\n",
    "    attributions = attributions.numpy()\n",
    "    attributions = (attributions - attributions.min()) / (attributions.max() - attributions.min())\n",
    "    plt.imshow(attributions, cmap='hot')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Integrated Gradients\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# Main Run\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load pre-trained model\n",
    "    model = tf.keras.applications.VGG16(weights=\"imagenet\")\n",
    "    model.trainable = False\n",
    "\n",
    "    # Load and preprocess image\n",
    "    img_path = tf.keras.utils.get_file(\"elephant.jpg\", \"https://i.imgur.com/Bvro0YD.png\")\n",
    "    image = preprocess_image(img_path)\n",
    "    \n",
    "    # Grad-CAM\n",
    "    heatmap = compute_gradcam(model, image, last_conv_layer_name=\"block5_conv3\")\n",
    "    display_gradcam(image, heatmap)\n",
    "\n",
    "    # Integrated Gradients\n",
    "    igrads = compute_integrated_gradients(model, tf.cast(image, tf.float32))\n",
    "    display_integrated_gradients(igrads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d85159",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_model\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py:12\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \n\u001B[0;32m      8\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_v2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __internal__\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_v2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\__init__.py:21\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minput_layer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Input\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\models\\__init__.py:18\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Functional\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\engine\\functional.py:34\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m input_spec\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m node \u001B[38;5;28;01mas\u001B[39;00m node_module\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m training \u001B[38;5;28;01mas\u001B[39;00m training_lib\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m training_utils\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialization\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:45\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialization\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaved_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m json_utils\n\u001B[1;32m---> 45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaved_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m model_serialization\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m generic_utils\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m io_utils\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\saving\\legacy\\save.py:24\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m object_registration\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hdf5_format\n\u001B[1;32m---> 24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m saving_utils\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialization\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaved_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load \u001B[38;5;28;01mas\u001B[39;00m saved_model_load\n",
      "File \u001B[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\keras\\saving\\legacy\\saved_model\\load_context.py:68\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns whether under a load context.\"\"\"\u001B[39;00m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_context\u001B[38;5;241m.\u001B[39min_load_context()\n\u001B[1;32m---> 68\u001B[0m tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mregister_load_context_function(in_load_context)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T05:25:18.705498Z",
     "start_time": "2025-04-22T05:25:16.997587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "\n",
    "# ========================\n",
    "# 1. FEATURE EXTRACTION\n",
    "# ========================\n",
    "def extract_features(file_path, n_mfcc=20, n_mels=128):\n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "    features = []\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    features.extend(np.mean(mfcc, axis=1))\n",
    "    features.extend(np.std(mfcc, axis=1))\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_db = librosa.power_to_db(mel)\n",
    "    features.extend(np.mean(mel_db, axis=1))\n",
    "    features.extend(np.std(mel_db, axis=1))\n",
    "\n",
    "    features.extend(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))\n",
    "    features.extend(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))\n",
    "    features.extend(np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1))\n",
    "    features.extend(np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)))\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features.extend(np.mean(chroma, axis=1))\n",
    "    features.extend(np.std(chroma, axis=1))\n",
    "\n",
    "    features.extend(np.mean(librosa.feature.zero_crossing_rate(y)))\n",
    "    features.extend(np.mean(librosa.feature.rms(y=y)))\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    features.extend(np.mean(y_harmonic))\n",
    "    features.extend(np.mean(y_percussive))\n",
    "\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    features.append(tempo)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 2. LOAD DATA\n",
    "# ========================\n",
    "def load_dataset(data_path):\n",
    "    X, y = [], []\n",
    "\n",
    "    real_dir = os.path.join(data_path, 'Real')\n",
    "    dummy_path = next((os.path.join(real_dir, f) for f in os.listdir(real_dir) if f.endswith('.wav')), None)\n",
    "\n",
    "    if dummy_path is None:\n",
    "        raise FileNotFoundError(\"No .wav file found in the 'Real' folder for feature dimension extraction.\")\n",
    "\n",
    "    feature_names = [f\"feature_{i}\" for i in range(len(extract_features(dummy_path)))]\n",
    "\n",
    "    for label in ['Real', 'Fake']:\n",
    "        class_path = os.path.join(data_path, label)\n",
    "        for file in os.listdir(class_path):\n",
    "            if file.endswith('.wav'):\n",
    "                path = os.path.join(class_path, file)\n",
    "                X.append(extract_features(path))\n",
    "                y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X_scaled, y, feature_names, scaler\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 3. CREATE MODEL\n",
    "# ========================\n",
    "def create_tabular_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 4. EXPLANATIONS\n",
    "# ========================\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    explainer = lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names,\n",
    "                                                  class_names=class_names, mode='classification')\n",
    "    return explainer.explain_instance(X_sample, predict_fn=model.predict, num_features=10)\n",
    "\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    explainer = shap.DeepExplainer(model, X_train[:100])\n",
    "    shap_values = explainer.shap_values(np.array([X_sample]))[0][0]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    shap.bar_plot(shap_values, feature_names=feature_names)\n",
    "    plt.title(\"SHAP Feature Contributions\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "\n",
    "    grads = tape.gradient(pred, sample_tensor).numpy()[0]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.barh(feature_names, grads)\n",
    "    plt.xlabel(\"Gradient\")\n",
    "    plt.title(\"Grad-CAM Style Input Gradient Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 5. MAIN EXECUTION\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "    X, y, feature_names, scaler = load_dataset(data_path)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = create_tabular_model(X_train.shape[1])\n",
    "    callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "                 ModelCheckpoint('best_tabular_model.h5', save_best_only=True)]\n",
    "\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=callbacks, verbose=1)\n",
    "    model = models.load_model('best_tabular_model.h5')\n",
    "\n",
    "    loss, acc = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "\n",
    "    for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "        sample = X_test[i]\n",
    "        pred = model.predict(sample[np.newaxis])[0][0]\n",
    "        pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "        true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {i}: True: {true_class}, Predicted: {pred_class} ({pred:.4f})\")\n",
    "\n",
    "        lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "        lime_exp.show_in_notebook()\n",
    "        explain_with_shap(model, X_train, sample, feature_names)\n",
    "        grad_cam_like_explanation(model, sample, feature_names)\n",
    "\n",
    "        print(\"\\nTop contributing LIME features:\")\n",
    "        for feature, weight in lime_exp.as_list()[:5]:\n",
    "            print(f\"{feature}: {weight:.4f}\")\n"
   ],
   "id": "26f9ba971878f2ac",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 144\u001B[39m\n\u001B[32m    142\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    143\u001B[39m     data_path = \u001B[33m\"\u001B[39m\u001B[33mc:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m144\u001B[39m     X, y, feature_names, scaler = \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    145\u001B[39m     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001B[32m0.2\u001B[39m, random_state=\u001B[32m42\u001B[39m)\n\u001B[32m    147\u001B[39m     model = create_tabular_model(X_train.shape[\u001B[32m1\u001B[39m])\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 64\u001B[39m, in \u001B[36mload_dataset\u001B[39m\u001B[34m(data_path)\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dummy_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mNo .wav file found in the \u001B[39m\u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m\u001B[33m folder for feature dimension extraction.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m64\u001B[39m feature_names = [\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfeature_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdummy_path\u001B[49m\u001B[43m)\u001B[49m))]\n\u001B[32m     66\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m]:\n\u001B[32m     67\u001B[39m     class_path = os.path.join(data_path, label)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 31\u001B[39m, in \u001B[36mextract_features\u001B[39m\u001B[34m(file_path, n_mfcc, n_mels)\u001B[39m\n\u001B[32m     28\u001B[39m features.extend(np.mean(mel_db, axis=\u001B[32m1\u001B[39m))\n\u001B[32m     29\u001B[39m features.extend(np.std(mel_db, axis=\u001B[32m1\u001B[39m))\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m \u001B[43mfeatures\u001B[49m\u001B[43m.\u001B[49m\u001B[43mextend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlibrosa\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m.\u001B[49m\u001B[43mspectral_centroid\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msr\u001B[49m\u001B[43m=\u001B[49m\u001B[43msr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m features.extend(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))\n\u001B[32m     33\u001B[39m features.extend(np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=\u001B[32m1\u001B[39m))\n",
      "\u001B[31mTypeError\u001B[39m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "489523611ad36fab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7cb4c02263c1fadc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6caa02b366ffb0ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T05:36:11.658952Z",
     "start_time": "2025-04-22T05:36:01.909062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Extended Feature Extraction\n",
    "def extract_features(file_path, n_mfcc=20, n_mels=128):\n",
    "    \"\"\"Extract multiple audio features and combine them into a single feature vector\"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    # MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    features.extend(mfcc_mean)\n",
    "    features.extend(mfcc_std)\n",
    "\n",
    "    # Mel Spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_db = librosa.power_to_db(mel)\n",
    "    mel_mean = np.mean(mel_db, axis=1)\n",
    "    mel_std = np.std(mel_db, axis=1)\n",
    "    features.extend(mel_mean)\n",
    "    features.extend(mel_std)\n",
    "\n",
    "    # Spectral Features\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "\n",
    "    features.append(np.mean(spectral_centroid))\n",
    "    features.append(np.mean(spectral_bandwidth))\n",
    "    features.append(np.mean(spectral_contrast, axis=1))\n",
    "    features.append(np.mean(spectral_rolloff))\n",
    "\n",
    "    # Chroma Features\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features.extend(np.mean(chroma, axis=1))\n",
    "    features.extend(np.std(chroma, axis=1))\n",
    "\n",
    "    # Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    features.append(np.mean(zcr))\n",
    "\n",
    "    # RMS Energy\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    features.append(np.mean(rms))\n",
    "\n",
    "    # Harmonic and Percussive\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    features.append(np.mean(y_harmonic))\n",
    "    features.append(np.mean(y_percussive))\n",
    "\n",
    "    # Tempo\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    features.append(tempo)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "# 2. Load and preprocess data\n",
    "def load_dataset(data_path):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    real_dir = os.path.join(data_path, 'Real')\n",
    "    dummy_path = next((os.path.join(real_dir, f) for f in os.listdir(real_dir) if f.endswith('.wav')), None)\n",
    "\n",
    "    if dummy_path is None:\n",
    "        raise FileNotFoundError(\"No .wav file found in the 'Real' folder for feature dimension extraction.\")\n",
    "\n",
    "    feature_names = [f\"feature_{i}\" for i in range(len(extract_features(dummy_path)))]\n",
    "\n",
    "    for label in ['Real', 'Fake']:\n",
    "        class_path = os.path.join(data_path, label)\n",
    "        for file in os.listdir(class_path):\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(class_path, file)\n",
    "                features = extract_features(file_path)\n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)  # Real=1, Fake=0\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    return X, y, feature_names, scaler\n",
    "\n",
    "# 3. Neural Network Model for Tabular Data\n",
    "def create_tabular_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 4. LIME Explanation for Tabular Data\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification'\n",
    "    )\n",
    "\n",
    "    exp = explainer.explain_instance(\n",
    "        data_row=X_sample,\n",
    "        predict_fn=model.predict,\n",
    "        num_features=10\n",
    "    )\n",
    "\n",
    "    return exp\n",
    "\n",
    "# 5. SHAP Explanation for Tabular Data\n",
    "def explain_with_shap(model, X_train, X_sample):\n",
    "    explainer = shap.KernelExplainer(model.predict, X_train)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    return shap_values\n",
    "\n",
    "# 6. Visualization Functions\n",
    "def plot_lime_explanation(exp):\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_shap_explanation(shap_values, X_sample):\n",
    "    shap.initjs()\n",
    "    shap.force_plot(shap_values[0], X_sample, matplotlib=True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(exp, feature_names):\n",
    "    lime_list = exp.as_list()\n",
    "    features = [x[0] for x in lime_list]\n",
    "    scores = [x[1] for x in lime_list]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(features, scores)\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title('LIME Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "    X, y, feature_names, scaler = load_dataset(data_path)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train model\n",
    "    model = create_tabular_model(X_train.shape[1])\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint('best_tabular_model.h5', save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate best model\n",
    "    model = models.load_model('best_tabular_model.h5')\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # LIME and SHAP Explanations\n",
    "    for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "        sample = X_test[i]\n",
    "        pred = model.predict(sample[np.newaxis, ...])[0][0]\n",
    "        pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "        true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"  True: {true_class}\")\n",
    "        print(f\"  Predicted: {pred_class} ({pred:.4f})\")\n",
    "\n",
    "        # Generate LIME explanation\n",
    "        exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "        plot_lime_explanation(exp)\n",
    "        plot_feature_importance(exp, feature_names)\n",
    "\n",
    "        # Generate SHAP explanation\n",
    "        shap_values = explain_with_shap(model, X_train, sample[np.newaxis, :])\n",
    "        plot_shap_explanation(shap_values, sample)\n",
    "\n",
    "        # Show raw feature values\n",
    "        print(\"\\nTop contributing features:\")\n",
    "        top_features = exp.as_list()[:5]  # Get top 5 features\n",
    "        for feature, weight in top_features:\n",
    "            feat_idx = int(feature.split('_')[-1]) if 'feature_' in feature else -1\n",
    "            if feat_idx >= 0 and feat_idx < len(feature_names):\n",
    "                print(f\"{feature_names[feat_idx]}: {weight:.4f} (value: {sample[feat_idx]:.4f})\")\n",
    "            else:\n",
    "                print(f\"{feature}: {weight:.4f}\")\n"
   ],
   "id": "fa9ff1d523f9f921",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (329,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 175\u001B[39m\n\u001B[32m    172\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    173\u001B[39m     \u001B[38;5;66;03m# Load and prepare data\u001B[39;00m\n\u001B[32m    174\u001B[39m     data_path = \u001B[33m\"\u001B[39m\u001B[33mc:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m175\u001B[39m     X, y, feature_names, scaler = \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    176\u001B[39m     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001B[32m0.2\u001B[39m, random_state=\u001B[32m42\u001B[39m)\n\u001B[32m    178\u001B[39m     \u001B[38;5;66;03m# Create and train model\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 82\u001B[39m, in \u001B[36mload_dataset\u001B[39m\u001B[34m(data_path)\u001B[39m\n\u001B[32m     79\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dummy_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     80\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mNo .wav file found in the \u001B[39m\u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m\u001B[33m folder for feature dimension extraction.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m82\u001B[39m feature_names = [\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfeature_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdummy_path\u001B[49m\u001B[43m)\u001B[49m))]\n\u001B[32m     84\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m]:\n\u001B[32m     85\u001B[39m     class_path = os.path.join(data_path, label)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 69\u001B[39m, in \u001B[36mextract_features\u001B[39m\u001B[34m(file_path, n_mfcc, n_mels)\u001B[39m\n\u001B[32m     66\u001B[39m tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n\u001B[32m     67\u001B[39m features.append(tempo)\n\u001B[32m---> \u001B[39m\u001B[32m69\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mValueError\u001B[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (329,) + inhomogeneous part."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T06:07:18.434493Z",
     "start_time": "2025-04-22T05:47:54.660184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "\n",
    "# ========================\n",
    "# 1. FEATURE EXTRACTION\n",
    "# ========================\n",
    "def extract_features(file_path, n_mfcc=20, n_mels=128):\n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "    features = []\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    features.append(np.mean(mfcc, axis=1))  # Mean MFCC values\n",
    "    features.append(np.std(mfcc, axis=1))   # Std of MFCC values\n",
    "\n",
    "    # Mel Spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_db = librosa.power_to_db(mel)\n",
    "    features.append(np.mean(mel_db, axis=1))  # Mean Mel spectrogram\n",
    "    features.append(np.std(mel_db, axis=1))   # Std Mel spectrogram\n",
    "\n",
    "    # Spectral features\n",
    "    features.append(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))  # Scalar mean spectral centroid\n",
    "    features.append(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))  # Scalar mean spectral bandwidth\n",
    "    features.append(np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1))  # Mean spectral contrast\n",
    "    features.append(np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)))  # Scalar mean spectral rolloff\n",
    "\n",
    "    # Chroma\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features.append(np.mean(chroma, axis=1))  # Mean chroma\n",
    "    features.append(np.std(chroma, axis=1))   # Std chroma\n",
    "\n",
    "    # Other features\n",
    "    features.append(np.mean(librosa.feature.zero_crossing_rate(y)))  # Scalar mean ZCR\n",
    "    features.append(np.mean(librosa.feature.rms(y=y)))  # Scalar mean RMS\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    features.append(np.mean(y_harmonic))  # Scalar mean harmonic\n",
    "    features.append(np.mean(y_percussive))  # Scalar mean percussive\n",
    "\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    features.append(tempo)  # Scalar tempo\n",
    "\n",
    "    # Flatten the list of features into a single array\n",
    "    return np.hstack(features)  # Concatenate into a single vector\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 2. LOAD DATA\n",
    "# ========================\n",
    "def load_dataset(data_path):\n",
    "    X, y = [], []\n",
    "    dummy_path = os.path.join(data_path, 'Real', 'real_1.wav')\n",
    "    feature_names = [f\"feature_{i}\" for i in range(len(extract_features(dummy_path)))]\n",
    "\n",
    "    for label in ['Real', 'Fake']:\n",
    "        class_path = os.path.join(data_path, label)\n",
    "        for file in os.listdir(class_path):\n",
    "            if file.endswith('.wav'):\n",
    "                path = os.path.join(class_path, file)\n",
    "                X.append(extract_features(path))\n",
    "                y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X_scaled, y, feature_names, scaler\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 3. CREATE MODEL\n",
    "# ========================\n",
    "def create_tabular_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 4. EXPLANATIONS\n",
    "# ========================\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    explainer = lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names,\n",
    "                                                  class_names=class_names, mode='classification')\n",
    "    return explainer.explain_instance(X_sample, predict_fn=model.predict, num_features=10)\n",
    "\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    explainer = shap.DeepExplainer(model, X_train[:100])  # Use a subset for speed\n",
    "    shap_values = explainer.shap_values(np.array([X_sample]))[0][0]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    shap.bar_plot(shap_values, feature_names=feature_names)\n",
    "    plt.title(\"SHAP Feature Contributions\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "\n",
    "    grads = tape.gradient(pred, sample_tensor).numpy()[0]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.barh(feature_names, grads)\n",
    "    plt.xlabel(\"Gradient\")\n",
    "    plt.title(\"Grad-CAM Style Input Gradient Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 5. MAIN EXECUTION\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "    X, y, feature_names, scaler = load_dataset(data_path)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = create_tabular_model(X_train.shape[1])\n",
    "    callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "                 ModelCheckpoint('best_tabular_model.h5', save_best_only=True)]\n",
    "\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=callbacks, verbose=1)\n",
    "    model = models.load_model('best_tabular_model.h5')\n",
    "\n",
    "    loss, acc = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Explain 3 random test samples\n",
    "    for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "        sample = X_test[i]\n",
    "        pred = model.predict(sample[np.newaxis])[0][0]\n",
    "        pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "        true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {i}: True: {true_class}, Predicted: {pred_class} ({pred:.4f})\")\n",
    "\n",
    "        lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "        lime_exp.show_in_notebook()\n",
    "        explain_with_shap(model, X_train, sample, feature_names)\n",
    "        grad_cam_like_explanation(model, sample, feature_names)\n",
    "\n",
    "        print(\"\\nTop contributing LIME features:\")\n",
    "        for feature, weight in lime_exp.as_list()[:5]:\n",
    "            print(f\"{feature}: {weight:.4f}\")\n"
   ],
   "id": "f7a721894a51020b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m82/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9067 - loss: 0.2412"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 13ms/step - accuracy: 0.9133 - loss: 0.2267 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
      "Epoch 2/50\n",
      "\u001B[1m68/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9988 - loss: 0.0109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9988 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 7.4457e-04\n",
      "Epoch 3/50\n",
      "\u001B[1m87/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 3.0038e-04\n",
      "Epoch 4/50\n",
      "\u001B[1m79/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 1.4937e-04\n",
      "Epoch 5/50\n",
      "\u001B[1m79/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9997 - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 8.7875e-05\n",
      "Epoch 6/50\n",
      "\u001B[1m80/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9978 - loss: 0.0035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9978 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 5.3713e-05\n",
      "Epoch 7/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 9.3110e-05\n",
      "Epoch 8/50\n",
      "\u001B[1m76/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9982 - loss: 0.0036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9982 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 3.5426e-05\n",
      "Epoch 9/50\n",
      "\u001B[1m86/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9981 - loss: 0.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9982 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 2.5274e-05\n",
      "Epoch 10/50\n",
      "\u001B[1m85/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 7.1785e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 7.2393e-04 - val_accuracy: 1.0000 - val_loss: 1.4505e-05\n",
      "Epoch 11/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 3.6935e-04 - val_accuracy: 1.0000 - val_loss: 1.8535e-05\n",
      "Epoch 12/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 4.9889e-05\n",
      "Epoch 13/50\n",
      "\u001B[1m84/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9981 - loss: 0.0025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9983 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 9.3110e-06\n",
      "Epoch 14/50\n",
      "\u001B[1m75/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 3.3335e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 3.3059e-04 - val_accuracy: 1.0000 - val_loss: 5.9166e-06\n",
      "Epoch 15/50\n",
      "\u001B[1m76/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 1.9430e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 1.8615e-04 - val_accuracy: 1.0000 - val_loss: 5.4139e-06\n",
      "Epoch 16/50\n",
      "\u001B[1m80/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 3.8913e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 3.6909e-04 - val_accuracy: 1.0000 - val_loss: 5.0891e-06\n",
      "Epoch 17/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 2.8243e-04 - val_accuracy: 1.0000 - val_loss: 6.1227e-04\n",
      "Epoch 18/50\n",
      "\u001B[1m83/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 2.4496e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 2.5274e-04 - val_accuracy: 1.0000 - val_loss: 2.9057e-06\n",
      "Epoch 19/50\n",
      "\u001B[1m83/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 7.6781e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 7.6173e-05 - val_accuracy: 1.0000 - val_loss: 2.2217e-06\n",
      "Epoch 20/50\n",
      "\u001B[1m80/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 1.8571e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 2.0844e-04 - val_accuracy: 1.0000 - val_loss: 1.9144e-06\n",
      "Epoch 21/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 2.1483e-04 - val_accuracy: 1.0000 - val_loss: 3.3927e-06\n",
      "Epoch 22/50\n",
      "\u001B[1m77/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9991 - loss: 0.0030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 1.6203e-06\n",
      "Epoch 23/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9992 - loss: 9.4483e-04 - val_accuracy: 1.0000 - val_loss: 1.7321e-06\n",
      "Epoch 24/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 1.7591e-04 - val_accuracy: 1.0000 - val_loss: 1.8162e-06\n",
      "Epoch 25/50\n",
      "\u001B[1m79/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 4.3229e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 4.7678e-05 - val_accuracy: 1.0000 - val_loss: 1.2828e-06\n",
      "Epoch 26/50\n",
      "\u001B[1m87/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 8.1412e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 8.3155e-05 - val_accuracy: 1.0000 - val_loss: 1.1380e-06\n",
      "Epoch 27/50\n",
      "\u001B[1m81/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 2.4440e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 2.4447e-05 - val_accuracy: 1.0000 - val_loss: 1.0600e-06\n",
      "Epoch 28/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9999 - loss: 8.7629e-04 - val_accuracy: 1.0000 - val_loss: 1.9799e-06\n",
      "Epoch 29/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 1.9018e-04 - val_accuracy: 1.0000 - val_loss: 2.8988e-06\n",
      "Epoch 30/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9987 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 3.8776e-06\n",
      "Epoch 31/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 3.5821e-04 - val_accuracy: 1.0000 - val_loss: 1.4647e-06\n",
      "Epoch 32/50\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 1.0317e-04 - val_accuracy: 1.0000 - val_loss: 1.0733e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 1.8925e-06\n",
      "\n",
      "Test Accuracy: 1.0000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 124ms/step\n",
      "\n",
      "Sample 704: True: Fake, Predicted: Fake (0.0000)\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 166\u001B[39m\n\u001B[32m    162\u001B[39m true_class = \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m y_test[i] == \u001B[32m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    164\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mSample \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: True: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrue_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Predicted: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m lime_exp = \u001B[43mexplain_with_lime\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    167\u001B[39m lime_exp.show_in_notebook()\n\u001B[32m    168\u001B[39m explain_with_shap(model, X_train, sample, feature_names)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 108\u001B[39m, in \u001B[36mexplain_with_lime\u001B[39m\u001B[34m(model, X_train, X_sample, feature_names, class_names)\u001B[39m\n\u001B[32m    105\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mexplain_with_lime\u001B[39m(model, X_train, X_sample, feature_names, class_names=[\u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m]):\n\u001B[32m    106\u001B[39m     explainer = lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names,\n\u001B[32m    107\u001B[39m                                                   class_names=class_names, mode=\u001B[33m'\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m108\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredict_fn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:452\u001B[39m, in \u001B[36mLimeTabularExplainer.explain_instance\u001B[39m\u001B[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001B[39m\n\u001B[32m    448\u001B[39m     labels = [\u001B[32m0\u001B[39m]\n\u001B[32m    449\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels:\n\u001B[32m    450\u001B[39m     (ret_exp.intercept[label],\n\u001B[32m    451\u001B[39m      ret_exp.local_exp[label],\n\u001B[32m--> \u001B[39m\u001B[32m452\u001B[39m      ret_exp.score, ret_exp.local_pred) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbase\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m            \u001B[49m\u001B[43mscaled_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m            \u001B[49m\u001B[43myss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    455\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    462\u001B[39m     ret_exp.intercept[\u001B[32m1\u001B[39m] = ret_exp.intercept[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_base.py:182\u001B[39m, in \u001B[36mLimeBase.explain_instance_with_data\u001B[39m\u001B[34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001B[39;00m\n\u001B[32m    146\u001B[39m \n\u001B[32m    147\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \u001B[33;03m    local_pred is the prediction of the explanation model on the original instance\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    181\u001B[39m weights = \u001B[38;5;28mself\u001B[39m.kernel_fn(distances)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m labels_column = \u001B[43mneighborhood_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    183\u001B[39m used_features = \u001B[38;5;28mself\u001B[39m.feature_selection(neighborhood_data,\n\u001B[32m    184\u001B[39m                                        labels_column,\n\u001B[32m    185\u001B[39m                                        weights,\n\u001B[32m    186\u001B[39m                                        num_features,\n\u001B[32m    187\u001B[39m                                        feature_selection)\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mIndexError\u001B[39m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:21:54.385628Z",
     "start_time": "2025-04-22T09:21:54.343910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lime import lime_tabular\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    def predict_proba_fn(x):\n",
    "        preds = model.predict(x)\n",
    "        return np.column_stack([1 - preds, preds])\n",
    "\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification'\n",
    "    )\n",
    "\n",
    "    explanation = explainer.explain_instance(\n",
    "        data_row=X_sample,\n",
    "        predict_fn=predict_proba_fn,\n",
    "        num_features=10\n",
    "    )\n",
    "\n",
    "    # Show in Jupyter cell\n",
    "    display(HTML(explanation.as_html()))\n",
    "\n",
    "    print(\"\\n📌 Top LIME Feature Contributions:\")\n",
    "    for feature, weight in explanation.as_list():\n",
    "        print(f\"{feature:50s}: {weight:+.4f}\")\n"
   ],
   "id": "a8a28ad65043d920",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:23:03.409655Z",
     "start_time": "2025-04-22T09:22:48.579724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        prediction = model(sample_tensor)\n",
    "\n",
    "    grads = tape.gradient(prediction, sample_tensor).numpy()[0]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_names, grads, color='dodgerblue')\n",
    "    plt.xlabel(\"Input Gradient\")\n",
    "    plt.title(\"Grad-CAM Style Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "2950ceb6e84b86d9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:23:23.011631Z",
     "start_time": "2025-04-22T09:23:22.140573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example loop for 3 random samples\n",
    "for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "    sample = X_test[i]\n",
    "    pred = model.predict(sample[np.newaxis])[0][0]\n",
    "    pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "    true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "    print(f\"\\n🎯 Sample Index: {i}\")\n",
    "    print(f\"True Label   : {true_class}\")\n",
    "    print(f\"Prediction   : {pred_class} ({pred:.4f})\")\n",
    "\n",
    "    # LIME\n",
    "    explain_with_lime(model, X_train, sample, feature_names)\n",
    "\n",
    "    # Grad-CAM-style\n",
    "    grad_cam_like_explanation(model, sample, feature_names)\n"
   ],
   "id": "89e5133c85a87d47",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Example loop for 3 random samples\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m np.random.choice(\u001B[38;5;28mlen\u001B[39m(\u001B[43mX_test\u001B[49m), \u001B[32m3\u001B[39m, replace=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m      3\u001B[39m     sample = X_test[i]\n\u001B[32m      4\u001B[39m     pred = model.predict(sample[np.newaxis])[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m]\n",
      "\u001B[31mNameError\u001B[39m: name 'X_test' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:28:20.887430Z",
     "start_time": "2025-04-22T09:28:07.215764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n"
   ],
   "id": "1df5d5f7eac60d8f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:27:38.201696Z",
     "start_time": "2025-04-22T09:27:38.184898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dataset(data_path):\n",
    "    X, y = [], []\n",
    "    dummy_path = os.path.join(data_path, 'Real', 'real_1.wav')\n",
    "    feature_names = [f\"feature_{i}\" for i in range(len(extract_features(dummy_path)))]\n",
    "\n",
    "    for label in ['Real', 'Fake']:\n",
    "        class_path = os.path.join(data_path, label)\n",
    "        for file in os.listdir(class_path):\n",
    "            if file.endswith('.wav'):\n",
    "                path = os.path.join(class_path, file)\n",
    "                X.append(extract_features(path))\n",
    "                y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X_scaled, y, feature_names, scaler\n"
   ],
   "id": "47464c1f435bd58e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "53bf5e11d62527e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:29:07.973323Z",
     "start_time": "2025-04-22T09:29:07.944948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features(file_path, n_mfcc=20, n_mels=128):\n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "    features = []\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    features.append(np.mean(mfcc, axis=1))\n",
    "    features.append(np.std(mfcc, axis=1))\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_db = librosa.power_to_db(mel)\n",
    "    features.append(np.mean(mel_db, axis=1))\n",
    "    features.append(np.std(mel_db, axis=1))\n",
    "\n",
    "    features.append(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))\n",
    "    features.append(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))\n",
    "    features.append(np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1))\n",
    "    features.append(np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)))\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features.append(np.mean(chroma, axis=1))\n",
    "    features.append(np.std(chroma, axis=1))\n",
    "\n",
    "    features.append(np.mean(librosa.feature.zero_crossing_rate(y)))\n",
    "    features.append(np.mean(librosa.feature.rms(y=y)))\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    features.append(np.mean(y_harmonic))\n",
    "    features.append(np.mean(y_percussive))\n",
    "\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    features.append(tempo)\n",
    "\n",
    "    return np.hstack(features)\n"
   ],
   "id": "5e26761b3eb97630",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:48:45.479153Z",
     "start_time": "2025-04-22T09:32:01.496964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_tabular_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load data\n",
    "data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "X, y, feature_names, scaler = load_dataset(data_path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = create_tabular_model(X_train.shape[1])\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('audio_model.h5', save_best_only=True)\n",
    "]\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=callbacks, verbose=1)\n",
    "model = models.load_model('model.h5')\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {acc:.4f}\")\n"
   ],
   "id": "30f761cb2d272c8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m64/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8856 - loss: 0.2609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 13ms/step - accuracy: 0.8952 - loss: 0.2418 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
      "Epoch 2/50\n",
      "\u001B[1m64/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 3/50\n",
      "\u001B[1m67/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 7.5114e-04\n",
      "Epoch 4/50\n",
      "\u001B[1m64/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 3.3021e-04\n",
      "Epoch 5/50\n",
      "\u001B[1m61/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9995 - loss: 0.0026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 1.5262e-04\n",
      "Epoch 6/50\n",
      "\u001B[1m69/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 8.6351e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 8.6044e-04 - val_accuracy: 1.0000 - val_loss: 8.6536e-05\n",
      "Epoch 7/50\n",
      "\u001B[1m65/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 4.2805e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 4.3534e-04 - val_accuracy: 1.0000 - val_loss: 6.4390e-05\n",
      "Epoch 8/50\n",
      "\u001B[1m63/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 4.3787e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 4.4473e-04 - val_accuracy: 1.0000 - val_loss: 4.4552e-05\n",
      "Epoch 9/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 6.0195e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9965 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 5.3108e-05\n",
      "Epoch 11/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9986 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 8.7259e-05\n",
      "Epoch 12/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9997 - loss: 7.5183e-04 - val_accuracy: 1.0000 - val_loss: 5.4965e-05\n",
      "Epoch 13/50\n",
      "\u001B[1m70/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9997 - loss: 7.3889e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9997 - loss: 7.4551e-04 - val_accuracy: 1.0000 - val_loss: 3.4464e-05\n",
      "Epoch 14/50\n",
      "\u001B[1m61/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 5.3151e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 5.4271e-04 - val_accuracy: 1.0000 - val_loss: 2.3745e-05\n",
      "Epoch 15/50\n",
      "\u001B[1m68/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 8.0171e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 7.7986e-04 - val_accuracy: 1.0000 - val_loss: 1.7348e-05\n",
      "Epoch 16/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 1.9722e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 1.9852e-04 - val_accuracy: 1.0000 - val_loss: 1.1189e-05\n",
      "Epoch 17/50\n",
      "\u001B[1m61/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 2.8439e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 2.7902e-04 - val_accuracy: 1.0000 - val_loss: 1.0341e-05\n",
      "Epoch 18/50\n",
      "\u001B[1m63/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 2.4527e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 2.4103e-04 - val_accuracy: 1.0000 - val_loss: 7.9871e-06\n",
      "Epoch 19/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 8.1155e-04 - val_accuracy: 1.0000 - val_loss: 1.2979e-05\n",
      "Epoch 20/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 1.5816e-04 - val_accuracy: 1.0000 - val_loss: 1.7603e-05\n",
      "Epoch 21/50\n",
      "\u001B[1m64/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 6.2137e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 7.8094e-05 - val_accuracy: 1.0000 - val_loss: 7.4812e-06\n",
      "Epoch 22/50\n",
      "\u001B[1m68/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 5.1593e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 5.0206e-04 - val_accuracy: 1.0000 - val_loss: 5.3802e-06\n",
      "Epoch 23/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 3.7857e-04 - val_accuracy: 1.0000 - val_loss: 5.7474e-06\n",
      "Epoch 24/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 2.9190e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 2.9189e-04 - val_accuracy: 1.0000 - val_loss: 3.3272e-06\n",
      "Epoch 25/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9994 - loss: 9.1067e-04 - val_accuracy: 1.0000 - val_loss: 4.8811e-05\n",
      "Epoch 26/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9982 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 1.6663e-04\n",
      "Epoch 27/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 9.9594e-04 - val_accuracy: 1.0000 - val_loss: 4.1602e-06\n",
      "Epoch 28/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.7954e-04 - val_accuracy: 1.0000 - val_loss: 6.1767e-05\n",
      "Epoch 29/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 6.3402e-05 - val_accuracy: 1.0000 - val_loss: 3.1210e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m23/23\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 4.7097e-06\n",
      "\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:49:43.450683Z",
     "start_time": "2025-04-22T09:49:43.361991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    explainer = lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names,\n",
    "                                                  class_names=class_names, mode='classification')\n",
    "    return explainer.explain_instance(X_sample, predict_fn=model.predict, num_features=10)\n",
    "\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    explainer = shap.DeepExplainer(model, X_train[:100])\n",
    "    shap_values = explainer.shap_values(np.array([X_sample]))[0][0]\n",
    "\n",
    "    shap.plots.bar(shap.Explanation(values=shap_values, feature_names=feature_names, data=X_sample))\n",
    "\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "\n",
    "    grads = tape.gradient(pred, sample_tensor).numpy()[0]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(feature_names, grads)\n",
    "    plt.xlabel(\"Gradient\")\n",
    "    plt.title(\"Grad-CAM Style Input Gradient Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "50fd5363945dc209",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:57:55.915218Z",
     "start_time": "2025-04-22T09:57:55.781650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    \"\"\"Explain model prediction using LIME\"\"\"\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Wrapper function to format predictions correctly for LIME\n",
    "    def predict_proba(x):\n",
    "        preds = model.predict(x, verbose=0).flatten()\n",
    "        return np.vstack([1-preds, preds]).T  # [prob_fake, prob_real]\n",
    "\n",
    "    explanation = explainer.explain_instance(\n",
    "        X_sample,\n",
    "        predict_fn=predict_proba,\n",
    "        num_features=min(10, len(feature_names))\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    \"\"\"Explain model prediction using SHAP\"\"\"\n",
    "    # Wrapper function for SHAP\n",
    "    def predict_fn(x):\n",
    "        return model.predict(x, verbose=0)\n",
    "\n",
    "    # Use KernelExplainer as more general purpose\n",
    "    explainer = shap.KernelExplainer(\n",
    "        predict_fn,\n",
    "        shap.sample(X_train, 100)  # Use subset for background\n",
    "    )\n",
    "\n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer.shap_values(X_sample.reshape(1, -1))\n",
    "\n",
    "    # Plot for binary classification\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # Take values for positive class\n",
    "\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "        shap_values[0],\n",
    "        feature_names=feature_names,\n",
    "        matplotlib=True\n",
    "    )\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    \"\"\"Gradient-based explanation similar to Grad-CAM\"\"\"\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "        target = pred[:, 1] if pred.shape[1] == 2 else pred  # Handle binary vs multi-class\n",
    "\n",
    "    grads = tape.gradient(target, sample_tensor).numpy()[0]\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sorted_idx = np.argsort(np.abs(grads))[::-1]\n",
    "    plt.barh(np.array(feature_names)[sorted_idx], grads[sorted_idx])\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Gradient-based Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with random test samples\n",
    "for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "    sample = X_test[i]\n",
    "    pred = model.predict(sample[np.newaxis], verbose=0)[0]\n",
    "\n",
    "    # Handle both binary (single output) and categorical (2 outputs) cases\n",
    "    if len(pred) == 2:  # Categorical output\n",
    "        pred_class = 'Real' if pred[1] > 0.5 else 'Fake'\n",
    "        pred_prob = pred[1] if pred[1] > 0.5 else 1 - pred[1]\n",
    "    else:  # Binary output\n",
    "        pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "        pred_prob = pred if pred > 0.5 else 1 - pred\n",
    "\n",
    "    true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "    print(f\"\\nSample {i}: True: {true_class}, Predicted: {pred_class} ({pred_prob:.4f})\")\n",
    "\n",
    "    # LIME explanation\n",
    "    lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "    lime_exp.show_in_notebook()\n",
    "\n",
    "    # SHAP explanation\n",
    "    explain_with_shap(model, X_train, sample, feature_names)\n",
    "\n",
    "    # Gradient explanation\n",
    "    grad_cam_like_explanation(model, sample, feature_names)\n",
    "\n",
    "    # Print top LIME features\n",
    "    print(\"\\nTop contributing LIME features:\")\n",
    "    for feature, weight in lime_exp.as_list()[:5]:\n",
    "        print(f\"{feature}: {weight:.4f}\")"
   ],
   "id": "4c5b023ca83558e6",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (788784872.py, line 24)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mexplanation = explainer.explain_instance(\u001B[39m\n                                            ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m '(' was never closed\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:59:59.954051Z",
     "start_time": "2025-04-22T09:59:49.748501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    \"\"\"Explain model prediction using LIME\"\"\"\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Wrapper function to format predictions correctly for LIME\n",
    "    def predict_proba(x):\n",
    "        preds = model.predict(x, verbose=0).flatten()\n",
    "        return np.vstack([1-preds, preds]).T  # [prob_fake, prob_real]\n",
    "\n",
    "    explanation = explainer.explain_instance(\n",
    "        X_sample,\n",
    "        predict_fn=predict_proba,\n",
    "        num_features=min(10, len(feature_names))\n",
    "    )\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    \"\"\"Explain model prediction using SHAP\"\"\"\n",
    "    # Wrapper function for SHAP\n",
    "    def predict_fn(x):\n",
    "        return model.predict(x, verbose=0)\n",
    "\n",
    "    # Use KernelExplainer as more general purpose\n",
    "    explainer = shap.KernelExplainer(\n",
    "        predict_fn,\n",
    "        shap.sample(X_train, 100)  # Use subset for background\n",
    "    )\n",
    "\n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer.shap_values(X_sample.reshape(1, -1))\n",
    "\n",
    "    # Plot for binary classification\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # Take values for positive class\n",
    "\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "        shap_values[0],\n",
    "        feature_names=feature_names,\n",
    "        matplotlib=True\n",
    "    )\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    \"\"\"Gradient-based explanation similar to Grad-CAM\"\"\"\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "        target = pred[:, 1] if pred.shape[1] == 2 else pred  # Handle binary vs multi-class\n",
    "\n",
    "    grads = tape.gradient(target, sample_tensor).numpy()[0]\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sorted_idx = np.argsort(np.abs(grads))[::-1]\n",
    "    plt.barh(np.array(feature_names)[sorted_idx], grads[sorted_idx])\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Gradient-based Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with random test samples\n",
    "for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "    sample = X_test[i]\n",
    "    pred = model.predict(sample[np.newaxis], verbose=0)[0]\n",
    "\n",
    "    # Handle both binary (single output) and categorical (2 outputs) cases\n",
    "    if len(pred) == 2:  # Categorical output\n",
    "        pred_class = 'Real' if pred[1] > 0.5 else 'Fake'\n",
    "        pred_prob = pred[1] if pred[1] > 0.5 else 1 - pred[1]\n",
    "    else:  # Binary output\n",
    "        pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "        pred_prob = pred if pred > 0.5 else 1 - pred\n",
    "\n",
    "    true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "    print(f\"\\nSample {i}: True: {true_class}, Predicted: {pred_class} ({pred_prob:.4f})\")\n",
    "\n",
    "    # LIME explanation\n",
    "    lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "    lime_exp.show_in_notebook()\n",
    "\n",
    "    # SHAP explanation\n",
    "    explain_with_shap(model, X_train, sample, feature_names)\n",
    "\n",
    "    # Gradient explanation\n",
    "    grad_cam_like_explanation(model, sample, feature_names)\n",
    "\n",
    "    # Print top LIME features\n",
    "    print(\"\\nTop contributing LIME features:\")\n",
    "    for feature, weight in lime_exp.as_list()[:5]:\n",
    "        print(f\"{feature}: {weight:.4f}\")"
   ],
   "id": "330f03d96057fd22",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 93\u001B[39m\n\u001B[32m     89\u001B[39m     pred_prob = pred \u001B[38;5;28;01mif\u001B[39;00m pred > \u001B[32m0.5\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m1\u001B[39m - pred\n\u001B[32m     91\u001B[39m true_class = \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m y_test[i] == \u001B[32m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mSample \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: True: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrue_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Predicted: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred_prob\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     95\u001B[39m \u001B[38;5;66;03m# LIME explanation\u001B[39;00m\n\u001B[32m     96\u001B[39m lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
      "\u001B[31mTypeError\u001B[39m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T10:02:20.335293Z",
     "start_time": "2025-04-22T10:02:20.312139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    \"\"\"Explain model prediction using LIME\"\"\"\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Wrapper function to format predictions correctly for LIME\n",
    "    def predict_proba(x):\n",
    "        preds = model.predict(x, verbose=0)\n",
    "        if preds.ndim == 1:  # Binary classification case\n",
    "            return np.vstack([1-preds, preds]).T\n",
    "        return preds  # Multi-class case\n",
    "\n",
    "    explanation = explainer.explain_instance(\n",
    "        X_sample,\n",
    "        predict_fn=predict_proba,\n",
    "        num_features=min(10, len(feature_names))\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    \"\"\"Explain model prediction using SHAP\"\"\"\n",
    "    # Wrapper function for SHAP\n",
    "    def predict_fn(x):\n",
    "        return model.predict(x, verbose=0)\n",
    "\n",
    "    # Use KernelExplainer as more general purpose\n",
    "    explainer = shap.KernelExplainer(\n",
    "        predict_fn,\n",
    "        shap.sample(X_train, 100)  # Use subset for background\n",
    "    )\n",
    "\n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer.shap_values(X_sample.reshape(1, -1))\n",
    "\n",
    "    # Plot for binary classification\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # Take values for positive class\n",
    "\n",
    "    shap.plots.bar(shap.Explanation(\n",
    "        values=shap_values[0],\n",
    "        base_values=explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "        feature_names=feature_names,\n",
    "        data=X_sample\n",
    "    ))\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    \"\"\"Gradient-based explanation similar to Grad-CAM\"\"\"\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "        target = pred[:, 1] if pred.shape[1] == 2 else pred[0]  # Handle binary vs multi-class\n",
    "\n",
    "    grads = tape.gradient(target, sample_tensor).numpy()[0]\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sorted_idx = np.argsort(np.abs(grads))[::-1]\n",
    "    plt.barh(np.array(feature_names)[sorted_idx], grads[sorted_idx])\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Gradient-based Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with random test samples\n",
    "for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "    sample = X_test[i]\n",
    "    pred = model.predict(sample[np.newaxis], verbose=0)\n",
    "\n",
    "    # Handle both binary (single output) and categorical (2 outputs) cases\n",
    "    if pred.shape[1] == 2:  # Categorical output\n",
    "        pred_class = 'Real' if pred[0,1] > 0.5 else 'Fake'\n",
    "        pred_prob = float(pred[0,1] if pred[0,1] > 0.5 else 1 - pred[0,1])\n",
    "    else:  # Binary output\n",
    "        pred_class = 'Real' if pred[0,0] > 0.5 else 'Fake'\n",
    "        pred_prob = float(pred[0,0] if pred[0,0] > 0.5 else 1 - pred[0,0])\n",
    "\n",
    "    true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "    print(f\"\\nSample {i}: True: {true_class}, Predicted: {pred_class} ({pred_prob:.4f})\")\n",
    "\n",
    "    # LIME explanation\n",
    "    lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "    lime_exp.show_in_notebook()\n",
    "\n",
    "    # SHAP explanation\n",
    "    explain_with_shap(model, X_train, sample, feature_names)\n",
    "\n",
    "    # Gradient explanation\n",
    "    grad_cam_like_explanation(model, sample, feature_names)\n",
    "\n",
    "    # Print top LIME features\n",
    "    print(\"\\nTop contributing LIME features:\")\n",
    "    for feature, weight in lime_exp.as_list()[:5]:\n",
    "        print(f\"{feature}: {weight:.4f}\")"
   ],
   "id": "d463d3e07368ba6",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (3403632678.py, line 26)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 26\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mexplanation = explainer.explain_instance(\u001B[39m\n                                            ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m '(' was never closed\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T10:05:15.037991Z",
     "start_time": "2025-04-22T10:04:20.140534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    \"\"\"Explain model prediction using LIME\"\"\"\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Wrapper function to format predictions correctly for LIME\n",
    "    def predict_proba(x):\n",
    "        preds = model.predict(x, verbose=0)\n",
    "        if preds.ndim == 1:  # Binary classification case\n",
    "            return np.vstack([1-preds, preds]).T\n",
    "        return preds  # Multi-class case\n",
    "\n",
    "    explanation = explainer.explain_instance(\n",
    "        X_sample,\n",
    "        predict_fn=predict_proba,\n",
    "        num_features=min(10, len(feature_names))\n",
    "    )\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    \"\"\"Explain model prediction using SHAP\"\"\"\n",
    "    # Wrapper function for SHAP\n",
    "    def predict_fn(x):\n",
    "        return model.predict(x, verbose=0)\n",
    "\n",
    "    # Use KernelExplainer as more general purpose\n",
    "    explainer = shap.KernelExplainer(\n",
    "        predict_fn,\n",
    "        shap.sample(X_train, 100)  # Use subset for background\n",
    "    )\n",
    "\n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer.shap_values(X_sample.reshape(1, -1))\n",
    "\n",
    "    # Plot for binary classification\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # Take values for positive class\n",
    "\n",
    "    shap.plots.bar(shap.Explanation(\n",
    "        values=shap_values[0],\n",
    "        base_values=explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "        feature_names=feature_names,\n",
    "        data=X_sample\n",
    "    ))\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    \"\"\"Gradient-based explanation similar to Grad-CAM\"\"\"\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "        target = pred[:, 1] if pred.shape[1] == 2 else pred[0]  # Handle binary vs multi-class\n",
    "\n",
    "    grads = tape.gradient(target, sample_tensor).numpy()[0]\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sorted_idx = np.argsort(np.abs(grads))[::-1]\n",
    "    plt.barh(np.array(feature_names)[sorted_idx], grads[sorted_idx])\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Gradient-based Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample test data - replace with your actual data\n",
    "    X_train = np.random.rand(100, 10)\n",
    "    X_test = np.random.rand(10, 10)\n",
    "    y_test = np.random.randint(0, 2, 10)\n",
    "    feature_names = [f\"feature_{i}\" for i in range(10)]\n",
    "\n",
    "    # Sample model - replace with your actual model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    # Test with random samples\n",
    "    for i in np.random.choice(len(X_test), min(3, len(X_test)), replace=False):\n",
    "        sample = X_test[i]\n",
    "        pred = model.predict(sample[np.newaxis], verbose=0)\n",
    "\n",
    "        # Handle both binary and categorical outputs\n",
    "        if pred.shape[1] == 2:  # Categorical output\n",
    "            pred_class = 'Real' if pred[0,1] > 0.5 else 'Fake'\n",
    "            pred_prob = float(pred[0,1] if pred[0,1] > 0.5 else 1 - pred[0,1])\n",
    "        else:  # Binary output\n",
    "            pred_class = 'Real' if pred[0,0] > 0.5 else 'Fake'\n",
    "            pred_prob = float(pred[0,0] if pred[0,0] > 0.5 else 1 - pred[0,0])\n",
    "\n",
    "        true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {i}: True: {true_class}, Predicted: {pred_class} ({pred_prob:.4f})\")\n",
    "\n",
    "        # LIME explanation\n",
    "        try:\n",
    "            lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "            lime_exp.show_in_notebook()\n",
    "            print(\"\\nTop contributing LIME features:\")\n",
    "            for feature, weight in lime_exp.as_list()[:5]:\n",
    "                print(f\"{feature}: {weight:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"LIME explanation failed: {str(e)}\")\n",
    "\n",
    "        # SHAP explanation\n",
    "        try:\n",
    "            explain_with_shap(model, X_train, sample, feature_names)\n",
    "        except Exception as e:\n",
    "            print(f\"SHAP explanation failed: {str(e)}\")\n",
    "\n",
    "        # Gradient explanation\n",
    "        try:\n",
    "            grad_cam_like_explanation(model, sample, feature_names)\n",
    "        except Exception as e:\n",
    "            print(f\"Gradient explanation failed: {str(e)}\")"
   ],
   "id": "eeeb244b58a9d82d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 2: True: Fake, Predicted: Fake (0.5568)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME explanation failed: index 1 is out of bounds for axis 1 with size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP explanation failed: 'numpy.float64' object is not iterable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 4: True: Fake, Predicted: Fake (0.5101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME explanation failed: index 1 is out of bounds for axis 1 with size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP explanation failed: 'numpy.float64' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZEdJREFUeJzt3Qu8VWWdP/6Hu8YdRbmIAoqkoqBSpGl00cLBKcYKMhxv/IAyrfEyJZWloYChNY6jITGCimFiEo5MappEXjI1GZ1UFJLogqEWIgMCwf6/vk+vff77HA9wgMM6wHm/X6/dOXvvtdd+1trPOXI+fZ/valIqlUoJAAAAAArUtMg3AwAAAIAglAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIANuvss89OPXv2rPZYkyZN0uWXX552JTNmzMjjeuqpp9Lu5IMf/GC+AQA0RkIpANgFvfLKK+n8889Phx56aHrXu96Vb4cffnj6whe+kJ599tm0p/vBD36Q/u3f/q2hh7HLiGAwQrfabm+//fZOec8JEyakH//4x2lXPR+nnnpq2l09//zzOdhdunRpQw8FABpU84Z9ewCgpnvvvTeNGDEiNW/ePI0cOTL1798/NW3aNL344ovp7rvvTt/73vdyaHXQQQc1yPjWrl2bx7azQ6n//d//Tf/yL/+yU99ndzJgwIB08cUXv+Pxli1b7rRQ6lOf+lQaNmzYTtl/Yxah1BVXXJGr5GpWIgJAYyKUAoBdyJIlS9JnPvOZHDg99NBDqWvXrtWev/rqq9ONN96YQ6ot+b//+7/UunXrnTLGvfbaa6fsly3r3r17OuOMM9LubNOmTWn9+vWNdg5FVdvOChEBYHdk+R4A7EK+/e1v50Bp+vTp7wikQlQoffGLX0w9evSo1vepTZs2OdD6h3/4h9S2bdtcYRV+8YtfpE9/+tPpwAMPTK1atcqvu/DCC3O1U02xVKtfv345MIivc+bMqXWMtfWU+uMf/5jOPffctP/+++f3OeKII9LNN99cbZv58+fn1955553pqquuSgcccEB+r4985CNp8eLFVdtF9ci8efPS7373u6olanWtJlmzZk0aO3Zs2meffVK7du3SmWeemf76179W22bu3Llp6NChqVu3bnmsBx98cBo/fnzauHFjte1efvnl9MlPfjJ16dIljzPGG4Hhm2++WW27mTNnpmOPPTbtvffeqVOnTnmb3//+9+8Y29SpU/N7xXbvfe9782dTn1auXJkry+IzjuM65JBDcogZQVCla665Jh1//PH5HMVYYux33XVXtW3inMc8vOWWW6o+g5hnm+szFmJOxHY19xPLUG+//fY8J2Jc9913X53nTF3FMrh4rzi2G264IfXu3Tsvef3oRz+aP4tSqZQ/4/gM45g/8YlPpL/85S+1Lgl84IEHclVafOaxZDaqE2v67W9/m3+u4vOO93nf+96X52xt8/2OO+5IX//613OoGNv++7//e35t+NCHPlR1fmP7bZmf8XMSP6dRdRX7iX3He8TvkNrCsPh8YjlwHFf8bjnttNPy74yymCexZDY+h9gmPpf4War58wMA9UmlFADsYkv3IkwYNGjQNr3ub3/7W/rYxz6WTjjhhPyHefyBGmbPnp2Dms9//vM5hPjVr36Vrr/++vSHP/whP1cWf4hHABN/hE+cODG98cYb6Zxzzsl/xG/Nn//85/xHeTmA6Ny5c/rJT36SRo0alVatWvWOJXiTJk3KlV6XXHJJDnjij+gI0Z544on8/Ne+9rX8eIzxu9/9bn4sQre6iPfv0KFD/gN80aJFealjhFvlgKDcFD32d9FFF+WvP/vZz9I3vvGNPNbJkyfnbaKaJ87nunXr0gUXXJCDqQhR4vOJ8Kd9+/Z5uwjXLrvssjR8+PD0//7f/0uvvfZaPr8f+MAH0jPPPJPHEv7zP/8z/4EfYVCcjwg1Pv7xj+dQozJg3JINGzak119/vdpj5X5j8RkPHjw4jzHeJ0LIxx57LI0bNy4tX768Wn+u6667Lr93nPM4zghNIiSJY4swJNx22235eCI8GzNmTH4swpHtEec3gsj4bPbdd98c/mzrnKmrCL/imOIzi9Ap5lZ8Nh/+8IfzHPjKV76SA9D4jGL+1QzBIoiMpbOf+9zn0llnnZXD4Tg3EaSdfPLJeZsYe3yOcc4jII6fqwjv4pxGuPdP//RP1fYZgVJUR8X7xXyKoCxeF+HUV7/61XTYYYfl7cpf6zI/yyIwGjJkSA6Y4jjj/eMYjzzyyHTKKafkbSLMirAtKi8jMP3Sl76U3nrrrfTTn/40L5Etf64xb+K94+c+xhdLhP/jP/4jz+NHH300tWjRYrs+EwDYohIAsEt48803S/Gf5mHDhr3jub/+9a+l1157req2Zs2aqufOOuus/LpLL730Ha+r3K5s4sSJpSZNmpR+97vfVT02YMCAUteuXUsrV66seuyBBx7I+z3ooIOqvT4e++Y3v1l1f9SoUfm1r7/+erXtPvOZz5Tat29fNYaHH344v/awww4rrVu3rmq76667Lj/+3HPPVT02dOjQd7zvlkyfPj3v49hjjy2tX7++6vFvf/vb+fG5c+du8ZyMHTu29K53vav09ttv5/vPPPNMft3s2bM3+55Lly4tNWvWrHTVVVdVezyOo3nz5lWPx3j222+/fI4rj3vq1Kn5PQYPHrzV44tzEdvWvJU/h/Hjx5dat25deumll6q9LuZEjHHZsmWbPf4YX79+/Uof/vCHqz0e+4u5VVM8VttnE2Op+U/LuN+0adPSb37zm2qP13XObOl8xBwpe+WVV/J7de7cudocHjduXH68f//+pQ0bNlQ9fvrpp5datmxZ9XmX9xnb/uhHP6r2MxnjPProo6se+5d/+Ze83S9+8Yuqx956661Sr169Sj179ixt3Lix2nzv3bv3O44n5lU8F9vUVJf5GWLexD5uvfXWqsdifnXp0qX0yU9+suqxm2++OW/3ne985x373bRpU/4axxLb3H777dWev++++2p9HADqi+V7ALCLiEqIzVUFxVKdqCYp32KJUk1RDVVTLFUqi+VYUWkTVR6RF0QFRIhKmoULF+bKkHIFUIjKkKic2pLYz49+9KP0j//4j/n72H/5FpVGUfH061//utprohKjsq/OiSeemL9G9dCOiqqeyoqOOCex5PG///u/az0nUTESY40xROVLNJMP5fNw//3358drE8u6YslTVKhUHndUVfXp0yc9/PDDebunnnoqrVixIlffVB53LIOrPN9bE9VzUd1SeYvliSGq3uIYOnbsWG0sJ510Uq6UWbBgQa3HH5U28RnFa2t+TvUlKrgq59H2zJm6iqqmynNarjiMXlyVzfnj8aioisqySrFkrrLSqbwENH5WXn311fxYzKWoIIuqxLL4mY25F8sIYzldpfi5qjznW1OX+Vn5vpV9xmJ+xdgqf5biXEeFWlSP1VSuHoz5E+ctfuYrP49Y2hnvUZ7LAFDfLN8DgF1E9IIKq1evfsdzN910U/4DNZYO1dbsOv7grm2p3bJly/LSn3vuuecdvWHKvZFieVuIIKWmvn37bjEgiOVqsZwt+iXFrTYRyFSKpWWVIkgJdeldUw4GyuIP6co/4mseQ/xBHf1zIiwo+81vfpN7/MSyqHIQWPOc9OrVKy+f+s53vpOXhEUoEMuz4tyXQ49Y6hWhSm3nLZTDsc2d33g+eh/VVQQLETLVJsby7LPP5sBya59BLNO78sorcxAZy8nKavaDqi9xLnd0ztRVzblV/qxqLpEsP15zzsXS2ZrnIfowhZhDETjG51nb8try8rt4Pno9be74t6Yu87MsfuZrjjd+nmIulEXfqPg53tIVM2P+xL7322+/ev08AGBrhFIAsIuIP5QjQIk+LzWV/wiuDFcqRUPkmlfkiwqZqHyI3jrRZ+bd7353viJfVIdElU7NBtjbo7yPCGuiIqQ2Rx11VLX7zZo1q3W7v6/22rKazd+j50+5AXddRBgSlTtRAfOtb30r99OJps4RvMU5qjwn1157bd53NJ6OnlvRZyf6bf3yl7/MYUBsG4FA9EKq7Zjq2gerPsRY4rP+8pe/XOvz5WAlmqtHuBY9r+IqjnE+IxyL8/iDH/ygTu+1ufCqZiPusppVQtszZ+pqc3NrR+bcjtqWKqltmZ/1eVyx3wikIoCtzebCTgDYUUIpANiFRKPpadOm5YbksQxnRzz33HPppZdeyk2Yy8u8Qiz7qnTQQQdVVUvUFM3CtyT+WI0KrwgkNlfFsz02F3zUHHtcKaxSHENciawsqs5ieWJclTBEs+to4h5L7yKYKYumzrWJhtFxi8qVaBz+/ve/P02ZMiVXGkVgEH/8RyVMOfSpTeX5jYbblY3L43379++fdlSMJY51a59BLOWKkCOWJUaQWRahVF0/g6jEifCkpnJF2NbsrDlTH6IJenymlcceP0OhfMXB+Dxr+7koL60rf95bsrlzu63zs65zIy4iEPNtc83KY5sHH3wwz+9tCdEAYEfpKQUAu5CodImrqZ177rl5qd6OVECUqygqXxPfx9XXKkW1zIABA3J4Vbk8KAKgmv1xanuPuGpfhB21VXjFUq3tERVdNZcqhQgxKm81K6diOVj88V0WV9+LKxOWr0RW2zmJ3kJRNVQplk3F6ypFOBXVaOUlb3HFs9jfFVdc8Y7PJe5HuBAGDhyYg5gIs+K9yuJKZ7WFO9sj+lo9/vjjOWyqKd6jfCwx3ghEKquaovruxz/+ca2fQW3jiwAjPpvKJWIR/M2ZM6dOY91Zc6Y+/OlPf6p2HDEPbr311vzzEUv3QgScERrH+a7s1xZzL4KrrfVhK5/bUPP81nV+bos419EfKq6kV1P5fWL+xJyIKwXWFHOnvuYpANSkUgoAdiHRdyiWUZ1++um5D8zIkSNzJU388RjVEvFcBCO19Y+qKZbrRYAQl6KPJXuxJCiCgNp6N8WytKjSiubNEYjFkr/rr78+VyLV1uOq0qRJk3Ij5FhiOHr06PxHebw+lhxF9UV8v62iwfIPf/jD3NfpPe95T14KF42xtyb+gP/IRz6S/8iOapb4Yz6OKZashWjyHpU+sWwsluNFQHPbbbe9I1SKfj7nn39+bpwdVVDxh3lsVw5UQpzbqJgaN25cDnaGDRuWK4Dic4pgIxpfx7mP6pTYbuzYsblSasSIEXmbqE7alp5SW/Kv//qvuW/YqaeempccxvmLoCSq5e666648vuhJFZ9x9MkaMmRI+uxnP5t7BUXT/OilVBkylT+D+Pxi+2gAHhVh8Rl/5jOfyUvJoiF4nMNowB3hX5ynujYo3xlzpj7EMYwaNSo9+eSTaf/9908333xzDocrK8kuvfTSNGvWrBx0xvF36tQpB7rxmcbPV81ltLWJkCvm0tVXX50Dvqhai7lR1/m5LaJKMoK1+FmKMC36o8XciPN83nnnpU984hN5yWDMz/g9EL3GPvrRj+Z5G9V90QQ9guxPfepT2z0GANiseruOHwBQbxYvXlz6/Oc/XzrkkENKe+21V2nvvfcuvfvd7y597nOfKy1cuLDatmeddVapdevWte7n+eefL5100kmlNm3alPbdd9/S6NGjS//zP/+TL/M+ffr0atv+6Ec/Kh122GGlVq1alQ4//PDS3Xffnfd90EEHVdsuXvvNb36z2mN//vOfS1/4whdKPXr0KLVo0SJflv4jH/lIaerUqVXbPPzww/m1s2fPrvbaV1555R3jWb16demzn/1sqUOHDvm5mmOoKV4b2/385z8vjRkzptSxY8d8zCNHjiy98cYb1bZ99NFHS+973/vyOe3WrVvpy1/+cun+++/Pr48xht/+9relc889t3TwwQfn89+pU6fShz70odKDDz74jveO83bCCSfkzyBu8TnFuVi0aFG17W688cZSr1698vkdOHBgacGCBaXBgwfn29bE8Q8dOnSL27z11lulcePG5TnTsmXL/Hkff/zxpWuuuaa0fv36qu3+8z//s9SnT588jhhrnLv4PGv+s/DFF18sfeADH8jnKZ6LuVD2wAMPlPr165ffp2/fvqWZM2fWuo+4H+eiNnWZM3U9H+U5NHny5GrbbW7OlefLk08++Y59xlw46qijqs5PzdeGJUuWlD71qU/l+Rnz473vfW/p3nvvrdN7l33/+98v9e7du9SsWbNqc68u8zPEvDniiCPesd/afmbXrFlT+trXvpbnX/lcx/jjOCrFuT/22GPze7dt27Z05JFH5vf/05/+VOsxAMCOahL/s/nICgAA9nyx9C6umhdXJwQAiqGnFAAAAACFE0oBAAAAUDihFAAAAACF01MKAAAAgMKplAIAAACgcEIpAAAAAArXvPi33PNt2rQp/elPf0pt27ZNTZo0aejhAAAAABQmOkW99dZbqVu3bqlp083XQwmldoIIpHr06NHQwwAAAABoML///e/TAQccsNnnhVI7QVRIlU9+u3btGno4AAAAAIVZtWpVLtYp5yObI5TaCcpL9iKQEkoBAAAAjVGTrbQ00ugcAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAIB36HnpvHwDANhZhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAA7NqhVKlUSmPGjEmdOnVKTZo0SQsXLtx5IwMAAABgj7VNodR9992XZsyYke699960fPny1K9fvx0ewNlnn52GDRuWdhXPPvtsOvHEE9Nee+2VevTokb797W839JAAAAAA9jjNt2XjJUuWpK5du6bjjz8+7Wo2btyYq7eaNt3+FYmrVq1KH/3oR9NJJ52UpkyZkp577rl07rnnpg4dOuQKMQAAAADqR9NtqWi64IIL0rJly3L407Nnz7Rp06Y0ceLE1KtXr7T33nun/v37p7vuuqtaUDRq1Kiq5/v27Zuuu+66qucvv/zydMstt6S5c+fmfcZt/vz5+Rbfr1y5smrbWCoYjy1dujTfj4qtCIvuueeedPjhh6dWrVrlsa1bty5dcsklqXv37ql169Zp0KBBeX91cfvtt6f169enm2++OR1xxBHpM5/5TPriF7+YvvOd79T1NAEAAABQn5VSESYdfPDBaerUqenJJ59MzZo1y4HUzJkzc1VRnz590oIFC9IZZ5yROnfunAYPHpxDqwMOOCDNnj077bPPPumxxx7LFUdRbTV8+PAcHr3wwgu5Qmn69On5faJfVWxXF2vWrElXX311mjZtWt7/fvvtl84///z0/PPPpzvuuCN169YtzZkzJw0ZMiRXPcUYt+Txxx9PH/jAB1LLli2rHvvYxz6W3+Ovf/1r6tixY62viyAsbmVxPAAAAADUQyjVvn371LZt2xxGdenSJYcwEyZMSA8++GA67rjj8ja9e/dOjzzySLrppptyKNWiRYt0xRVXVO0jKqYi+LnzzjtzKNWmTZtcQRX7in1uqw0bNqQbb7wxV2iFqJSKcCu+RiAVIviKXljxeIx3S1599dU8xkr7779/1XObC6UinKs8TgAAAADqsadUpcWLF+dKpZNPPrna47H87eijj666f8MNN+TlcBEUrV27Nj8/YMCAVB+ioumoo46quh/VULFk8NBDD622XYReUUm1s4wbNy5ddNFF1Sqlokk6AAAAAPUcSq1evTp/nTdvXu7fVCn6O4VYQheVStdee22upopKq8mTJ6cnnnhii/suNysvlUrVqqJqiiqr6DNVOaao5Hr66afz10pRlbU1Ua315z//udpj5ftbquSK4y0fMwAAAAA7MZSqbC4eS/Vq8+ijj+Yr9Z133nnVruBXs9opqpsqRU+qsHz58qolc9HofGuiQiv2tWLFinTiiSdu8zFFcPa1r30tB2Cx9DD89Kc/zQ3aN7d0DwAAAICdePW9mqLqKaqgLrzwwnwFvQibfv3rX6frr78+3w/RWPypp55K999/f3rppZfSZZddlpukV4qr+D377LNp0aJF6fXXX8+B0CGHHJKXv8XV+V5++eVcjRXVVlsTy/ZGjhyZzjzzzHT33XenV155Jf3qV7/KPZ9iH1vz2c9+NodkccXA3/zmN+mHP/xhbvBeuTQPAAAAgAYMpcL48eNz0BShz2GHHZavchfhT7lZ+NixY9Npp52WRowYkQYNGpTeeOONalVTYfTo0bkSaeDAgblCKqqrokpp1qxZ6cUXX8w9o+Lqd1deeWWdxhQNzSOUuvjii/N+hw0bloOwAw88sE7N3B944IEcZh177LF5H9/4xjfyFQMBAAAAqD9NSpWNm6gX0eg8Aq4333wztWvXrqGHAwCwzXpe+vcq86WThjb0UACAPTQX2aFKKQAAAADYHo0qlDrllFPyVfhqu02YMKGhhwcAAADQaGz31fd2R9OmTUtr166t9blOnToVPh4AAACAxqpRhVLdu3dv6CEAAAAA0NiW7wEAAACwaxBKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFC45sW/JQAAu7qlk4Y29BAAgD2cSikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwzYt/SwCAxqPnpfPS7mzppKENPQQAYA+lUgoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAANi1Q6lSqZTGjBmTOnXqlJo0aZIWLly480YGAAAAwB5rm0Kp++67L82YMSPde++9afny5alfv347PICzzz47DRs2LO0KLr/88hy21by1bt26oYcGAAAAsEdpvi0bL1myJHXt2jUdf/zxaVezcePGHCA1bbr9KxIvueSS9LnPfa7aYx/5yEfSe97znnoYIQAAAABlTbeloumCCy5Iy5Yty+FPz54906ZNm9LEiRNTr1690t5775369++f7rrrrmpB0ahRo6qe79u3b7ruuuuqVSbdcsstae7cuVVVSfPnz8+3+H7lypVV28ZSwXhs6dKl+X5UbHXo0CHdc8896fDDD0+tWrXKY1u3bl0Ol7p3754rnAYNGpT3Vxdt2rRJXbp0qbr9+c9/Ts8//3w+BgAAAAAaoFIqwqSDDz44TZ06NT355JOpWbNmOZCaOXNmmjJlSurTp09asGBBOuOMM1Lnzp3T4MGDc2h1wAEHpNmzZ6d99tknPfbYY7knVVRbDR8+PIdHL7zwQlq1alWaPn16fp/oVxXb1cWaNWvS1VdfnaZNm5b3v99++6Xzzz8/B0l33HFH6tatW5ozZ04aMmRIeu655/IYt0Xs99BDD00nnnjiNr0OAAAAgHoKpdq3b5/atm2bw6ioIoqKpAkTJqQHH3wwHXfccXmb3r17p0ceeSTddNNNOZRq0aJFuuKKK6r2ERVTjz/+eLrzzjtzKBWVSVFBFfuKfW6rDRs2pBtvvDFXaIWolIpwK75GIBUi+IpeWPF4jLeu3n777XT77benSy+9dKvbxvjjVhYhGwAAAAD11FOq0uLFi3Ol0sknn1zt8fXr16ejjz666v4NN9yQbr755hwUrV27Nj8/YMCAVB9atmyZjjrqqKr7UQ0VSwajuqlSBEZRSbUtosLqrbfeSmedddZWt42KscrwDQAAAICdFEqtXr06f503b17u31Qp+juFWEIXlUrXXnttrqaKSqvJkyenJ554Yov7LjcrL5VK1aqiaooqq+gzVTmmqOR6+umn89dKUZW1rUv3Tj311LT//vtvddtx48aliy66qFqlVI8ePbbp/QAAAAAak+0OpSqbi8dSvdo8+uij+Up95513XrUr+NWsdorqpkrRkyosX748dezYsarR+dZEhVbsa8WKFTvUB+qVV15JDz/8cG6iXhdxHspBHAAAAAA7MZSKqqeogrrwwgtzQ/MTTjghvfnmmzmIateuXV72Fo3Fb7311nT//ffnflK33XZbbpIe35fFVfzi+UWLFuUldtG76pBDDsmVRnF1vquuuiq99NJLudpqa2LZ3siRI9OZZ56Zt4+Q6rXXXksPPfRQXuY3dOjQOh1bLDeMZuynnHLK9p4eAAAAALbg7+vkttP48ePTZZddlnsqHXbYYfkqd7Gcrxw6jR07Np122mlpxIgRadCgQemNN96oVjUVRo8enfr27ZsGDhyYK6Qi1IoG6bNmzUovvvhiDpPiCntXXnllncYUDc0jlLr44ovzfocNG5aDsAMPPLBOr4+AbcaMGenss89+xxJAAAAAAOpHk1Jl4ybqRfSUioqvqByLqjEAoPHqeem8tDtbOqluleYAANuai+xQpRQAAAAAbI9GFUpFj6i4Cl9ttwkTJjT08AAAAAAaje1udL47mjZtWlq7dm2tz3Xq1Knw8QAAAAA0Vo0qlOrevXtDDwEAAACAxrZ8DwAAAIBdg1AKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMI1L/4tAQAaj6WThjb0EAAAdkkqpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAoXPPi3xIAYPfU89J5qbFZOmloQw8BANhDqZQCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAB27VCqVCqlMWPGpE6dOqUmTZqkhQsX7ryRAQAAALDH2qZQ6r777kszZsxI9957b1q+fHnq16/fDg/g7LPPTsOGDUu7gvnz56dPfOITqWvXrql169ZpwIAB6fbbb2/oYQEAAADscZpvy8ZLlizJgc3xxx+fdjUbN27M1VtNm27/isTHHnssHXXUUekrX/lK2n///XP4duaZZ6b27dunU089tV7HCwAAANCYNd2WiqYLLrggLVu2LIc/PXv2TJs2bUoTJ05MvXr1SnvvvXfq379/uuuuu6oFRaNGjap6vm/fvum6666rev7yyy9Pt9xyS5o7d27eZ9yiWilu8f3KlSurto2lgvHY0qVL8/2o2OrQoUO655570uGHH55atWqVx7Zu3bp0ySWXpO7du+dqp0GDBuX91cVXv/rVNH78+By6HXzwwelLX/pSGjJkSLr77rvrepoAAAAAqM9KqQiTIqiZOnVqevLJJ1OzZs1yIDVz5sw0ZcqU1KdPn7RgwYJ0xhlnpM6dO6fBgwfn0OqAAw5Is2fPTvvss0+uRIqeVFFtNXz48BwevfDCC2nVqlVp+vTp+X2iX1VsVxdr1qxJV199dZo2bVre/3777ZfOP//89Pzzz6c77rgjdevWLc2ZMycHS88991we47Z6880302GHHbbNrwMAAACgHkKpWMLWtm3bHEZ16dIlVyRNmDAhPfjgg+m4447L2/Tu3Ts98sgj6aabbsqhVIsWLdIVV1xRtY+omHr88cfTnXfemUOpNm3a5Aqq2Ffsc1tt2LAh3XjjjblCK0SlVIRb8TUCqRDBV/TCisdjvNsixhkBXBzPlsT441YWIRsAAAAA9dRTqtLixYtzpdLJJ59c7fH169eno48+uur+DTfckG6++eYcFK1duzY/Hw3E60PLli1zD6iyqIaKJYOHHnpote0iMIpKqm3x8MMPp3POOSd9//vfT0ccccQWt42KscrwDQAAAICdFEqtXr06f503b17u31Qp+juFWEIXlUrXXnttrqaKSqvJkyenJ554Yov7LjcrL5VK1aqiaooqq+gzVTmmqOR6+umn89dKUZVVVz//+c/TP/7jP6bvfve7udH51owbNy5ddNFF1SqlevToUef3AwAAAGhstjuUqmwuHkv1avPoo4/mpuHnnXdetSv41ax2iuqmStGTKixfvjx17NixqtH51kSFVuxrxYoV6cQTT9yu44qm6HGlvehVFf2v6iLOQzmIAwAAAGAnhlJR9RRVUBdeeGFuaH7CCSfkpuARRLVr1y6dddZZubH4rbfemu6///7cT+q2227LPZri+7K4il88v2jRorzELnpXHXLIIbnSKK7Od9VVV6WXXnopV1ttTSzbGzlyZK5uiu0jpHrttdfSQw89lJf5DR06dKtL9iKQiqvuffKTn0yvvvpqVXAWDdgBAAAAqB9/Xye3ncaPH58uu+yy3FMprlAXV7mL5Xzl0Gns2LHptNNOSyNGjEiDBg1Kb7zxRrWqqTB69OjUt2/fNHDgwFwhFaFWNEifNWtWevHFF3OYFFVLV155ZZ3GFA3NI5S6+OKL836HDRuWg7ADDzxwq6+95ZZbcp+sOJ64QmD5FscAAAAAQP1pUqps3ES9iJ5SUfEVlWNRNQYA7Bl6XjovNTZLJ2250hwAYHtzkR2qlAIAAACA7dGoQqlTTjklX4WvttuECRMaengAAAAAjcZ2NzrfHU2bNi2tXbu21uc0MgcAAAAoTqMKpbp3797QQwAAAACgsS3fAwAAAGDXIJQCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHDNG3oAAAC7i6WThjb0EAAA9hgqpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAoXPPi3xIAYNfX89J5DT2EXcLSSUMbeggAwB5KpRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAALBrh1KlUimNGTMmderUKTVp0iQtXLhw540MAAAAgD3WNoVS9913X5oxY0a699570/Lly1O/fv12eABnn312GjZsWNoVLF26NIdtNW+//OUvG3poAAAAAHuU5tuy8ZIlS1LXrl3T8ccfn3Y1GzduzAFS06Y7viLxwQcfTEcccUTV/X322WeH9wkAAADA/6/ptlQ0XXDBBWnZsmU5/OnZs2fatGlTmjhxYurVq1fae++9U//+/dNdd91VLSgaNWpU1fN9+/ZN1113XdXzl19+ebrlllvS3Llzq6qS5s+fn2/x/cqVK6u2jaWC8VhUM4Wo2OrQoUO655570uGHH55atWqVx7Zu3bp0ySWXpO7du6fWrVunQYMG5f1tiwihunTpUnVr0aLFNr0eAAAAgHqqlIow6eCDD05Tp05NTz75ZGrWrFkOpGbOnJmmTJmS+vTpkxYsWJDOOOOM1Llz5zR48OAcWh1wwAFp9uzZOeh57LHHck+qqLYaPnx4Do9eeOGFtGrVqjR9+vT8PtGvKrarizVr1qSrr746TZs2Le9/v/32S+eff356/vnn0x133JG6deuW5syZk4YMGZKee+65PMa6+PjHP57efvvtdOihh6Yvf/nL+f6WRBAWt7I4HgAAAADqIZRq3759atu2bQ6jonooQpgJEybkpW7HHXdc3qZ3797pkUceSTfddFMOpaLC6IorrqjaR1RMPf744+nOO+/MoVSbNm1yBVXsK/a5rTZs2JBuvPHGXKEVolIqwq34GoFUiOAremHF4zHeLYnxXHvtten9739/Xgb4ox/9KPe7+vGPf7zFYCrCucrjBAAAAKAee0pVWrx4ca5UOvnkk6s9vn79+nT00UdX3b/hhhvSzTffnIOitWvX5ucHDBiQ6kPLli3TUUcdVXU/qqFiyWBUOFWK0KsufaH23XffdNFFF1Xdf8973pP+9Kc/pcmTJ28xlBo3bly110WlVI8ePbbjiAAAAAAah+0OpVavXp2/zps3L/dvqhT9nUIsoYtKpag+imqqqLSKgOeJJ57Y4r7LzcpLpVK1qqiaosoq+kxVjikquZ5++un8tWYV1PaInlQ//elPt7hNHG/5mAEAAADYiaFUZXPxWKpXm0cffTRfqe+8886rdgW/mtVOUd1UKXpSheXLl6eOHTtWNTrfmqjQin2tWLEinXjiiak+xPtGDywAAAAAdoFQKqqeogrqwgsvzA3NTzjhhPTmm2/mIKpdu3bprLPOyo3Fb7311nT//ffnflK33XZbbpIe35fFVfzi+UWLFuUldtG76pBDDsnL3+LqfFdddVV66aWXcrXV1sSyvZEjR6Yzzzwzbx8h1WuvvZYeeuihvMxv6NChW3x9XAkwQrLy8sO77747Lz2MRuoAAAAA1J+/r5PbTuPHj0+XXXZZbvR92GGH5avcxXK+cug0duzYdNppp6URI0bkZXBvvPFGtaqpMHr06NS3b980cODAXCEVoVY0SJ81a1Z68cUXc5gUV9i78sor6zSmaGgeodTFF1+c9xuNyiMIO/DAA+t8TMcee2we79y5c9MPf/jDdM4552zH2QEAAABgc5qUKhs3US+i0XlUfEXlWFSNAQC7n56XzmvoIewSlk7acqU5AMD25iI7VCkFAAAAANujUYVSp5xySr4KX223CRMmNPTwAAAAABqN7W50vjuKhuVr166t9blOnToVPh4AAACAxqpRhVLdu3dv6CEAAAAA0NiW7wEAAACwaxBKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFC45sW/JQDArm/ppKENPQQAgD2aSikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwzYt/SwAAdhc9L53X0EPY5S2dNLShhwAAuyWVUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAADs2qFUqVRKY8aMSZ06dUpNmjRJCxcu3HkjAwAAAGCPtU2h1H333ZdmzJiR7r333rR8+fLUr1+/HR7A2WefnYYNG5Z2Fffff3963/vel9q2bZs6d+6cPvnJT6alS5c29LAAAAAAGm8otWTJktS1a9d0/PHHpy5duqTmzZunXcXGjRvTpk2bdmgfr7zySvrEJz6RPvzhD+cqsAioXn/99XTaaafV2zgBAAAA2IZQKiqaLrjggrRs2bK8dK9nz545BJo4cWLq1atX2nvvvVP//v3TXXfdVS0oGjVqVNXzffv2Tdddd13V85dffnm65ZZb0ty5c/M+4zZ//vx8i+9XrlxZtW2ERPFYuWopKrY6dOiQ7rnnnnT44YenVq1a5bGtW7cuXXLJJal79+6pdevWadCgQXl/dfH000/nMV955ZXp4IMPTsccc0zeV7z3hg0b6nqqAAAAANiKOpc6RZgUQc3UqVPTk08+mZo1a5YDqZkzZ6YpU6akPn36pAULFqQzzjgjL3sbPHhwDq0OOOCANHv27LTPPvukxx57LPekimqr4cOH58DnhRdeSKtWrUrTp0/P7xP9qmK7ulizZk26+uqr07Rp0/L+99tvv3T++een559/Pt1xxx2pW7duac6cOWnIkCHpueeey2PckmOPPTY1bdo0jyVCuNWrV6fbbrstnXTSSalFixabfV0EYXEri+MBAAAAoB5Cqfbt2+c+SxFGxdK9CGEmTJiQHnzwwXTcccflbXr37p0eeeSRdNNNN+VQKoKcK664omofUTH1+OOPpzvvvDOHUm3atMkVVLGv2Oe2iuqlG2+8MVdohaiUikApvkYgFSL4il5Y8XiMd0tifA888EAe29ixY3PVVBzbf//3f2/xdRHOVR4nAAAAAPXYU6rS4sWLc6XSySefnMOl8u3WW2/NvafKbrjhhlyBFNVT8XxUWkVoVB9atmyZjjrqqKr7UQ0VQdKhhx5abUw///nPq41pc1599dU0evTodNZZZ+VqsHhdvMenPvWpfOXBzRk3blx68803q26///3v6+X4AAAAAPZU292pPJa2hXnz5uX+TZWiv1OIJXRRqXTttdfmiqOotJo8eXJ64okntrjvWEIXKoOg2no6RZVV9JmqHFNUckVvqPhaKcKprYkALSrCvv3tb1c9FssTe/TokcccV+WrTRxv+ZgBAAAA2ImhVGVz8ViqV5tHH300X6nvvPPOq3qsZsVSVCJFdVOlqKoKy5cvTx07dszfR7PxrTn66KPzvlasWJFOPPHEbT6mqPwqB2Jl5XBrR6/sBwAAAEA9LN+LqqeogrrwwgvzFfQibPr1r3+drr/++nw/RGPxp556Kt1///3ppZdeSpdddlleFlcpruL37LPPpkWLFqXXX389V0QdcsghuToprs738ssv52qsqLbamli2N3LkyHTmmWemu+++O73yyivpV7/6Ve75FPvYmqFDh+bxfetb38rvG8dzzjnnpIMOOigHXgAAAAA0cCgVxo8fn4OmCH0OO+ywfJW7CH+iYXiIZuGnnXZaGjFiRBo0aFB64403qlVNhejh1Ldv3zRw4MBcIRXVVdEgfdasWenFF1/MPaPiCntXXnllncYUDc0jlLr44ovzfocNG5aDpgMPPHCrr/3whz+cfvCDH6Qf//jHOYSK44lqsGiUHksFAQAAAKgfTUpb6uDNdlm1alXuTRVNz9u1a9fQwwEA2G49L916tXljt3TS0IYeAgDslrnIDlVKAQAAAMD2aFSh1CmnnJKvwlfbbcKECQ09PAAAAIBGY7uvvrc7mjZtWlq7dm2tz3Xq1Knw8QAAAAA0Vo0qlOrevXtDDwEAAACAxrZ8DwAAAIBdg1AKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMI1L/4tAQDYXSydNLShhwAA7KFUSgEAAABQOKEUAAAAAIUTSgEAAABQOKEUAAAAAIUTSgEAAABQOKEUAAAAAIUTSgEAAABQOKEUAAAAAIVrXvxbAgA0rJ6XzmvoIew2lk4a2tBDAAD2UCqlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAANi1Q6lSqZTGjBmTOnXqlJo0aZIWLly480YGAAAAwB5rm0Kp++67L82YMSPde++9afny5alfv347PICzzz47DRs2LO1qFi9enNq2bZs6dOjQ0EMBAAAAaNyh1JIlS1LXrl3T8ccfn7p06ZKaN2+edhUbN25MmzZtqpd9bdiwIZ1++unpxBNPrJf9AQAAALCdoVRUNF1wwQVp2bJleelez549cwg0ceLE1KtXr7T33nun/v37p7vuuqtaUDRq1Kiq5/v27Zuuu+66qucvv/zydMstt6S5c+fmfcZt/vz5+Rbfr1y5smrbWCoYjy1dujTfj4qtqGK655570uGHH55atWqVx7Zu3bp0ySWXpO7du6fWrVunQYMG5f1ti69//evp3e9+dxo+fPg2vQ4AAACAuqlzqVOESQcffHCaOnVqevLJJ1OzZs1yIDVz5sw0ZcqU1KdPn7RgwYJ0xhlnpM6dO6fBgwfn0OqAAw5Is2fPTvvss0967LHHck+qqLaKwCfCoxdeeCGtWrUqTZ8+Pb9P9KuK7epizZo16eqrr07Tpk3L+99vv/3S+eefn55//vl0xx13pG7duqU5c+akIUOGpOeeey6PcWt+9rOf5fFGCHb33XfXaRwRhMWtLI4HAAAAgHoIpdq3b597LEUYFUv3IoSZMGFCevDBB9Nxxx2Xt+ndu3d65JFH0k033ZRDqRYtWqQrrriiah9RMfX444+nO++8M4dSbdq0yRVUsa/Y5/Yss7vxxhtzhVaISqkIt+JrBFIhgq/ohRWPx3i35I033sgVYRG0tWvXrs7jiHCu8jgBAAAA2LLmO9IIPCqVTj755GqPr1+/Ph199NFV92+44YZ0880356Bo7dq1+fkBAwak+tCyZct01FFHVd2PaqhYMnjooYdW2y5Cr6ik2prRo0enz372s+kDH/jANo1j3Lhx6aKLLqpWKdWjR49t2gcAAABAY7LdodTq1avz13nz5uX+TZWiv1OIJXRRqXTttdfmaqqotJo8eXJ64okntrjvpk3/3uqqVCpVq4qqKaqsos9U5Ziikuvpp5/OXytFVVZdlu5Fj6prrrmm6v1jCWI0dI9li+eee26tr4vjLR8zAAAAADsxlKpsLh5L9Wrz6KOP5iv1nXfeedWu4Fez2imqmypFT6qwfPny1LFjx/x99HjamqjQin2tWLFiu66cF0sLK8cSDdijZ1X0uKoZvAEAAADQAKFUVD1FFdSFF16Yq4lOOOGE9Oabb+YgKvoxnXXWWbmx+K233pruv//+3E/qtttuy03S4/uyuIpfPL9o0aK8xC56Vx1yyCF5+Vtcne+qq65KL730Uq622ppYtjdy5Mh05pln5u0jpHrttdfSQw89lJf5DR06dIuvP+yww6rdf+qpp3LVVr9+/bb3NAEAAABQi7+vk9tO48ePT5dddllu9B2BTlzlLpbzlUOnsWPHptNOOy2NGDEiDRo0KDcSr6yaKvdx6tu3bxo4cGCukIpQKxqkz5o1K7344os5TIpqpSuvvLJOY4qG5hFKXXzxxXm/w4YNy0HYgQceuCOHCgAAAEA9alKqbNxEvYhG51HxFZVj23IVPwCgGD0vndfQQ9htLJ205UpzAIDtzUV2qFIKAAAAALZHowqlTjnllHwVvtpuEyZMaOjhAQAAADQa293ofHc0bdq0tHbt2lqf69SpU+HjAQAAAGisGlUo1b1794YeAgAAAACNbfkeAAAAALsGoRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhWte/FsCADSspZOGNvQQAAAaPZVSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4ZoX/5YAsHk9L53X0EMAKiydNLShhwAA7KFUSgEAAABQOKEUAAAAAIUTSgEAAABQOKEUAAAAAIUTSgEAAABQOKEUAAAAAIUTSgEAAABQOKEUAAAAAIUTSgEAAABQOKEUAAAAAIUTSgEAAABQOKEUAAAAALt2KFUqldKYMWNSp06dUpMmTdLChQt33sgAAAAA2GNtUyh13333pRkzZqR77703LV++PPXr12+HB3D22WenYcOGpV1FBG/XXHNNOvTQQ1OrVq1S9+7d01VXXdXQwwIAAADYozTflo2XLFmSunbtmo4//vi0q9m4cWOu3mradMdWJH7pS19KDzzwQA6mjjzyyPSXv/wl3wAAAACoP023paLpggsuSMuWLcvhT8+ePdOmTZvSxIkTU69evdLee++d+vfvn+66665qQdGoUaOqnu/bt2+67rrrqp6//PLL0y233JLmzp2b9xm3+fPn51t8v3LlyqptY6lgPLZ06dJ8Pyq2OnTokO655550+OGH56qmGNu6devSJZdckiucWrdunQYNGpT3VxcvvPBC+t73vpfH8/GPfzyP+9hjj00nn3xyXU8TAAAAAPVZKRVh0sEHH5ymTp2annzyydSsWbMcSM2cOTNNmTIl9enTJy1YsCCdccYZqXPnzmnw4ME5tDrggAPS7Nmz0z777JMee+yx3JMqqq2GDx+ew6MIglatWpWmT5+e3yf6VcV2dbFmzZp09dVXp2nTpuX977fffun8889Pzz//fLrjjjtSt27d0pw5c9KQIUPSc889l8e4Jf/1X/+VevfunZcnxmtiKd9JJ52Uvv3tb+dxAQAAAFBwKNW+ffvUtm3bHEZ16dIlVyRNmDAhPfjgg+m4447L20Sg88gjj6Sbbroph1ItWrRIV1xxRdU+ovLo8ccfT3feeWcOpdq0aZMrqGJfsc9ttWHDhnTjjTfmCq0QlVIRbsXXCKRCBF/RCysej/FuyW9/+9v0u9/9Lodot956a670uvDCC9OnPvWp9LOf/Wyzr4vxx60sQjYAAAAA6qmnVKXFixfnSqWaS9vWr1+fjj766Kr7N9xwQ7r55ptzULR27dr8/IABA1J9aNmyZTrqqKOq7kc1VARJ0aS8UgRGUUm1NVHZFdtGIFXex3/+53/mJXyLFi3Kyw9rExVjleEbAAAAADsplFq9enX+Om/evNy/qVL0dwqxhC4qla699tpcTRWVVpMnT05PPPHEFvddblYey+cqq6Jqiiqr6DNVOaao5Hr66afz10pRlbU1saywefPm1UKtww47LH+NUG1zodS4cePSRRddVK1SqkePHlt9PwAAAIDGartDqcrm4rFUrzaPPvpovlLfeeedV+0KfjWrnaK6qVL0pArLly9PHTt2rGp0vjVRoRX7WrFiRTrxxBO3+Zje//73p7/97W95jNE/K7z00kv560EHHbTZ18V5KAdxAAAAANTj1fdqiqqnqIKKnktxBb0Icn7961+n66+/Pt8P0Vj8qaeeSvfff38Ody677LLcJL1SXMXv2WefzcvjXn/99VwRdcghh+RKo7g638svv5yrsaLaamuiwmnkyJHpzDPPTHfffXd65ZVX0q9+9au8vC72sTXR1PyYY45J5557bnrmmWdyxdXYsWPzEsWaSwIBAAAAaIBQKowfPz4HTRH6xDK3uGJdhD/R0DxEoHPaaaelESNGpEGDBqU33nijWtVUGD16dF4WN3DgwFwhFdVV0SB91qxZ6cUXX8w9o+IKe1deeWWdxhQNzSOUuvjii/N+hw0bloOwAw88cKuvjWWDcQW+fffdN33gAx9IQ4cOzccVyxABAAAAqD9NSpWNm6gX0VMqrlb45ptvpnbt2jX0cAB2Kz0v3XplK1CcpZOGNvQQAIA9NBfZoUopAAAAANgejSqUOuWUU/JV+Gq7TZgwoaGHBwAAANBobPfV93ZH06ZNS2vXrq31uU6dOhU+HgAAAIDGqlGFUt27d2/oIQAAAADQ2JbvAQAAALBrEEoBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAULjmxb8lAGze0klDG3oIAABAAVRKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFC45sW/JQAAu4uel85r6CEA0EgsnTS0oYdAwVRKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAu3YoVSqV0pgxY1KnTp1SkyZN0sKFC3feyAAAAADYY21TKHXfffelGTNmpHvvvTctX7489evXb4cHcPbZZ6dhw4alXcWdd96ZBgwYkN71rnelgw46KE2ePLmhhwQAAACwx2m+LRsvWbIkde3aNR1//PFpV7Nx48ZcvdW06favSPzJT36SRo4cma6//vr00Y9+NL3wwgtp9OjRae+9907nn39+vY4XAAAAoDFrui0VTRdccEFatmxZDn969uyZNm3alCZOnJh69eqVg5v+/funu+66q1pQNGrUqKrn+/btm6677rqq5y+//PJ0yy23pLlz5+Z9xm3+/Pn5Ft+vXLmyattYKhiPLV26NN+Piq0OHTqke+65Jx1++OGpVatWeWzr1q1Ll1xySerevXtq3bp1GjRoUN5fXdx22225autzn/tc6t27dxo6dGgaN25cuvrqq/PSRQAAAAAKrpSKMOnggw9OU6dOTU8++WRq1qxZDqRmzpyZpkyZkvr06ZMWLFiQzjjjjNS5c+c0ePDgHFodcMABafbs2WmfffZJjz32WO5JFdVWw4cPz+FRVCOtWrUqTZ8+Pb9P9KuK7epizZo1OTCaNm1a3v9+++2XK5qef/75dMcdd6Ru3bqlOXPmpCFDhqTnnnsuj3FLItCKZXuVIkz7wx/+kH73u9/lIA4AAACAAkOp9u3bp7Zt2+YwqkuXLjnAmTBhQnrwwQfTcccdl7eJ6qJHHnkk3XTTTTmUatGiRbriiiuq9hEVU48//nju2xShVJs2bXLoE/uKfW6rDRs2pBtvvDFXaIWolIpwK75GIBUi+IpeWPF4jHdLPvaxj6ULL7wwV4V96EMfSosXL07XXnttfi56aG0ulIrxx60sQjYAAAAA6qmnVKUIbKJS6eSTT672+Pr169PRRx9ddf+GG25IN998cw6K1q5dm5+PRuL1oWXLlumoo46quh/VULFk8NBDD622XQRGUUm1NdE/KvpmnXrqqTnwateuXfrSl76UlxluqVdVVIxVhm8AAAAA7KRQavXq1fnrvHnzcv+mStHfKcQSuqhUimqjqKaKSqu4mt0TTzyxxX2XA6DKPk4REtUUVVbRZ6pyTFHJ9fTTT+evlaIqa2tiX7EcMCqqXn311bwM8aGHHqqqAtuc6Dt10UUXVauU6tGjx1bfDwAAAKCx2u5QqrK5eCzVq82jjz6ar9R33nnnVT0WlUg1q52iuqlShEHlJXMdO3asanS+NVGhFftasWJFOvHEE9P2ikCrHLTNmjUrB2rlMdUmzkM5iAMAAABgJ4ZSUfUUVVDRgykamp9wwgnpzTffzEFULHs766yzcmPxW2+9Nd1///25n1Rc3S6apMf3ZdGnKZ5ftGhRXmIXvasOOeSQXGkUy+auuuqq9NJLL1X1dtqSWLY3cuTIdOaZZ+btI6R67bXXcrVTLPOLq+ltyeuvv56vHvjBD34wvf3227kPVTRp//nPf769pwkAAACAWmy+UVIdjB8/Pl122WW5p9Jhhx2Wr3IXy/nKodPYsWPTaaedlkaMGJEGDRqU3njjjWpVU+U+Tn379k0DBw7M1UgRakWD9KhQevHFF3OYFEvqrrzyyjqNKYKkCKUuvvjivN9hw4blIOzAAw+s0+tvueWWPJb3v//96Te/+U2aP39+eu9737sdZwcAAACAzWlSqmzcRL2InlJR8RWVY1E1BgCwu+p56byGHgIAjcTSSVte3cSel4vsUKUUAAAAAGyPRhVKnXLKKfkqfLXd4op7AAAAAOzijc53R9OmTUtr166t9blOnToVPh4AAACAxqpRhVLdu3dv6CEAAAAA0NiW7wEAAACwaxBKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFA4oRQAAAAAhRNKAQAAAFC45sW/JQAAu4ulk4Y29BAAgD2USikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACte8+LcEAGB30fPSeQ09BABoVJZOGpoaC5VSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAADArh1KlUqlNGbMmNSpU6fUpEmTtHDhwp03MgAAAAD2WNsUSt13331pxowZ6d57703Lly9P/fr12+EBnH322WnYsGFpV7Bo0aL0oQ99KO2///5pr732Sr17905f//rX04YNGxp6aAAAAAB7lObbsvGSJUtS165d0/HHH592NRs3bszVW02bbv+KxBYtWqQzzzwzHXPMMalDhw7pf/7nf9Lo0aPTpk2b0oQJE+p1vAAAAACNWdNtqWi64IIL0rJly3L407NnzxzWTJw4MfXq1SvtvffeqX///umuu+6qFhSNGjWq6vm+ffum6667rur5yy+/PN1yyy1p7ty5eZ9xmz9/fr7F9ytXrqzaNpYKxmNLly7N96NiK4Kje+65Jx1++OGpVatWeWzr1q1Ll1xySerevXtq3bp1GjRoUN5fXURl1DnnnJOP46CDDkof//jH08iRI9MvfvGLup4mAAAAAOqzUirCpIMPPjhNnTo1Pfnkk6lZs2Y5kJo5c2aaMmVK6tOnT1qwYEE644wzUufOndPgwYNzaHXAAQek2bNnp3322Sc99thjuSdVVFsNHz48h0cvvPBCWrVqVZo+fXp+n+hXFdvVxZo1a9LVV1+dpk2blve/3377pfPPPz89//zz6Y477kjdunVLc+bMSUOGDEnPPfdcHuO2WLx4cV6yeNppp21xuwjC4lYWxwMAAABAPYRS7du3T23bts1hVJcuXXIIE0vaHnzwwXTcccdVVRo98sgj6aabbsqhVCyHu+KKK6r2ERVTjz/+eLrzzjtzKNWmTZtcQRX7in1uq+j1dOONN+bKphCVUhFuxdcIpEIEXxEsxeN1XYIXyxN//etf53FFiPatb31ri9tHOFd5nAAAAADUY0+pmlVEUal08sknV3t8/fr16eijj666f8MNN6Sbb745B0Vr167Nzw8YMCDVh5YtW6ajjjqq6n5UQ8WSwUMPPbTadhEuRSVVXf3whz9Mb731Vu4p9a//+q/pmmuuSV/+8pc3u/24cePSRRddVK1SqkePHtt8PAAAAACNxXaHUqtXr85f582bl/s3VYr+TiGW0EWl0rXXXpurqaLSavLkyemJJ57Y4r7LzcpLpVLVY7VdAS+qrKLPVOWYopLr6aefzl8rRVVWXZUDpehVFSFXVEtdfPHF79hn5fGWjxkAAACAnRhKVTYXj6V6tXn00UfzUrjzzjuv2hX8alY7RfBTKXpSheXLl6eOHTtWNTrfmqjQin2tWLEinXjiiak+RF+sCMTi6+ZCKQAAAAAKCqWi6imqoC688MIc2JxwwgnpzTffzEFUu3bt0llnnZUbi996663p/vvvz/2kbrvtttwkPb4vi6v4xfOLFi3KS+yid9UhhxySq5Xi6nxXXXVVeumll3K11dbEsr24Wt6ZZ56Zt4+Q6rXXXksPPfRQXuY3dOjQLb7+9ttvz32wjjzyyBy4PfXUU3lp3ogRI/LjAAAAADRwKBXGjx+fq5qi0fdvf/vb1KFDh3TMMcekr371q/n5sWPHpmeeeSaHOrHM7vTTT89VUz/5yU+q9jF69Og0f/78NHDgwLz87uGHH04f/OAH06xZs9LnP//5HCa95z3vSVdeeWX69Kc/vdUxRUPz2DaW2/3xj39M++67b3rf+96XTj311K2fjObN89X8IgSLpYMHHXRQvppfBG8AAAAA1J8mpcrGTdSLaHQeFV9RORZVYwAAu6uel85r6CEAQKOydNKWV3ntSbnI3zuKAwAAAECBGlUodcopp+Sr8NV2mzBhQkMPDwAAAKDR2KGeUrubadOmpbVr19b6XKdOnQofDwAAAEBj1ahCqe7duzf0EAAAAABobMv3AAAAANg1CKUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKFzz4t8SAIDdxdJJQxt6CADAHkqlFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAULjmxb8lu5Oel85r6CEAAA1o6aShDT0EAGAPpVIKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgF07lCqVSmnMmDGpU6dOqUmTJmnhwoU7b2QAAAAA7LG2KZS677770owZM9K9996bli9fnvr167fDAzj77LPTsGHD0q7g7bffzuM58sgjU/PmzXeZcQEAAADsaZpvy8ZLlixJXbt2Tccff3za1WzcuDFXbzVt2nSH9rH33nunL37xi+lHP/pRvY4PAAAAgP9fnROcqCC64IIL0rJly3L407Nnz7Rp06Y0ceLE1KtXrxzm9O/fP911113VQp5Ro0ZVPd+3b9903XXXVT1/+eWXp1tuuSXNnTs37zNu8+fPz7f4fuXKlVXbxlLBeGzp0qX5flRsdejQId1zzz3p8MMPT61atcpjW7duXbrkkktS9+7dU+vWrdOgQYPy/uoitv/e976XRo8enbp06VLXUwMAAADAzqqUijDp4IMPTlOnTk1PPvlkatasWQ6kZs6cmaZMmZL69OmTFixYkM4444zUuXPnNHjw4BxaHXDAAWn27Nlpn332SY899ljuSRXVVsOHD8/h0QsvvJBWrVqVpk+fnt8n+lXFdnWxZs2adPXVV6dp06bl/e+3337p/PPPT88//3y64447Urdu3dKcOXPSkCFD0nPPPZfHuDNEEBa3sjgeAAAAAOohlGrfvn1q27ZtDqOiiihCmAkTJqQHH3wwHXfccXmb3r17p0ceeSTddNNNOZRq0aJFuuKKK6r2ERVTjz/+eLrzzjtzKNWmTZtcQRX72p7KpA0bNqQbb7wxV2iFqJSKcCu+RiAVIviKXljxeIx3Z4hwrvI4AQAAAKjHnlKVFi9enCuVTj755GqPr1+/Ph199NFV92+44YZ0880356Bo7dq1+fkBAwak+tCyZct01FFHVd2PaqhYMnjooYdW2y5Cr6ik2lnGjRuXLrroomqVUj169Nhp7wcAAADQaEOp1atX56/z5s3L/ZsqRX+nEEvoolLp2muvzdVUUWk1efLk9MQTT2xx3+Vm5aVSqVpVVE1RZRV9pirHFJVcTz/9dP5aKaqydpY43vIxAwAAALATQ6nK5uKxVK82jz76aL5S33nnnVftCn41q52iuqlS9KQKy5cvTx07dqxqdL41UaEV+1qxYkU68cQTt+u4AAAAANiFQ6moeooqqAsvvDA3ND/hhBPSm2++mYOodu3apbPOOis3Fr/11lvT/fffn/tJ3XbbbblJenxfFlfxi+cXLVqUl9hF76pDDjkkL3+Lq/NdddVV6aWXXsrVVlsTy/ZGjhyZzjzzzLx9hFSvvfZaeuihh/Iyv6FDh251H9EkPZYY/uUvf0lvvfVWVRhWX0sOAQAAANiBUCqMHz8+VzVFo+/f/va3qUOHDumYY45JX/3qV/PzY8eOTc8880waMWJEXmZ3+umn56qpn/zkJ1X7GD16dJo/f34aOHBgXn738MMPpw9+8INp1qxZ6fOf/3wOk97znvekK6+8Mn3605/e6piioXlse/HFF6c//vGPad99903ve9/70qmnnlqnY/qHf/iH9Lvf/a7qfrk/VuVSQgAAAAB2TJOStKXeRaPzqPiKyrGoGtud9bx0XkMPAQBoQEsnbb3SHABge3KRv3cUBwAAAIACNapQ6pRTTslX4avtNmHChIYeHgAAAECjsUM9pXY306ZNS2vXrq31uU6dOhU+HgAAAIDGqlGFUt27d2/oIQAAAADQ2JbvAQAAALBrEEoBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAULjmxb8lu5Olk4Y29BAAAACAPZBKKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAK17z4t9zzlUql/HXVqlUNPRQAAACAQpXzkHI+sjlCqZ3grbfeyl979OjR0EMBAAAAaLB8pH379pt9vklpa7EV22zTpk3pT3/6U2rbtm1q0qRJQw+n0aayEQr+/ve/T+3atWvo4bCHM98okvlGkcw3imKuUSTzjSI11vlWKpVyINWtW7fUtOnmO0eplNoJ4oQfcMABDT0MUso/9I3pB5+GZb5RJPONIplvFMVco0jmG0VqjPOt/RYqpMo0OgcAAACgcEIpAAAAAAonlGKP1KpVq/TNb34zf4WdzXyjSOYbRTLfKIq5RpHMN4pkvm2ZRucAAAAAFE6lFAAAAACFE0oBAAAAUDihFAAAAACFE0qxW/rLX/6SRo4cmdq1a5c6dOiQRo0alVavXr3F10ydOjV98IMfzK9p0qRJWrly5Tu26dmzZ36u8jZp0qSdeCQ05vm2Pftlz7c98+Ltt99OX/jCF9I+++yT2rRpkz75yU+mP//5z9W2qfm7LW533HHHTj4adjU33HBD/m/dXnvtlQYNGpR+9atfbXH72bNnp3e/+915+yOPPDL993//d7XnozXpN77xjdS1a9e09957p5NOOim9/PLLO/koaKzz7eyzz37H77EhQ4bs5KNgT5xvv/nNb/J/K8v/9v+3f/u3Hd4njUt9z7fLL7/8Hb/f4vdhYyCUYrcUf7DFD/dPf/rTdO+996YFCxakMWPGbPE1a9asyf9w+epXv7rF7b71rW+l5cuXV90uuOCCeh49u5udNd+2Z7/s+bZnXlx44YXpv/7rv/IfdD//+c/Tn/70p3Taaae9Y7vp06dX+/02bNiwnXgk7Gp++MMfposuuihfAejXv/516t+/f/rYxz6WVqxYUev2jz32WDr99NNzMPrMM8/k+RK3//3f/63a5tvf/nb693//9zRlypT0xBNPpNatW+d9RlBK47Yz5luI/7ZW/h6bNWtWQUfEnjTf4t9pvXv3zv/nc5cuXeplnzQeO2O+hSOOOKLa77dHHnkkNQpx9T3YnTz//PNxxcjSk08+WfXYT37yk1KTJk1Kf/zjH7f6+ocffji//q9//es7njvooINK3/3ud+t9zOy+dtZ829H9smfannmxcuXKUosWLUqzZ8+ueuyFF17I+3n88cerHov7c+bM2clHwK7sve99b+kLX/hC1f2NGzeWunXrVpo4cWKt2w8fPrw0dOjQao8NGjSoNHbs2Pz9pk2bSl26dClNnjy52nxs1apVadasWTvtOGic8y2cddZZpU984hM7cdQ0lvlWl3//78g+2bPtjPn2zW9+s9S/f/9SY6RSit3O448/npe0DBw4sOqxWC7QtGnT/P/S7qhIsGMJzNFHH50mT56c/va3v+3wPtl97az5trPnMbun7ZkXTz/9dNqwYUPerizKvQ888MC8v0qxxG/fffdN733ve9PNN9+cl17ROKxfvz7Plcp5EvMq7tecJ2XxeOX2If6f4PL2r7zySnr11VerbdO+ffu8jGFz+6Rx2BnzrWz+/Plpv/32S3379k2f//zn0xtvvLGTjoI9eb41xD7ZM+zMufHyyy+nbt265aqqqJxftmxZagyaN/QAYFvFP4DjHyOVmjdvnjp16pSf2xFf/OIX0zHHHJP3FWXk48aNy6WT3/nOd3Zw1OyudtZ825nzmN3X9syLeLxly5Y5zKq0//77V3tNLE3+8Ic/nN71rnelBx54IJ133nm5V1X83mPP9/rrr6eNGzfmeVEp7r/44ou1vibmT23bl+dV+euWtqFx2hnzrbx0L5Ym9+rVKy1ZsiQvkT/llFPyH4LNmjXbSUfDnjjfGmKf7Bl21twYNGhQmjFjRg7c4+/PK664Ip144ol5CXPbtm3TnkwoxS7j0ksvTVdfffUWt3nhhRd26hhibXDZUUcdlf/QGzt2bJo4cWJq1arVTn1vGt98o/HYFebbZZddVvV9VIL+3//9X64GFUoBu4vPfOYzVd9HI/T4t9rBBx+cq6c+8pGPNOjYAHbEKaecUvV9/G6LkOqggw5Kd955Z+61tycTSrHLuPjii/NVVbYkShmjOVzNJnKxxC6uWLWlxnHbI34ZxL6XLl2aU2v2HA0934qcx+zZ8y0ej1LyuMJjZbVUXH1vS3Mpfr+NHz8+rVu3TujeCMSyzagkqXlVxi3Nk3h8S9uXv8ZjcfW9ym0GDBiwE46CxjzfNvd7M95r8eLFQqlGbHvmW0Pskz1DUXOjQ4cO6dBDD82/3/Z0ekqxy+jcuXPug7KlW1QuHXfccfmPr1jLW/azn/0sbdq0Kf+RVZ8WLlyY1wjXXE7D7q+h51uR85g9e74de+yxqUWLFumhhx6qemzRokW5D0Hsb0u/3zp27CiQaiRifsVcqZwnMa/i/ubmSTxeuX2Iq0KWt48lVPEP8MptVq1alfufbWnusefbGfOtNn/4wx9yT6nKUJTGZ3vmW0Pskz1DUXNj9erVeZlyo/j91tCd1mF7DBkypHT00UeXnnjiidIjjzxS6tOnT+n000+vev4Pf/hDqW/fvvn5suXLl5eeeeaZ0ve///18FaoFCxbk+2+88UZ+/rHHHstXQli4cGFpyZIlpZkzZ5Y6d+5cOvPMMxvkGNmz51td9kvjtD3z7XOf+1zpwAMPLP3sZz8rPfXUU6Xjjjsu38ruueeePBefe+650ssvv1y68cYbS+9617tK3/jGNwo/PhrOHXfcka+MN2PGjHylxzFjxpQ6dOhQevXVV/Pz//zP/1y69NJLq7Z/9NFHS82bNy9dc801+YqOcWWguNJjzKOySZMm5X3MnTu39Oyzz+Yro/Xq1au0du3aBjlG9tz59tZbb5UuueSSfFXRV155pfTggw+WjjnmmPw78u23326w42T3nG/r1q3L/y6LW9euXfPciu/jv5F13SeN186YbxdffHFp/vz5+fdb/D486aSTSvvuu29pxYoVpT2dUIrdUvxhH3+ktWnTptSuXbvSOeeck/+xUhY/zBEEPPzww1WPxT9u4rGat+nTp+fnn3766Xzp4fbt25f22muv0mGHHVaaMGGCf+iwU+ZbXfZL47Q98y0CgPPOO6/UsWPHHDb90z/9Uw5Gy37yk5+UBgwYkPfZunXrfMnhKVOm5EsY07hcf/31OcBs2bJlvqT1L3/5y6rnBg8eXDrrrLOqbX/nnXeWDj300Lz9EUccUZo3b1615zdt2lS67LLLSvvvv3/+B/pHPvKR0qJFiwo7HhrPfFuzZk3pox/9aP4/DCOsisuqjx49WkDAds238n9La95iu7ruk8atvufbiBEjcmAV++vevXu+v3jx4lJj0CT+p6GrtQAAAABoXPSUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgDYAWeffXYaNmxY1f0PfvCD6V/+5V8adEy7mssvvzwNGDBgp+x7xowZqUOHDjtl3wDAziWUAgD2GK+++mr60pe+lA455JC01157pf333z+9//3vT9/73vfSmjVrChnD3XffncaPH79Tg68tbdekSZP0uc997h3PfeELX8jPxTZFu+SSS9JDDz20zccDAOzZmjf0AAAA6sNvf/vbHEBF1cyECRPSkUcemVq1apWee+65NHXq1NS9e/f08Y9/vNbXbtiwIbVo0aJextGpU6fUkHr06JHuuOOO9N3vfjftvffe+bG33347/eAHP0gHHnhgg4ypTZs2+QYAUEmlFACwRzjvvPNS8+bN01NPPZWGDx+eDjvssNS7d+/0iU98Is2bNy/94z/+Y9W2UTEU1VMRUrVu3TpdddVVaePGjWnUqFGpV69eOczp27dvuu6666q9R2xz0UUX5eBrn332SV/+8pdTqVSqtk3N5Xvr1q3LlUIRisV7DRo0KM2fP/8dy8/uv//+POYIb4YMGZKWL19etfTtlltuSXPnzs3jjlvl62s65phjcjAVFVtl8X0EUkcffXS1be+77750wgknVB3PqaeempYsWVJtm8ceeywvvYvKs4EDB6Yf//jHeQwLFy7Mz8dY4n5UQsXz73rXu9Lxxx+fFi1aVOvyvc0dT3k/K1eurHpdvEc8tnTp0mrnK44l3uef/umf0htvvPGOcxD7jvMQY445cMUVV6S//e1vmz1nAEDDEEoBALu9CCYeeOCBvEQtgp/aRLhRKcKRCDWikurcc89NmzZtSgcccECaPXt2ev7559M3vvGN9NWvfjXdeeedVa+59tprcyhy8803p0ceeST95S9/SXPmzNni2M4///z0+OOP5+qlZ599Nn3605/OodPLL79ctU0sLbzmmmvSbbfdlhYsWJCWLVuWg6wQXyNkKwdVcYvQZ0vieKZPn151P8Z7zjnnvGO7//u//8shWwR5ESo1bdo0n5M4F2HVqlU5zIuqs1//+td5WeJXvvKVWt/za1/7Wj4/sa8IB2MMtdme4yl74okncnAY5zQCqw996EPpyiuvrLbNL37xi3TmmWfmZZzxOd500035M4vgEQDYtVi+BwDs9hYvXpwrlqK6qdK+++6bl66FCKyuvvrqquc++9nPviOoiYqasqiYijApQqkIUcK//du/pXHjxqXTTjst358yZUqucNqcCJciHIqv3bp1qwplokIpHo9lhuXlg7Gvgw8+ON+P0OVb3/pW/j4qp6JyKyquunTpUqfzccYZZ+Rx/u53v8v3H3300RyK1ayw+uQnP1ntfoRXnTt3zmFOv3798pK/CPO+//3v56qjww8/PP3xj39Mo0ePfsd7RugzePDg/P2ll16ahg4dms99vK7S9hxPWVSuRZgVFWrh0EMPzZVccT4rP8N4/7POOivfj0qpCNPiNd/85je36f0AgJ1LKAUA7LF+9atf5aqfkSNH5hCkUiw1q+mGG27IwUyESGvXrk3r16+vWnb25ptv5qqeWH5XFhVBsZ+aS/jKogorlvxFeFIpxhLL5cpiKVo5kApdu3ZNK1as2O7jjmApQqGoEIqxxfcR0NUU1VpRERYVSK+//npVhVQcf4RSsQTvqKOOqhYsvfe97631PWO7yvGHOIb67GP1wgsv5EquSscdd1y1UOp//ud/cghXWRkVn0EEZFGRFucaANg1CKUAgN1eXG0vKnoq+xiVq2RCueF3pZrL/KKSKKqYYglaBB1t27ZNkydPzoHN9lq9enVq1qxZevrpp/PXSpWNv2s2WY9j2VzQVVexfC4qrsphW21iad5BBx2UK6GikitCqQijIozbVpXHUF4qWQ656iKWDobK444Ksu0551EtVa5mq1SzagsAaFhCKQBgtxdVRyeffHL6j//4j3TBBRdstq/UlkR1TfQ2iobpZZVNv9u3b58rgCKk+sAHPpAfi+bZEThFU+3aRGPxqNKJiqETTzwxba+WLVvm/WyLWOYW4VIERB/72Mdq7cMVIV4EUuWxRZ+sSrEccubMmbmyK65kGJ588sm0o2o7nqjuClGN1rFjx/x9uZl6WTSCrxkS/vKXv6x2Pz6LOK4IKgGAXZtG5wDAHuHGG2/MIVEsp/vhD3+Yl3pFOBGhyosvvviOSqWa+vTpk5t0R4+ol156KV122WXvCGCiefakSZPyFehinxFgVV4trqZYthdLB6PxdlwB75VXXslLCidOnJivCFhXPXv2zE3S43himV1dKojieOMcRH+o2o49gp8I86ZOnZp7cv3sZz/LTc8rRd+tqHYaM2ZM3lecm2jIXlvj+G1R2/FEiBRXDYwG9LGsMM5PVK1V+uIXv5iX6sUYYpsIISuX7oVYjnjrrbfmaqnf/OY3edxRBff1r399u8cLAOwcQikAYI8QPZmeeeaZdNJJJ+Um3/37988B1fXXX5+X5UWz6y0ZO3ZsXvI1YsSI3DcqKokqq6bCxRdfnP75n/85N9EuL/Gr2eOopmhoHqFUvDYqj4YNG5bDrm3ptRSNxeO1cTxRURRVXXXRrl27fNvccrkIa6LSK5bsXXjhhXm5Ys3X/9d//VeuWIreWnGFvQh9dnQpXG3HE8v/Zs2alcO+6E8VTelrXlnvfe97X67siobn8fnGFRdrhk1RFXbvvffm597znvfk13z3u9/NyxQBgF1Lk9KONiwAAKDRuP322/NVC6Pxe229ugAA6kpPKQAANiuWwkXD+O7du+cr233lK19Jw4cPF0gBADtMKAUAwGa9+uqreclefI1G75/+9KfTVVdd1dDDAgD2AJbvAQAAAFA4jc4BAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAASEX7/wAJFzj+yVeDCwAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 8: True: Real, Predicted: Real (0.5245)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME explanation failed: index 1 is out of bounds for axis 1 with size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP explanation failed: 'numpy.float64' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T10:08:31.453794Z",
     "start_time": "2025-04-22T10:08:31.357614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming you have feature_names stored somewhere\n",
    "try:\n",
    "    print(\"Model was trained on these features:\")\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        print(f\"{i+1}. {feature}\")\n",
    "except NameError:\n",
    "    print(\"Feature names not found in memory\")"
   ],
   "id": "e756e0660218992c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained on these features:\n",
      "1. feature_0\n",
      "2. feature_1\n",
      "3. feature_2\n",
      "4. feature_3\n",
      "5. feature_4\n",
      "6. feature_5\n",
      "7. feature_6\n",
      "8. feature_7\n",
      "9. feature_8\n",
      "10. feature_9\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:40:10.222129Z",
     "start_time": "2025-04-22T13:39:20.388523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "    sample = X_test[i]\n",
    "    pred = model.predict(sample[np.newaxis])[0][0]\n",
    "    pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "    true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "    print(f\"\\nSample {i}: True: {true_class}, Predicted: {pred_class} ({pred:.4f})\")\n",
    "\n",
    "    lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "    lime_exp.show_in_notebook()\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nTop contributing LIME features:\")\n",
    "    for feature, weight in lime_exp.as_list()[:5]:\n",
    "        print(f\"{feature}: {weight:.4f}\")\n"
   ],
   "id": "8221dcb7a6230d30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 9s/step\n",
      "\n",
      "Sample 5: True: Real, Predicted: Fake (0.4278)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      5\u001B[39m true_class = \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m y_test[i] == \u001B[32m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mSample \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: True: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrue_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Predicted: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m lime_exp = \u001B[43mexplain_with_lime\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m lime_exp.show_in_notebook()\n\u001B[32m     14\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mTop contributing LIME features:\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 25\u001B[39m, in \u001B[36mexplain_with_lime\u001B[39m\u001B[34m(model, X_train, X_sample, feature_names, class_names)\u001B[39m\n\u001B[32m     22\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m np.vstack([\u001B[32m1\u001B[39m-preds, preds]).T\n\u001B[32m     23\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m preds  \u001B[38;5;66;03m# Multi-class case\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m explanation = \u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_sample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpredict_fn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpredict_proba\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m explanation\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:452\u001B[39m, in \u001B[36mLimeTabularExplainer.explain_instance\u001B[39m\u001B[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001B[39m\n\u001B[32m    448\u001B[39m     labels = [\u001B[32m0\u001B[39m]\n\u001B[32m    449\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels:\n\u001B[32m    450\u001B[39m     (ret_exp.intercept[label],\n\u001B[32m    451\u001B[39m      ret_exp.local_exp[label],\n\u001B[32m--> \u001B[39m\u001B[32m452\u001B[39m      ret_exp.score, ret_exp.local_pred) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbase\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m            \u001B[49m\u001B[43mscaled_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m            \u001B[49m\u001B[43myss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    455\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    462\u001B[39m     ret_exp.intercept[\u001B[32m1\u001B[39m] = ret_exp.intercept[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_base.py:182\u001B[39m, in \u001B[36mLimeBase.explain_instance_with_data\u001B[39m\u001B[34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001B[39;00m\n\u001B[32m    146\u001B[39m \n\u001B[32m    147\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \u001B[33;03m    local_pred is the prediction of the explanation model on the original instance\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    181\u001B[39m weights = \u001B[38;5;28mself\u001B[39m.kernel_fn(distances)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m labels_column = \u001B[43mneighborhood_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    183\u001B[39m used_features = \u001B[38;5;28mself\u001B[39m.feature_selection(neighborhood_data,\n\u001B[32m    184\u001B[39m                                        labels_column,\n\u001B[32m    185\u001B[39m                                        weights,\n\u001B[32m    186\u001B[39m                                        num_features,\n\u001B[32m    187\u001B[39m                                        feature_selection)\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mIndexError\u001B[39m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "# Create the prediction function that LIME expects (should output probabilities)\n",
    "def predict_fn(X):\n",
    "    return model.predict(X)  # Ensure model returns probabilities (not class predictions)\n",
    "\n",
    "# Explain a random instance (can replace X_test[0] with any specific sample)\n",
    "sample = X_test[0].reshape(1, -1)\n",
    "\n",
    "# Create LIME explainer for tabular data\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train,\n",
    "    feature_names=feature_names,\n",
    "    class_names=['Fake', 'Real'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Explain the prediction for the given sample\n",
    "lime_exp = explainer.explain_instance(sample[0], predict_fn, num_features=10)\n",
    "\n",
    "# Show explanation in the notebook\n",
    "lime_exp.show_in_notebook()\n"
   ],
   "id": "4df7493c779ec5ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:25:36.085611Z",
     "start_time": "2025-04-22T09:25:36.015152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y, feature_names, scaler = load_dataset(data_path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "e4da345f69edbce7",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m X, y, feature_names, scaler = \u001B[43mload_dataset\u001B[49m(data_path)\n\u001B[32m      2\u001B[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001B[32m0.2\u001B[39m, random_state=\u001B[32m42\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:52:01.326251Z",
     "start_time": "2025-04-22T09:52:01.153786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lime\n",
    "from lime import lime_tabular\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your model is already loaded\n",
    "# model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "# X_scaled = np.load('X_scaled.npy')  # Data used for training\n",
    "# feature_names = np.load('feature_names.npy')  # Features used for training\n",
    "# y_labels = np.load('y_labels.npy')\n",
    "\n",
    "# Adjust model prediction for LIME\n",
    "def predict_fn_for_lime(X):\n",
    "    predictions = model.predict(X)\n",
    "    return np.column_stack([1 - predictions, predictions])  # [Fake, Real] probabilities\n",
    "\n",
    "# Initialize LimeTabularExplainer for model explanation\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_scaled,\n",
    "    feature_names=feature_names,  # No need for .tolist() here\n",
    "    class_names=['Fake', 'Real'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Choose a sample to explain\n",
    "sample = X_scaled[0]  # or any sample from X_scaled\n",
    "\n",
    "# Explain the instance with LIME\n",
    "lime_exp = explainer.explain_instance(sample, predict_fn_for_lime, num_features=10)\n",
    "\n",
    "# Show LIME explanation\n",
    "lime_exp.show_in_notebook()  # This will render the explanation in a Jupyter Notebook\n",
    "\n",
    "# Optionally save LIME explanation as HTML\n",
    "lime_exp.as_html()\n",
    "with open(\"lime_explanation.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lime_exp.as_html())\n",
    "\n",
    "# Open in a web browser\n",
    "import webbrowser\n",
    "webbrowser.open(\"lime_explanation.html\")\n"
   ],
   "id": "f80a60e9f5464342",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     20\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m np.column_stack([\u001B[32m1\u001B[39m - predictions, predictions])  \u001B[38;5;66;03m# [Fake, Real] probabilities\u001B[39;00m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# Initialize LimeTabularExplainer for model explanation\u001B[39;00m\n\u001B[32m     23\u001B[39m explainer = lime_tabular.LimeTabularExplainer(\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m     training_data=\u001B[43mX_scaled\u001B[49m,\n\u001B[32m     25\u001B[39m     feature_names=feature_names,  \u001B[38;5;66;03m# No need for .tolist() here\u001B[39;00m\n\u001B[32m     26\u001B[39m     class_names=[\u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     27\u001B[39m     mode=\u001B[33m'\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     28\u001B[39m )\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# Choose a sample to explain\u001B[39;00m\n\u001B[32m     31\u001B[39m sample = X_scaled[\u001B[32m0\u001B[39m]  \u001B[38;5;66;03m# or any sample from X_scaled\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:14:17.537081Z",
     "start_time": "2025-04-22T09:14:11.493656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from lime import lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume you already have these:\n",
    "# X_scaled: scaled features (numpy array)\n",
    "# model: your trained Keras or PyTorch model\n",
    "# feature_names: list of feature names\n",
    "\n",
    "# Predict function wrapper for LIME (output: [Fake, Real])\n",
    "def predict_fn_for_lime(input_data):\n",
    "    predictions = model.predict(input_data)\n",
    "    return np.column_stack([1 - predictions, predictions])\n",
    "\n",
    "# Initialize LimeTabularExplainer\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_scaled,\n",
    "    feature_names=feature_names,\n",
    "    class_names=['Fake', 'Real'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Explain the first sample\n",
    "sample = X_scaled[0]\n",
    "lime_exp = explainer.explain_instance(sample, predict_fn_for_lime, num_features=10)\n",
    "\n",
    "# Display explanation in notebook or save to HTML\n",
    "lime_exp.show_in_notebook()  # If Jupyter works\n",
    "# with open(\"lime_explanation.html\", \"w\") as f:\n",
    "#     f.write(lime_exp.as_html())\n"
   ],
   "id": "9ca6f2eb0d6a27f2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     13\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m np.column_stack([\u001B[32m1\u001B[39m - predictions, predictions])\n\u001B[32m     15\u001B[39m \u001B[38;5;66;03m# Initialize LimeTabularExplainer\u001B[39;00m\n\u001B[32m     16\u001B[39m explainer = lime_tabular.LimeTabularExplainer(\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     training_data=\u001B[43mX_scaled\u001B[49m,\n\u001B[32m     18\u001B[39m     feature_names=feature_names,\n\u001B[32m     19\u001B[39m     class_names=[\u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     20\u001B[39m     mode=\u001B[33m'\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     21\u001B[39m )\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Explain the first sample\u001B[39;00m\n\u001B[32m     24\u001B[39m sample = X_scaled[\u001B[32m0\u001B[39m]\n",
      "\u001B[31mNameError\u001B[39m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:36:02.035566Z",
     "start_time": "2025-04-22T08:35:53.076239Z"
    }
   },
   "cell_type": "code",
   "source": "!pip show ipython\n",
   "id": "29d0d96743342db9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ipython\n",
      "Version: 9.1.0\n",
      "Summary: IPython: Productive Interactive Computing\n",
      "Home-page: https://ipython.org\n",
      "Author: The IPython Development Team\n",
      "Author-email: ipython-dev@python.org\n",
      "License: BSD-3-Clause\n",
      "Location: C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\n",
      "Requires: colorama, decorator, ipython-pygments-lexers, jedi, matplotlib-inline, prompt_toolkit, pygments, stack_data, traitlets, typing_extensions\n",
      "Required-by: ipykernel\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:36:20.585309Z",
     "start_time": "2025-04-22T08:36:20.456782Z"
    }
   },
   "cell_type": "code",
   "source": "!python --version\n",
   "id": "b256c78d04ed719a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.6\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:14:02.474402Z",
     "start_time": "2025-04-22T09:11:45.711517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip uninstall ipython\n",
    "!pip install ipython\n"
   ],
   "id": "c0b7ce6d85eb372c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: ipython in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (9.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (4.13.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from stack_data->ipython) (0.2.3)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:31:48.026320Z",
     "start_time": "2025-04-22T08:31:48.019049Z"
    }
   },
   "cell_type": "code",
   "source": "from IPython.display import display\n",
   "id": "504fa04dbdc0be20",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:29:04.032835Z",
     "start_time": "2025-04-22T08:28:53.819394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lime\n",
    "from lime import lime_tabular\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your model is already loaded\n",
    "# model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "# X_scaled = np.load('X_scaled.npy')  # Data used for training\n",
    "# feature_names = np.load('feature_names.npy')  # Features used for training\n",
    "# y_labels = np.load('y_labels.npy')\n",
    "\n",
    "# Adjust model prediction for LIME\n",
    "def predict_fn_for_lime(X):\n",
    "    predictions = model.predict(X)\n",
    "    return np.column_stack([1 - predictions, predictions])  # [Fake, Real] probabilities\n",
    "\n",
    "# Initialize LimeTabularExplainer for model explanation\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_scaled,\n",
    "    feature_names=feature_names,  # No need for .tolist() here\n",
    "    class_names=['Fake', 'Real'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Choose a sample to explain\n",
    "sample = X_scaled[0]  # or any sample from X_scaled\n",
    "\n",
    "# Explain the instance with LIME\n",
    "lime_exp = explainer.explain_instance(sample, predict_fn_for_lime, num_features=10)\n",
    "\n",
    "# Show LIME explanation\n",
    "lime_exp.show_in_notebook()  # This will render the explanation in a Jupyter Notebook\n",
    "\n",
    "# Optionally save LIME explanation as HTML\n",
    "lime_exp.as_html()\n",
    "with open(\"lime_explanation.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lime_exp.as_html())\n",
    "\n",
    "# Open in a web browser\n",
    "import webbrowser\n",
    "webbrowser.open(\"lime_explanation.html\")\n"
   ],
   "id": "4ba91c0385251d66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\IPython\\core\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 33\u001B[39m\n\u001B[32m     30\u001B[39m lime_exp = explainer.explain_instance(sample, predict_fn_for_lime, num_features=\u001B[32m10\u001B[39m)\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Show LIME explanation\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m \u001B[43mlime_exp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshow_in_notebook\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# This will render the explanation in a Jupyter Notebook\u001B[39;00m\n\u001B[32m     35\u001B[39m \u001B[38;5;66;03m# Optionally save LIME explanation as HTML\u001B[39;00m\n\u001B[32m     36\u001B[39m lime_exp.as_html()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\explanation.py:194\u001B[39m, in \u001B[36mExplanation.show_in_notebook\u001B[39m\u001B[34m(self, labels, predict_proba, show_predicted_value, **kwargs)\u001B[39m\n\u001B[32m    184\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mshow_in_notebook\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[32m    185\u001B[39m                      labels=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    186\u001B[39m                      predict_proba=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    187\u001B[39m                      show_predicted_value=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    188\u001B[39m                      **kwargs):\n\u001B[32m    189\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Shows html explanation in ipython notebook.\u001B[39;00m\n\u001B[32m    190\u001B[39m \n\u001B[32m    191\u001B[39m \u001B[33;03m    See as_html() for parameters.\u001B[39;00m\n\u001B[32m    192\u001B[39m \u001B[33;03m    This will throw an error if you don't have IPython installed\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m194\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mIPython\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcore\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdisplay\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m display, HTML\n\u001B[32m    195\u001B[39m     display(HTML(\u001B[38;5;28mself\u001B[39m.as_html(labels=labels,\n\u001B[32m    196\u001B[39m                               predict_proba=predict_proba,\n\u001B[32m    197\u001B[39m                               show_predicted_value=show_predicted_value,\n\u001B[32m    198\u001B[39m                               **kwargs)))\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'display' from 'IPython.core.display' (C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\IPython\\core\\display.py)"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T09:53:18.540288Z",
     "start_time": "2025-04-22T09:53:02.309841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "# Create the prediction function that LIME expects (should output probabilities)\n",
    "def predict_fn(X):\n",
    "    return model.predict(X)  # Ensure model returns probabilities (not class predictions)\n",
    "\n",
    "# Explain a random instance (can replace X_test[0] with any specific sample)\n",
    "sample = X_test[0].reshape(1, -1)\n",
    "\n",
    "# Create LIME explainer for tabular data\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train,\n",
    "    feature_names=feature_names,\n",
    "    class_names=['Fake', 'Real'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Explain the prediction for the given sample\n",
    "lime_exp = explainer.explain_instance(sample[0], predict_fn, num_features=10)\n",
    "\n",
    "# Show explanation in the notebook\n",
    "lime_exp.show_in_notebook()\n"
   ],
   "id": "3bb9b448c8c1a656",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 21\u001B[39m\n\u001B[32m     13\u001B[39m explainer = lime.lime_tabular.LimeTabularExplainer(\n\u001B[32m     14\u001B[39m     X_train,\n\u001B[32m     15\u001B[39m     feature_names=feature_names,\n\u001B[32m     16\u001B[39m     class_names=[\u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     17\u001B[39m     mode=\u001B[33m'\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     18\u001B[39m )\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# Explain the prediction for the given sample\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m lime_exp = \u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredict_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Show explanation in the notebook\u001B[39;00m\n\u001B[32m     24\u001B[39m lime_exp.show_in_notebook()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:452\u001B[39m, in \u001B[36mLimeTabularExplainer.explain_instance\u001B[39m\u001B[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001B[39m\n\u001B[32m    448\u001B[39m     labels = [\u001B[32m0\u001B[39m]\n\u001B[32m    449\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels:\n\u001B[32m    450\u001B[39m     (ret_exp.intercept[label],\n\u001B[32m    451\u001B[39m      ret_exp.local_exp[label],\n\u001B[32m--> \u001B[39m\u001B[32m452\u001B[39m      ret_exp.score, ret_exp.local_pred) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbase\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m            \u001B[49m\u001B[43mscaled_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m            \u001B[49m\u001B[43myss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    455\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    462\u001B[39m     ret_exp.intercept[\u001B[32m1\u001B[39m] = ret_exp.intercept[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_base.py:182\u001B[39m, in \u001B[36mLimeBase.explain_instance_with_data\u001B[39m\u001B[34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001B[39;00m\n\u001B[32m    146\u001B[39m \n\u001B[32m    147\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \u001B[33;03m    local_pred is the prediction of the explanation model on the original instance\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    181\u001B[39m weights = \u001B[38;5;28mself\u001B[39m.kernel_fn(distances)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m labels_column = \u001B[43mneighborhood_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    183\u001B[39m used_features = \u001B[38;5;28mself\u001B[39m.feature_selection(neighborhood_data,\n\u001B[32m    184\u001B[39m                                        labels_column,\n\u001B[32m    185\u001B[39m                                        weights,\n\u001B[32m    186\u001B[39m                                        num_features,\n\u001B[32m    187\u001B[39m                                        feature_selection)\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mIndexError\u001B[39m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:29:45.434008Z",
     "start_time": "2025-04-22T08:29:45.421859Z"
    }
   },
   "cell_type": "code",
   "source": "import IPython",
   "id": "86047eec90233540",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:22:45.999036Z",
     "start_time": "2025-04-22T08:22:27.068270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import webbrowser\n",
    "\n",
    "# =========================\n",
    "# 1. Define Feature Names\n",
    "# =========================\n",
    "def get_feature_names(n_mfcc=20, n_mels=128):\n",
    "    feature_names = []\n",
    "\n",
    "    # MFCC mean and std\n",
    "    feature_names += [f\"mfcc_{i+1}_mean\" for i in range(n_mfcc)]\n",
    "    feature_names += [f\"mfcc_{i+1}_std\" for i in range(n_mfcc)]\n",
    "\n",
    "    # Mel spectrogram mean and std\n",
    "    feature_names += [f\"mel_{i+1}_mean\" for i in range(n_mels)]\n",
    "    feature_names += [f\"mel_{i+1}_std\" for i in range(n_mels)]\n",
    "\n",
    "    # Spectral features\n",
    "    feature_names.append(\"spectral_centroid_mean\")\n",
    "    feature_names.append(\"spectral_bandwidth_mean\")\n",
    "    feature_names += [f\"spectral_contrast_{i+1}_mean\" for i in range(7)]\n",
    "    feature_names.append(\"spectral_rolloff_mean\")\n",
    "\n",
    "    # Chroma mean and std\n",
    "    feature_names += [f\"chroma_{i+1}_mean\" for i in range(12)]\n",
    "    feature_names += [f\"chroma_{i+1}_std\" for i in range(12)]\n",
    "\n",
    "    # Other features\n",
    "    feature_names.append(\"zcr_mean\")\n",
    "    feature_names.append(\"rms_mean\")\n",
    "    feature_names.append(\"harmonic_mean\")\n",
    "    feature_names.append(\"percussive_mean\")\n",
    "    feature_names.append(\"tempo\")\n",
    "\n",
    "    return feature_names\n",
    "\n",
    "# =========================\n",
    "# 2. Load Data and Model\n",
    "# =========================\n",
    "X_scaled = np.load('X_scaled.npy')\n",
    "y_labels = np.load('y_labels.npy')\n",
    "feature_names = get_feature_names()\n",
    "\n",
    "model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "\n",
    "# =========================\n",
    "# 3. Prediction Function for LIME\n",
    "# =========================\n",
    "def predict_fn_for_lime(X):\n",
    "    predictions = model.predict(X)\n",
    "    return np.column_stack([1 - predictions, predictions])  # [Fake, Real] probabilities\n",
    "\n",
    "# =========================\n",
    "# 4. LIME Explanation\n",
    "# =========================\n",
    "explainer = LimeTabularExplainer(\n",
    "    X_scaled,\n",
    "    feature_names=feature_names,\n",
    "    class_names=['Fake', 'Real'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "sample = X_scaled[0]\n",
    "lime_exp = explainer.explain_instance(sample, predict_fn_for_lime, num_features=10)\n",
    "\n",
    "# Save to HTML\n",
    "with open(\"lime_explanation.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lime_exp.as_html())\n",
    "webbrowser.open(\"lime_explanation.html\")\n",
    "\n",
    "# Optional: Print top features to console\n",
    "print(\"\\nTop 10 LIME features:\")\n",
    "for feature, weight in lime_exp.as_list():\n",
    "    print(f\"{feature}: {weight:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# 5. Grad-CAM-like Explanation\n",
    "# =========================\n",
    "def grad_cam_explanation(model, sample, feature_names):\n",
    "    with tf.GradientTape() as tape:\n",
    "        sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "        tape.watch(sample_tensor)\n",
    "        predictions = model(sample_tensor)\n",
    "\n",
    "    grads = tape.gradient(predictions, sample_tensor).numpy().flatten()\n",
    "    importance = np.abs(grads)\n",
    "    importance = importance / (importance.max() + 1e-10)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(feature_names, importance)\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Grad-CAM-like Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "grad_cam_explanation(model, sample, feature_names)\n",
    "\n",
    "# =========================\n",
    "# 6. Evaluate Model\n",
    "# =========================\n",
    "y_pred = model.predict(X_scaled)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_labels, y_pred_classes)\n",
    "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n"
   ],
   "id": "11aceab0f9fd4826",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step\n",
      "\n",
      "Top 10 LIME features:\n",
      "mel_119_mean <= -0.80: 0.1041\n",
      "mel_123_std <= -1.05: 0.0984\n",
      "mel_117_mean <= -0.80: 0.0869\n",
      "mel_127_std <= -1.04: 0.0854\n",
      "spectral_contrast_7_mean > 0.96: 0.0774\n",
      "mel_126_std <= -1.04: 0.0765\n",
      "mel_120_mean <= -0.80: 0.0755\n",
      "mel_125_std <= -1.04: 0.0698\n",
      "mel_57_mean <= -0.57: -0.0595\n",
      "-1.06 < mel_119_std <= -0.12: 0.0586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step\n",
      "\n",
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:24:18.153411Z",
     "start_time": "2025-04-22T07:24:12.912623Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install ipython",
   "id": "8a551de77fcae587",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (9.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from ipython) (4.13.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from stack_data->ipython) (0.2.3)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:24:32.337953Z",
     "start_time": "2025-04-22T07:24:32.202600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.save('X_scaled.npy', X)\n",
    "np.save('y_labels.npy', y)\n",
    "np.save('feature_names.npy', np.array(feature_names))\n"
   ],
   "id": "7644d4ad22e9616f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:26:27.640013Z",
     "start_time": "2025-04-22T07:26:05.744560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========================\n",
    "# Load Saved Data\n",
    "# ========================\n",
    "X = np.load('X_scaled.npy')\n",
    "y = np.load('y_labels.npy')\n",
    "feature_names = np.load('feature_names.npy', allow_pickle=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========================\n",
    "# Recreate the Model\n",
    "# ========================\n",
    "def create_tabular_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_shape,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_tabular_model(X_train.shape[1])\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ModelCheckpoint('best_tabular_model.h5', save_best_only=True)]\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=callbacks, verbose=1)\n",
    "model = models.load_model('best_tabular_model.h5')\n",
    "\n",
    "# ========================\n",
    "# Explanation Functions\n",
    "# ========================\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names):\n",
    "    explainer = lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names,\n",
    "                                                  class_names=['Fake', 'Real'], mode='classification')\n",
    "    explanation = explainer.explain_instance(X_sample, model.predict, num_features=10)\n",
    "\n",
    "    import webbrowser\n",
    "    html_path = \"lime_explanation.html\"\n",
    "    with open(html_path, \"w\") as f:\n",
    "        f.write(explanation.as_html())\n",
    "    webbrowser.open(html_path)\n",
    "    return explanation\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    explainer = shap.DeepExplainer(model, X_train[:100])\n",
    "    shap_values = explainer.shap_values(np.array([X_sample]))[0][0]\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    shap.bar_plot(shap_values, feature_names=feature_names)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    import tensorflow as tf\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "    grads = tape.gradient(pred, sample_tensor).numpy()[0]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.barh(feature_names, grads)\n",
    "    plt.xlabel(\"Gradient\")\n",
    "    plt.title(\"Grad-CAM Style Input Gradient Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ========================\n",
    "# Predict and Explain\n",
    "# ========================\n",
    "for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "    sample = X_test[i]\n",
    "    pred = model.predict(sample[np.newaxis])[0][0]\n",
    "    pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "    true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "    print(f\"\\nSample {i}: True: {true_class}, Predicted: {pred_class} ({pred:.4f})\")\n",
    "\n",
    "    lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "    explain_with_shap(model, X_train, sample, feature_names)\n",
    "    grad_cam_like_explanation(model, sample, feature_names)\n",
    "\n",
    "    print(\"\\nTop contributing LIME features:\")\n",
    "    for feature, weight in lime_exp.as_list()[:5]:\n",
    "        print(f\"{feature}: {weight:.4f}\")\n"
   ],
   "id": "5a908d18364701b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m71/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9018 - loss: 0.2334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 15ms/step - accuracy: 0.9037 - loss: 0.2297 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
      "Epoch 2/50\n",
      "\u001B[1m64/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9993 - loss: 0.0106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9994 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 3/50\n",
      "\u001B[1m54/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9997 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m71/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 2.7491e-04\n",
      "Epoch 5/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 3.3976e-04\n",
      "Epoch 6/50\n",
      "\u001B[1m55/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 1.3763e-04\n",
      "Epoch 7/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 2.3694e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m55/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 1.0339e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 4.2990e-04 - val_accuracy: 1.0000 - val_loss: 1.2037e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m64/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 3.8880e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 4.2496e-04 - val_accuracy: 1.0000 - val_loss: 8.4502e-05\n",
      "Epoch 11/50\n",
      "\u001B[1m59/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 2.7583e-05\n",
      "Epoch 12/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 6.6387e-04 - val_accuracy: 1.0000 - val_loss: 4.0475e-05\n",
      "Epoch 13/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 6.8660e-04 - val_accuracy: 1.0000 - val_loss: 4.1874e-05\n",
      "Epoch 14/50\n",
      "\u001B[1m69/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 3.4887e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.4420e-04 - val_accuracy: 1.0000 - val_loss: 2.0841e-05\n",
      "Epoch 15/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 1.1833e-04 - val_accuracy: 1.0000 - val_loss: 2.2038e-05\n",
      "Epoch 16/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 8.5797e-04 - val_accuracy: 1.0000 - val_loss: 4.4508e-05\n",
      "Epoch 17/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 5.8793e-04 - val_accuracy: 1.0000 - val_loss: 2.1586e-05\n",
      "Epoch 18/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 8.9019e-05 - val_accuracy: 1.0000 - val_loss: 2.8634e-05\n",
      "Epoch 19/50\n",
      "\u001B[1m72/72\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 7.1916e-05 - val_accuracy: 1.0000 - val_loss: 2.6320e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 151ms/step\n",
      "\n",
      "Sample 654: True: Fake, Predicted: Fake (0.0000)\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 93\u001B[39m\n\u001B[32m     89\u001B[39m true_class = \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m y_test[i] == \u001B[32m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     91\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mSample \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: True: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrue_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Predicted: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m lime_exp = \u001B[43mexplain_with_lime\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     94\u001B[39m explain_with_shap(model, X_train, sample, feature_names)\n\u001B[32m     95\u001B[39m grad_cam_like_explanation(model, sample, feature_names)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 50\u001B[39m, in \u001B[36mexplain_with_lime\u001B[39m\u001B[34m(model, X_train, X_sample, feature_names)\u001B[39m\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mexplain_with_lime\u001B[39m(model, X_train, X_sample, feature_names):\n\u001B[32m     48\u001B[39m     explainer = lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names,\n\u001B[32m     49\u001B[39m                                                   class_names=[\u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m], mode=\u001B[33m'\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m     explanation = \u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     52\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mwebbrowser\u001B[39;00m\n\u001B[32m     53\u001B[39m     html_path = \u001B[33m\"\u001B[39m\u001B[33mlime_explanation.html\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:452\u001B[39m, in \u001B[36mLimeTabularExplainer.explain_instance\u001B[39m\u001B[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001B[39m\n\u001B[32m    448\u001B[39m     labels = [\u001B[32m0\u001B[39m]\n\u001B[32m    449\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels:\n\u001B[32m    450\u001B[39m     (ret_exp.intercept[label],\n\u001B[32m    451\u001B[39m      ret_exp.local_exp[label],\n\u001B[32m--> \u001B[39m\u001B[32m452\u001B[39m      ret_exp.score, ret_exp.local_pred) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbase\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m            \u001B[49m\u001B[43mscaled_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m            \u001B[49m\u001B[43myss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    455\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    462\u001B[39m     ret_exp.intercept[\u001B[32m1\u001B[39m] = ret_exp.intercept[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_base.py:182\u001B[39m, in \u001B[36mLimeBase.explain_instance_with_data\u001B[39m\u001B[34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001B[39;00m\n\u001B[32m    146\u001B[39m \n\u001B[32m    147\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \u001B[33;03m    local_pred is the prediction of the explanation model on the original instance\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    181\u001B[39m weights = \u001B[38;5;28mself\u001B[39m.kernel_fn(distances)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m labels_column = \u001B[43mneighborhood_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    183\u001B[39m used_features = \u001B[38;5;28mself\u001B[39m.feature_selection(neighborhood_data,\n\u001B[32m    184\u001B[39m                                        labels_column,\n\u001B[32m    185\u001B[39m                                        weights,\n\u001B[32m    186\u001B[39m                                        num_features,\n\u001B[32m    187\u001B[39m                                        feature_selection)\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mIndexError\u001B[39m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:28:19.886246Z",
     "start_time": "2025-04-22T07:28:14.158356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# ========== Load Data and Model ==========\n",
    "X = np.load('X_scaled.npy')\n",
    "y = np.load('y_labels.npy')\n",
    "feature_names = np.load('feature_names.npy', allow_pickle=True)\n",
    "model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "\n",
    "# ========== Choose Random Sample ==========\n",
    "sample_idx = random.randint(0, len(X) - 1)\n",
    "sample = X[sample_idx]\n",
    "true_label = y[sample_idx]\n",
    "pred_prob = model.predict(sample[np.newaxis])[0][0]\n",
    "pred_class = 'Real' if pred_prob > 0.5 else 'Fake'\n",
    "true_class = 'Real' if true_label == 1 else 'Fake'\n",
    "\n",
    "print(f\"\\nSample {sample_idx}: True: {true_class}, Predicted: {pred_class} ({pred_prob:.4f})\")\n",
    "\n",
    "# ========== LIME Explanation ==========\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    X, feature_names=feature_names.tolist(), class_names=['Fake', 'Real'], mode='classification'\n",
    ")\n",
    "lime_exp = explainer.explain_instance(sample, model.predict, num_features=10)\n",
    "\n",
    "# Save LIME output to HTML and open in browser\n",
    "import webbrowser\n",
    "with open(\"lime_explanation.html\", \"w\") as f:\n",
    "    f.write(lime_exp.as_html())\n",
    "webbrowser.open(\"lime_explanation.html\")\n",
    "\n",
    "# ========== SHAP Explanation ==========\n",
    "explainer_shap = shap.DeepExplainer(model, X[:100])  # subset of background data\n",
    "shap_values = explainer_shap.shap_values(np.array([sample]))[0][0]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "shap.bar_plot(shap_values, feature_names=feature_names.tolist())\n",
    "plt.title(\"SHAP Feature Contributions\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========== Grad-CAM-Like Explanation ==========\n",
    "sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(sample_tensor)\n",
    "    pred = model(sample_tensor)\n",
    "\n",
    "grads = tape.gradient(pred, sample_tensor).numpy()[0]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.barh(feature_names, grads)\n",
    "plt.xlabel(\"Gradient\")\n",
    "plt.title(\"Grad-CAM Style Input Gradient Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========== Top LIME Features ==========\n",
    "print(\"\\nTop contributing LIME features:\")\n",
    "for feature, weight in lime_exp.as_list()[:5]:\n",
    "    print(f\"{feature}: {weight:.4f}\")\n"
   ],
   "id": "6348cf9c02e3071c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 284ms/step\n",
      "\n",
      "Sample 1941: True: Fake, Predicted: Fake (0.0000)\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m     24\u001B[39m \u001B[38;5;66;03m# ========== LIME Explanation ==========\u001B[39;00m\n\u001B[32m     25\u001B[39m explainer = lime_tabular.LimeTabularExplainer(\n\u001B[32m     26\u001B[39m     X, feature_names=feature_names.tolist(), class_names=[\u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m], mode=\u001B[33m'\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     27\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m lime_exp = \u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# Save LIME output to HTML and open in browser\u001B[39;00m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mwebbrowser\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:452\u001B[39m, in \u001B[36mLimeTabularExplainer.explain_instance\u001B[39m\u001B[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001B[39m\n\u001B[32m    448\u001B[39m     labels = [\u001B[32m0\u001B[39m]\n\u001B[32m    449\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels:\n\u001B[32m    450\u001B[39m     (ret_exp.intercept[label],\n\u001B[32m    451\u001B[39m      ret_exp.local_exp[label],\n\u001B[32m--> \u001B[39m\u001B[32m452\u001B[39m      ret_exp.score, ret_exp.local_pred) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbase\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m            \u001B[49m\u001B[43mscaled_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m            \u001B[49m\u001B[43myss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    455\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    462\u001B[39m     ret_exp.intercept[\u001B[32m1\u001B[39m] = ret_exp.intercept[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_base.py:182\u001B[39m, in \u001B[36mLimeBase.explain_instance_with_data\u001B[39m\u001B[34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001B[39;00m\n\u001B[32m    146\u001B[39m \n\u001B[32m    147\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \u001B[33;03m    local_pred is the prediction of the explanation model on the original instance\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    181\u001B[39m weights = \u001B[38;5;28mself\u001B[39m.kernel_fn(distances)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m labels_column = \u001B[43mneighborhood_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    183\u001B[39m used_features = \u001B[38;5;28mself\u001B[39m.feature_selection(neighborhood_data,\n\u001B[32m    184\u001B[39m                                        labels_column,\n\u001B[32m    185\u001B[39m                                        weights,\n\u001B[32m    186\u001B[39m                                        num_features,\n\u001B[32m    187\u001B[39m                                        feature_selection)\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mIndexError\u001B[39m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T06:53:25.263087Z",
     "start_time": "2025-04-22T06:53:19.649093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "\n",
    "# ========================\n",
    "# EXPLANATION FUNCTIONS\n",
    "# ========================\n",
    "\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    \"\"\"Generate LIME explanation for a single sample\"\"\"\n",
    "    # Create custom predict function for LIME compatibility\n",
    "    def predict_proba(x):\n",
    "        return np.hstack((1 - model.predict(x, verbose=0), model.predict(x, verbose=0)))\n",
    "\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    explanation = explainer.explain_instance(\n",
    "        data_row=X_sample,\n",
    "        predict_fn=predict_proba,\n",
    "        num_features=10\n",
    "    )\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    \"\"\"Generate SHAP explanation for a single sample\"\"\"\n",
    "    # Use subset of training data as background\n",
    "    background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]\n",
    "\n",
    "    # Create SHAP explainer\n",
    "    explainer = shap.DeepExplainer(\n",
    "        model=model,\n",
    "        data=background\n",
    "    )\n",
    "\n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer.shap_values(np.array([X_sample]))[0][0]\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    shap.bar_plot(\n",
    "        shap_values=shap_values,\n",
    "        feature_names=feature_names,\n",
    "        max_display=15\n",
    "    )\n",
    "    plt.title(\"SHAP Feature Contributions\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    \"\"\"Generate gradient-based explanation similar to Grad-CAM\"\"\"\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        prediction = model(sample_tensor)\n",
    "\n",
    "    gradients = tape.gradient(prediction, sample_tensor).numpy()[0]\n",
    "\n",
    "    # Plot gradients\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.barh(feature_names, gradients)\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Input Gradient Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ========================\n",
    "# MAIN EXECUTION\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    # Load preprocessed data and trained model\n",
    "    model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "    X_scaled = np.load('preprocessed_features.npy')  # Assuming saved preprocessing\n",
    "    y = np.load('labels.npy')\n",
    "    feature_names = np.load('feature_names.npy')\n",
    "\n",
    "    # Split data (if not already saved)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Explain 3 random samples\n",
    "    for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "        sample = X_test[i]\n",
    "        pred_prob = model.predict(sample[np.newaxis])[0][0]\n",
    "        pred_class = 'Real' if pred_prob > 0.5 else 'Fake'\n",
    "        true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"True: {true_class}, Predicted: {pred_class} ({pred_prob:.4f})\")\n",
    "\n",
    "        # Generate explanations\n",
    "        lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "        lime_exp.show_in_notebook()\n",
    "\n",
    "        explain_with_shap(model, X_train, sample, feature_names)\n",
    "\n",
    "        grad_cam_like_explanation(model, sample, feature_names)\n",
    "\n",
    "        # Show LIME feature weights\n",
    "        print(\"\\nTop LIME Features:\")\n",
    "        for feat, weight in lime_exp.as_list()[:10]:\n",
    "            print(f\"{feat}: {weight:.4f}\")"
   ],
   "id": "b31c72cc2ee5a73e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'preprocessed_features.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 83\u001B[39m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     81\u001B[39m     \u001B[38;5;66;03m# Load preprocessed data and trained model\u001B[39;00m\n\u001B[32m     82\u001B[39m     model = tf.keras.models.load_model(\u001B[33m'\u001B[39m\u001B[33mbest_tabular_model.h5\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m     X_scaled = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mpreprocessed_features.npy\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Assuming saved preprocessing\u001B[39;00m\n\u001B[32m     84\u001B[39m     y = np.load(\u001B[33m'\u001B[39m\u001B[33mlabels.npy\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     85\u001B[39m     feature_names = np.load(\u001B[33m'\u001B[39m\u001B[33mfeature_names.npy\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:459\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[39m\n\u001B[32m    457\u001B[39m     own_fid = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    458\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m459\u001B[39m     fid = stack.enter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[32m    460\u001B[39m     own_fid = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    462\u001B[39m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'preprocessed_features.npy'"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f0568f91ad13aae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:30:02.069532Z",
     "start_time": "2025-04-22T07:29:52.908852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from lime import lime_tabular\n",
    "from tensorflow.keras import backend as K\n",
    "import librosa.display\n",
    "import os\n",
    "\n",
    "# Load the saved data\n",
    "X = np.load('X_scaled.npy')\n",
    "y = np.load('y_labels.npy')\n",
    "feature_names = np.load('feature_names.npy', allow_pickle=True)\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "\n",
    "# ========== Modify the predict function for LIME ==========\n",
    "def predict_fn(x):\n",
    "    # Ensure the model returns probabilities for both classes (Fake, Real)\n",
    "    return np.array([model.predict(x)[:, 0], 1 - model.predict(x)[:, 0]]).T\n",
    "\n",
    "# ========== Choose Random Sample ==========\n",
    "sample_idx = random.randint(0, len(X) - 1)\n",
    "sample = X[sample_idx]\n",
    "true_label = y[sample_idx]\n",
    "pred_prob = model.predict(sample[np.newaxis])[0][0]\n",
    "pred_class = 'Real' if pred_prob > 0.5 else 'Fake'\n",
    "true_class = 'Real' if true_label == 1 else 'Fake'\n",
    "\n",
    "print(f\"\\nSample {sample_idx}: True: {true_class}, Predicted: {pred_class} ({pred_prob:.4f})\")\n",
    "\n",
    "# ========== LIME Explanation ==========\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    X, feature_names=feature_names.tolist(), class_names=['Fake', 'Real'], mode='classification'\n",
    ")\n",
    "\n",
    "lime_exp = explainer.explain_instance(sample, predict_fn, num_features=10)\n",
    "\n",
    "# Save LIME output to HTML and open in browser\n",
    "import webbrowser\n",
    "with open(\"lime_explanation.html\", \"w\") as f:\n",
    "    f.write(lime_exp.as_html())\n",
    "webbrowser.open(\"lime_explanation.html\")\n",
    "\n",
    "\n",
    "# ========== SHAP Explanation ==========\n",
    "# Initialize SHAP explainer using the model\n",
    "explainer_shap = shap.KernelExplainer(predict_fn, X)\n",
    "\n",
    "# Compute SHAP values for the sample\n",
    "shap_values = explainer_shap.shap_values(sample)\n",
    "\n",
    "# Plot SHAP values\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values, X, feature_names=feature_names.tolist())\n",
    "\n",
    "# Save SHAP plot as an image\n",
    "shap.summary_plot(shap_values, X, feature_names=feature_names.tolist(), show=False)\n",
    "plt.savefig('shap_summary_plot.png')\n",
    "\n",
    "# ========== Grad-CAM Explanation (Placeholder) ==========\n",
    "# Since Grad-CAM typically works on convolutional neural networks (CNNs) for visual tasks,\n",
    "# it's not directly applicable to your tabular data model, as it's used for interpreting\n",
    "# deep learning models on image classification tasks. However, you can apply Grad-CAM\n",
    "# to models that use CNNs with image-based inputs.\n",
    "# If you plan to use Grad-CAM on audio data transformed to spectrograms, here's an approach.\n",
    "\n",
    "# Placeholder for Grad-CAM explanation (if you modify the model to use CNN)\n",
    "def grad_cam(model, X, layer_name='conv2d'):\n",
    "    # Convert the sample to a tensor and compute the gradients\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        inputs = tf.convert_to_tensor(X)\n",
    "        tape.watch(inputs)\n",
    "        layer_output, predictions = grad_model(inputs)\n",
    "    grads = tape.gradient(predictions, layer_output)\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Generate Grad-CAM heatmap\n",
    "    heatmap = layer_output[0].numpy() @ pooled_grads.numpy()\n",
    "    heatmap = np.mean(heatmap, axis=-1)\n",
    "\n",
    "    plt.imshow(heatmap, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# This Grad-CAM implementation is placeholder code. You can modify your model to include\n",
    "# convolutional layers and then use Grad-CAM on the audio features by transforming them\n",
    "# into spectrograms, for example.\n",
    "\n",
    "# Example of Grad-CAM usage (if applicable, with convolutional layers)\n",
    "# grad_cam(model, sample[np.newaxis])\n",
    "\n"
   ],
   "id": "f15561750e645a84",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 141ms/step\n",
      "\n",
      "Sample 2472: True: Fake, Predicted: Fake (0.0000)\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u03b5' in position 59564: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mUnicodeEncodeError\u001B[39m                        Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 44\u001B[39m\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mwebbrowser\u001B[39;00m\n\u001B[32m     43\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mlime_explanation.html\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m---> \u001B[39m\u001B[32m44\u001B[39m     \u001B[43mf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlime_exp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mas_html\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     45\u001B[39m webbrowser.open(\u001B[33m\"\u001B[39m\u001B[33mlime_explanation.html\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     48\u001B[39m \u001B[38;5;66;03m# ========== SHAP Explanation ==========\u001B[39;00m\n\u001B[32m     49\u001B[39m \u001B[38;5;66;03m# Initialize SHAP explainer using the model\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\cp1252.py:19\u001B[39m, in \u001B[36mIncrementalEncoder.encode\u001B[39m\u001B[34m(self, input, final)\u001B[39m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mencode\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, final=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcodecs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcharmap_encode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43mencoding_table\u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m]\n",
      "\u001B[31mUnicodeEncodeError\u001B[39m: 'charmap' codec can't encode character '\\u03b5' in position 59564: character maps to <undefined>"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bc50b57be1563c91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d6c6fee0478e69c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ac69e2cf5e01e11c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "80ef6b51a66ec85a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:16:37.534844Z",
     "start_time": "2025-04-22T07:00:30.223092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "\n",
    "# ========================\n",
    "# FEATURE EXTRACTION\n",
    "# ========================\n",
    "def extract_features(file_path, n_mfcc=20, n_mels=128):\n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "    features = []\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    features.append(np.mean(mfcc, axis=1))\n",
    "    features.append(np.std(mfcc, axis=1))\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_db = librosa.power_to_db(mel)\n",
    "    features.append(np.mean(mel_db, axis=1))\n",
    "    features.append(np.std(mel_db, axis=1))\n",
    "\n",
    "    features.append(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))\n",
    "    features.append(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))\n",
    "    features.append(np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1))\n",
    "    features.append(np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)))\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features.append(np.mean(chroma, axis=1))\n",
    "    features.append(np.std(chroma, axis=1))\n",
    "\n",
    "    features.append(np.mean(librosa.feature.zero_crossing_rate(y)))\n",
    "    features.append(np.mean(librosa.feature.rms(y=y)))\n",
    "\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    features.append(np.mean(y_harmonic))\n",
    "    features.append(np.mean(y_percussive))\n",
    "\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    features.append(tempo)\n",
    "\n",
    "    return np.hstack(features)\n",
    "\n",
    "# ========================\n",
    "# LOAD DATA\n",
    "# ========================\n",
    "def load_dataset(data_path):\n",
    "    X, y = [], []\n",
    "    dummy_path = os.path.join(data_path, 'Real', 'real_1.wav')\n",
    "    feature_names = [f\"feature_{i}\" for i in range(len(extract_features(dummy_path)))]\n",
    "\n",
    "    for label in ['Real', 'Fake']:\n",
    "        class_path = os.path.join(data_path, label)\n",
    "        for file in os.listdir(class_path):\n",
    "            if file.endswith('.wav'):\n",
    "                path = os.path.join(class_path, file)\n",
    "                X.append(extract_features(path))\n",
    "                y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X_scaled, y, feature_names, scaler\n",
    "\n",
    "# ========================\n",
    "# EXPLANATION FUNCTIONS\n",
    "# ========================\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    def predict_proba(x):\n",
    "        return np.hstack((1 - model.predict(x, verbose=0), model.predict(x, verbose=0)))\n",
    "\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification'\n",
    "    )\n",
    "\n",
    "    return explainer.explain_instance(X_sample, predict_fn=predict_proba, num_features=10)\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]\n",
    "    explainer = shap.DeepExplainer(model, background)\n",
    "    shap_values = explainer.shap_values(np.array([X_sample]))[0][0]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    shap.bar_plot(shap_values=shap_values, feature_names=feature_names, max_display=15)\n",
    "    plt.title(\"SHAP Feature Contributions\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        prediction = model(sample_tensor)\n",
    "    gradients = tape.gradient(prediction, sample_tensor).numpy()[0]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.barh(feature_names, gradients)\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Input Gradient Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ========================\n",
    "# MAIN EXECUTION\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "    X, y, feature_names, _ = load_dataset(data_path)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "\n",
    "    for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "        sample = X_test[i]\n",
    "        pred_prob = model.predict(sample[np.newaxis])[0][0]\n",
    "        pred_class = 'Real' if pred_prob > 0.5 else 'Fake'\n",
    "        true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"True: {true_class}, Predicted: {pred_class} ({pred_prob:.4f})\")\n",
    "\n",
    "        lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "        lime_exp.show_in_notebook()\n",
    "\n",
    "        explain_with_shap(model, X_train, sample, feature_names)\n",
    "        grad_cam_like_explanation(model, sample, feature_names)\n",
    "\n",
    "        print(\"\\nTop LIME Features:\")\n",
    "        for feat, weight in lime_exp.as_list()[:10]:\n",
    "            print(f\"{feat}: {weight:.4f}\")\n"
   ],
   "id": "86b870798e3579ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 695ms/step\n",
      "\n",
      "Sample 303:\n",
      "True: Real, Predicted: Real (1.0000)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\IPython\\core\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 134\u001B[39m\n\u001B[32m    131\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTrue: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrue_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Predicted: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred_prob\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    133\u001B[39m lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m \u001B[43mlime_exp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshow_in_notebook\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    136\u001B[39m explain_with_shap(model, X_train, sample, feature_names)\n\u001B[32m    137\u001B[39m grad_cam_like_explanation(model, sample, feature_names)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\explanation.py:194\u001B[39m, in \u001B[36mExplanation.show_in_notebook\u001B[39m\u001B[34m(self, labels, predict_proba, show_predicted_value, **kwargs)\u001B[39m\n\u001B[32m    184\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mshow_in_notebook\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[32m    185\u001B[39m                      labels=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    186\u001B[39m                      predict_proba=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    187\u001B[39m                      show_predicted_value=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    188\u001B[39m                      **kwargs):\n\u001B[32m    189\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Shows html explanation in ipython notebook.\u001B[39;00m\n\u001B[32m    190\u001B[39m \n\u001B[32m    191\u001B[39m \u001B[33;03m    See as_html() for parameters.\u001B[39;00m\n\u001B[32m    192\u001B[39m \u001B[33;03m    This will throw an error if you don't have IPython installed\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m194\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mIPython\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcore\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdisplay\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m display, HTML\n\u001B[32m    195\u001B[39m     display(HTML(\u001B[38;5;28mself\u001B[39m.as_html(labels=labels,\n\u001B[32m    196\u001B[39m                               predict_proba=predict_proba,\n\u001B[32m    197\u001B[39m                               show_predicted_value=show_predicted_value,\n\u001B[32m    198\u001B[39m                               **kwargs)))\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'display' from 'IPython.core.display' (C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\IPython\\core\\display.py)"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3f853cc73c5bb690"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4652046242c8bedb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a9f826fcd4ecbcb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "636c3848051bea6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fd73c78086ca9768"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5c6eac48a6c2ddbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6ade0b78fc8bda40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9450909596d8c056"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a0db5015e33cf779"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:34:02.057710Z",
     "start_time": "2025-04-22T07:33:52.664359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import shap\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.metrics import accuracy_score\n",
    "import webbrowser\n",
    "\n",
    "# Load the data\n",
    "X_scaled = np.load('X_scaled.npy')\n",
    "y_labels = np.load('y_labels.npy')\n",
    "feature_names = np.load('feature_names.npy')\n",
    "\n",
    "# Load the trained model (update the path to 'best_tabular_model.h5')\n",
    "model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "\n",
    "# ========== LIME Explanation ==========\n",
    "# Initialize the LimeTabularExplainer\n",
    "explainer = LimeTabularExplainer(\n",
    "    X_scaled, feature_names=feature_names.tolist(),\n",
    "    class_names=['Fake', 'Real'], mode='classification'\n",
    ")\n",
    "\n",
    "# Choose a sample for explanation (index 0 for this example)\n",
    "sample = X_scaled[0]\n",
    "\n",
    "# Explain the instance with LIME\n",
    "lime_exp = explainer.explain_instance(sample, model.predict, num_features=10)\n",
    "\n",
    "# Save LIME output to HTML with UTF-8 encoding\n",
    "with open(\"lime_explanation.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lime_exp.as_html())\n",
    "webbrowser.open(\"lime_explanation.html\")\n",
    "\n",
    "# ========== SHAP Explanation ==========\n",
    "# Initialize SHAP explainer using the model\n",
    "shap_explainer = shap.KernelExplainer(model.predict, X_scaled)\n",
    "shap_values = shap_explainer.shap_values(X_scaled)\n",
    "\n",
    "# Plot SHAP summary plot\n",
    "shap.summary_plot(shap_values[1], X_scaled, feature_names=feature_names.tolist(), plot_type=\"bar\")\n",
    "\n",
    "# ========== Grad-CAM-like Explanation ==========\n",
    "# Create Grad-CAM-like visual explanation (for tabular data)\n",
    "# Grad-CAM is typically used for CNNs with image data, so here we use the concept for feature importance\n",
    "def grad_cam_explanation(model, sample):\n",
    "    # Get gradients of output w.r.t. input features\n",
    "    with tf.GradientTape() as tape:\n",
    "        sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "        tape.watch(sample_tensor)\n",
    "        predictions = model(sample_tensor)\n",
    "\n",
    "    # Calculate gradients\n",
    "    grads = tape.gradient(predictions, sample_tensor)\n",
    "\n",
    "    # Get absolute gradients (this can be adjusted for different types of explanations)\n",
    "    abs_grads = np.abs(grads.numpy())\n",
    "\n",
    "    # Visualize the feature importance\n",
    "    feature_importance = abs_grads.flatten()\n",
    "    feature_importance = feature_importance / np.max(feature_importance)  # Normalize\n",
    "\n",
    "    # Plot Grad-CAM-like explanation (feature importance)\n",
    "    plt.bar(range(len(feature_importance)), feature_importance)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Feature Importance (Gradient Magnitude)')\n",
    "    plt.title('Grad-CAM-like Explanation (Feature Importance)')\n",
    "    plt.show()\n",
    "\n",
    "# Call Grad-CAM-like explanation for the first sample\n",
    "grad_cam_explanation(model, sample)\n",
    "\n",
    "# ========= Evaluating Model Performance =========\n",
    "y_pred = model.predict(X_scaled)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)  # Assuming binary classification\n",
    "accuracy = accuracy_score(y_labels, y_pred_classes)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ],
   "id": "1640e94ebf956710",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 33\u001B[39m\n\u001B[32m     30\u001B[39m sample = X_scaled[\u001B[32m0\u001B[39m]\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Explain the instance with LIME\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m lime_exp = \u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[38;5;66;03m# Save LIME output to HTML with UTF-8 encoding\u001B[39;00m\n\u001B[32m     36\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mlime_explanation.html\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\"\u001B[39m, encoding=\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:452\u001B[39m, in \u001B[36mLimeTabularExplainer.explain_instance\u001B[39m\u001B[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001B[39m\n\u001B[32m    448\u001B[39m     labels = [\u001B[32m0\u001B[39m]\n\u001B[32m    449\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels:\n\u001B[32m    450\u001B[39m     (ret_exp.intercept[label],\n\u001B[32m    451\u001B[39m      ret_exp.local_exp[label],\n\u001B[32m--> \u001B[39m\u001B[32m452\u001B[39m      ret_exp.score, ret_exp.local_pred) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbase\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m            \u001B[49m\u001B[43mscaled_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m            \u001B[49m\u001B[43myss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    455\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    462\u001B[39m     ret_exp.intercept[\u001B[32m1\u001B[39m] = ret_exp.intercept[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_base.py:182\u001B[39m, in \u001B[36mLimeBase.explain_instance_with_data\u001B[39m\u001B[34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001B[39;00m\n\u001B[32m    146\u001B[39m \n\u001B[32m    147\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \u001B[33;03m    local_pred is the prediction of the explanation model on the original instance\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    181\u001B[39m weights = \u001B[38;5;28mself\u001B[39m.kernel_fn(distances)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m labels_column = \u001B[43mneighborhood_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    183\u001B[39m used_features = \u001B[38;5;28mself\u001B[39m.feature_selection(neighborhood_data,\n\u001B[32m    184\u001B[39m                                        labels_column,\n\u001B[32m    185\u001B[39m                                        weights,\n\u001B[32m    186\u001B[39m                                        num_features,\n\u001B[32m    187\u001B[39m                                        feature_selection)\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mIndexError\u001B[39m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "84ea6c2177b5595f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T07:35:52.345642Z",
     "start_time": "2025-04-22T07:35:41.526317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import shap\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.metrics import accuracy_score\n",
    "import webbrowser\n",
    "\n",
    "# Load the data\n",
    "X_scaled = np.load('X_scaled.npy')\n",
    "y_labels = np.load('y_labels.npy')\n",
    "feature_names = np.load('feature_names.npy')\n",
    "\n",
    "# Load the trained model (update the path to 'best_tabular_model.h5')\n",
    "model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "\n",
    "# Function to adjust the model's output to match LIME expectations for binary classification\n",
    "def predict_fn_for_lime(X):\n",
    "    # Get model predictions\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # For binary classification, convert to 2D output with probabilities for both classes\n",
    "    return np.column_stack([1 - predictions, predictions])  # [Fake, Real] probabilities\n",
    "\n",
    "# ========== LIME Explanation ==========\n",
    "# Initialize the LimeTabularExplainer\n",
    "explainer = LimeTabularExplainer(\n",
    "    X_scaled, feature_names=feature_names.tolist(),\n",
    "    class_names=['Fake', 'Real'], mode='classification'\n",
    ")\n",
    "\n",
    "# Choose a sample for explanation (index 0 for this example)\n",
    "sample = X_scaled[0]\n",
    "\n",
    "# Explain the instance with LIME using adjusted predict_fn\n",
    "lime_exp = explainer.explain_instance(sample, predict_fn_for_lime, num_features=10)\n",
    "\n",
    "# Save LIME output to HTML with UTF-8 encoding\n",
    "with open(\"lime_explanation.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lime_exp.as_html())\n",
    "webbrowser.open(\"lime_explanation.html\")\n",
    "\n",
    "# ========== SHAP Explanation ==========\n",
    "# Initialize SHAP explainer using the model\n",
    "shap_explainer = shap.KernelExplainer(model.predict, X_scaled)\n",
    "shap_values = shap_explainer.shap_values(X_scaled)\n",
    "\n",
    "# Plot SHAP summary plot\n",
    "shap.summary_plot(shap_values[1], X_scaled, feature_names=feature_names.tolist(), plot_type=\"bar\")\n",
    "\n",
    "# ========== Grad-CAM-like Explanation ==========\n",
    "# Create Grad-CAM-like visual explanation (for tabular data)\n",
    "def grad_cam_explanation(model, sample):\n",
    "    # Get gradients of output w.r.t. input features\n",
    "    with tf.GradientTape() as tape:\n",
    "        sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "        tape.watch(sample_tensor)\n",
    "        predictions = model(sample_tensor)\n",
    "\n",
    "    # Calculate gradients\n",
    "    grads = tape.gradient(predictions, sample_tensor)\n",
    "\n",
    "    # Get absolute gradients (this can be adjusted for different types of explanations)\n",
    "    abs_grads = np.abs(grads.numpy())\n",
    "\n",
    "    # Visualize the feature importance\n",
    "    feature_importance = abs_grads.flatten()\n",
    "    feature_importance = feature_importance / np.max(feature_importance)  # Normalize\n",
    "\n",
    "    # Plot Grad-CAM-like explanation (feature importance)\n",
    "    plt.bar(range(len(feature_importance)), feature_importance)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Feature Importance (Gradient Magnitude)')\n",
    "    plt.title('Grad-CAM-like Explanation (Feature Importance)')\n",
    "    plt.show()\n",
    "\n",
    "# Call Grad-CAM-like explanation for the first sample\n",
    "grad_cam_explanation(model, sample)\n",
    "\n",
    "# ========= Evaluating Model Performance =========\n",
    "y_pred = model.predict(X_scaled)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)  # Assuming binary classification\n",
    "accuracy = accuracy_score(y_labels, y_pred_classes)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ],
   "id": "ab17688865d1e2ef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step\n",
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:shap:Using 3600 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3600 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 24.4 GiB for an array with shape (2718, 1206000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mMemoryError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 51\u001B[39m\n\u001B[32m     48\u001B[39m \u001B[38;5;66;03m# ========== SHAP Explanation ==========\u001B[39;00m\n\u001B[32m     49\u001B[39m \u001B[38;5;66;03m# Initialize SHAP explainer using the model\u001B[39;00m\n\u001B[32m     50\u001B[39m shap_explainer = shap.KernelExplainer(model.predict, X_scaled)\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m shap_values = \u001B[43mshap_explainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshap_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_scaled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     53\u001B[39m \u001B[38;5;66;03m# Plot SHAP summary plot\u001B[39;00m\n\u001B[32m     54\u001B[39m shap.summary_plot(shap_values[\u001B[32m1\u001B[39m], X_scaled, feature_names=feature_names.tolist(), plot_type=\u001B[33m\"\u001B[39m\u001B[33mbar\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\shap\\explainers\\_kernel.py:275\u001B[39m, in \u001B[36mKernelExplainer.shap_values\u001B[39m\u001B[34m(self, X, **kwargs)\u001B[39m\n\u001B[32m    273\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.keep_index:\n\u001B[32m    274\u001B[39m     data = convert_to_instance_with_index(data, column_name, index_value[i : i + \u001B[32m1\u001B[39m], index_name)\n\u001B[32m--> \u001B[39m\u001B[32m275\u001B[39m explanations.append(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mexplain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    276\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mgc_collect\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m    277\u001B[39m     gc.collect()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\shap\\explainers\\_kernel.py:366\u001B[39m, in \u001B[36mKernelExplainer.explain\u001B[39m\u001B[34m(self, incoming_instance, **kwargs)\u001B[39m\n\u001B[32m    363\u001B[39m         \u001B[38;5;28mself\u001B[39m.nsamples = \u001B[38;5;28mself\u001B[39m.max_samples\n\u001B[32m    365\u001B[39m \u001B[38;5;66;03m# reserve space for some of our computations\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mallocate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[38;5;66;03m# weight the different subset sizes\u001B[39;00m\n\u001B[32m    369\u001B[39m num_subset_sizes = \u001B[38;5;28mint\u001B[39m(np.ceil((\u001B[38;5;28mself\u001B[39m.M - \u001B[32m1\u001B[39m) / \u001B[32m2.0\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\shap\\explainers\\_kernel.py:576\u001B[39m, in \u001B[36mKernelExplainer.allocate\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    574\u001B[39m         \u001B[38;5;28mself\u001B[39m.synth_data = scipy.sparse.csr_matrix((new_data, new_indices, new_indptr), shape=shape).tolil()\n\u001B[32m    575\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m576\u001B[39m     \u001B[38;5;28mself\u001B[39m.synth_data = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnsamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    578\u001B[39m \u001B[38;5;28mself\u001B[39m.maskMatrix = np.zeros((\u001B[38;5;28mself\u001B[39m.nsamples, \u001B[38;5;28mself\u001B[39m.M))\n\u001B[32m    579\u001B[39m \u001B[38;5;28mself\u001B[39m.kernelWeights = np.zeros(\u001B[38;5;28mself\u001B[39m.nsamples)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\numpy\\lib\\_shape_base_impl.py:1304\u001B[39m, in \u001B[36mtile\u001B[39m\u001B[34m(A, reps)\u001B[39m\n\u001B[32m   1302\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m dim_in, nrep \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(c.shape, tup):\n\u001B[32m   1303\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m nrep != \u001B[32m1\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1304\u001B[39m             c = \u001B[43mc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrepeat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1305\u001B[39m         n //= dim_in\n\u001B[32m   1306\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m c.reshape(shape_out)\n",
      "\u001B[31mMemoryError\u001B[39m: Unable to allocate 24.4 GiB for an array with shape (2718, 1206000) and data type float64"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:14:35.728390Z",
     "start_time": "2025-04-22T08:14:17.554821Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "20b800d1a53f9d3c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:15:47.752855Z",
     "start_time": "2025-04-22T08:15:29.600983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.metrics import accuracy_score\n",
    "import webbrowser\n",
    "\n",
    "# Load the data\n",
    "X_scaled = np.load('X_scaled.npy')\n",
    "y_labels = np.load('y_labels.npy')\n",
    "feature_names = np.load('feature_names.npy')\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "\n",
    "# Function to adjust the model's output to match LIME expectations for binary classification\n",
    "def predict_fn_for_lime(X):\n",
    "    predictions = model.predict(X)\n",
    "    return np.column_stack([1 - predictions, predictions])  # [Fake, Real] probabilities\n",
    "\n",
    "# ========== LIME Explanation ==========\n",
    "# Initialize the LimeTabularExplainer\n",
    "explainer = LimeTabularExplainer(\n",
    "    X_scaled, feature_names=feature_names.tolist(),\n",
    "    class_names=['Fake', 'Real'], mode='classification'\n",
    ")\n",
    "\n",
    "# Choose a sample for explanation (index 0 for this example)\n",
    "sample = X_scaled[0]\n",
    "\n",
    "# Explain the instance with LIME using adjusted predict_fn\n",
    "lime_exp = explainer.explain_instance(sample, predict_fn_for_lime, num_features=10)\n",
    "\n",
    "# Save LIME output to HTML\n",
    "with open(\"lime_explanation.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lime_exp.as_html())\n",
    "webbrowser.open(\"lime_explanation.html\")\n",
    "\n",
    "# ========== Grad-CAM-like Explanation ==========\n",
    "def grad_cam_explanation(model, sample):\n",
    "    # Get gradients of output w.r.t. input features\n",
    "    with tf.GradientTape() as tape:\n",
    "        sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "        tape.watch(sample_tensor)\n",
    "        predictions = model(sample_tensor)\n",
    "\n",
    "    # Calculate gradients\n",
    "    grads = tape.gradient(predictions, sample_tensor)\n",
    "    abs_grads = np.abs(grads.numpy())\n",
    "\n",
    "    # Visualize the feature importance\n",
    "    feature_importance = abs_grads.flatten()\n",
    "    feature_importance = feature_importance / np.max(feature_importance)\n",
    "\n",
    "    plt.bar(range(len(feature_importance)), feature_importance)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Feature Importance (Gradient Magnitude)')\n",
    "    plt.title('Grad-CAM-like Explanation (Feature Importance)')\n",
    "    plt.show()\n",
    "\n",
    "# Call Grad-CAM-like explanation\n",
    "grad_cam_explanation(model, sample)\n",
    "\n",
    "# ========= Evaluating Model Performance =========\n",
    "y_pred = model.predict(X_scaled)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_labels, y_pred_classes)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ],
   "id": "f6f604dc35f309b9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m113/113\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T08:09:58.620122Z",
     "start_time": "2025-04-22T07:41:15.233520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have your model and data (X_scaled) already\n",
    "# If you're using a deep learning model, ensure it's loaded and compiled\n",
    "\n",
    "# Step 1: Downsample the background dataset (Optional)\n",
    "# You can use k-means to summarize the data or shap.sample() to downsample\n",
    "background_data = shap.kmeans(X_scaled, 100)  # Using 100 representative samples\n",
    "\n",
    "# Step 2: Initialize the SHAP explainer with the downsampled background data\n",
    "shap_explainer = shap.KernelExplainer(model.predict, background_data)\n",
    "\n",
    "# Step 3: Compute SHAP values on a subset of your data to avoid memory overload\n",
    "# If you need to explain more instances, consider splitting the dataset\n",
    "shap_values = shap_explainer.shap_values(X_scaled[:100])  # Only explain the first 100 samples\n",
    "\n",
    "# Step 4: Plot SHAP summary plot\n",
    "shap.summary_plot(shap_values[1], X_scaled[:100], feature_names=feature_names.tolist(), plot_type=\"bar\")\n",
    "\n",
    "# Optional: If your model is tree-based, consider switching to TreeExplainer for efficiency\n",
    "# If using tree-based models (like XGBoost or LightGBM):\n",
    "# shap_explainer = shap.TreeExplainer(model)\n",
    "# shap_values = shap_explainer.shap_values(X_scaled[:100])\n"
   ],
   "id": "bbe1921c7c41c985",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:18<30:26, 18.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:37<31:09, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:56<30:41, 18.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [01:17<31:27, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 95ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [01:38<32:01, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 57ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [01:52<28:14, 18.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [02:07<26:23, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [02:25<26:32, 17.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [02:40<25:08, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [02:57<24:57, 16.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [03:14<25:01, 16.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [03:34<26:02, 17.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [03:49<24:49, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [04:05<23:39, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [04:20<22:56, 16.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [04:38<23:13, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [05:01<25:46, 18.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [05:19<25:08, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 73ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [05:39<25:22, 18.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [05:55<24:15, 18.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [06:16<24:51, 18.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [06:35<24:34, 18.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [06:54<24:29, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [07:14<24:27, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [07:30<22:57, 18.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [07:50<23:05, 18.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [08:08<22:37, 18.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [08:26<22:03, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [08:45<21:52, 18.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [09:04<21:54, 18.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [09:21<21:01, 18.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [09:38<20:05, 17.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [09:56<19:58, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [10:13<19:22, 17.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 57ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [10:29<18:38, 17.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [10:45<17:55, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [11:03<17:51, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [11:19<17:30, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [11:35<16:48, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [11:50<16:08, 16.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [12:07<16:11, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [12:25<16:07, 16.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [12:41<15:40, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 72ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [12:57<15:20, 16.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [13:14<15:16, 16.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [13:34<15:59, 17.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [13:56<16:41, 18.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 99ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [14:13<15:53, 18.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [14:30<15:11, 17.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [14:47<14:37, 17.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [15:04<14:10, 17.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [15:19<13:30, 16.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [15:37<13:21, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 80ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [15:53<12:54, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [16:10<12:36, 16.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [16:26<12:09, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [16:43<12:01, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [16:59<11:39, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [17:17<11:28, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [17:33<11:05, 16.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [17:49<10:46, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [18:08<10:59, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [18:26<10:40, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [18:44<10:34, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 72ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [19:02<10:20, 17.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [19:19<09:52, 17.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [19:36<09:34, 17.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [19:53<09:07, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [20:09<08:43, 16.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 77ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [20:26<08:31, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [20:42<08:05, 16.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [20:58<07:42, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [21:15<07:23, 16.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [21:31<07:08, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [21:47<06:45, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [22:05<06:42, 16.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [22:21<06:21, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [22:36<05:57, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [22:51<05:30, 15.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 117ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [23:07<05:17, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [23:23<04:59, 15.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [23:38<04:40, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [23:54<04:28, 15.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [24:11<04:16, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [24:27<03:59, 15.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [24:43<03:45, 16.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [24:58<03:26, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [25:14<03:08, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [25:29<02:51, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [25:47<02:43, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [26:04<02:27, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [26:20<02:10, 16.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [26:35<01:52, 16.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [26:51<01:35, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [27:13<01:28, 17.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [27:28<01:08, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [27:44<00:50, 16.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [28:00<00:33, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [28:16<00:16, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step\n",
      "\u001B[1m8494/8494\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [28:32<00:00, 17.12s/it]\n",
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_25496\\3274357731.py:21: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values[1], X_scaled[:100], feature_names=feature_names.tolist(), plot_type=\"bar\")\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The shape of the shap_values matrix does not match the shape of the provided data matrix.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 21\u001B[39m\n\u001B[32m     18\u001B[39m shap_values = shap_explainer.shap_values(X_scaled[:\u001B[32m100\u001B[39m])  \u001B[38;5;66;03m# Only explain the first 100 samples\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# Step 4: Plot SHAP summary plot\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m \u001B[43mshap\u001B[49m\u001B[43m.\u001B[49m\u001B[43msummary_plot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshap_values\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_scaled\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplot_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mbar\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Optional: If your model is tree-based, consider switching to TreeExplainer for efficiency\u001B[39;00m\n\u001B[32m     24\u001B[39m \u001B[38;5;66;03m# If using tree-based models (like XGBoost or LightGBM):\u001B[39;00m\n\u001B[32m     25\u001B[39m \u001B[38;5;66;03m# shap_explainer = shap.TreeExplainer(model)\u001B[39;00m\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# shap_values = shap_explainer.shap_values(X_scaled[:100])\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:667\u001B[39m, in \u001B[36msummary_legacy\u001B[39m\u001B[34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale, rng)\u001B[39m\n\u001B[32m    662\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    663\u001B[39m             shape_msg + \u001B[33m\"\u001B[39m\u001B[33m Perhaps the extra column in the shap_values matrix is the \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    664\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mconstant offset? Of so just pass shap_values[:,:-1].\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    665\u001B[39m         )\n\u001B[32m    666\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m667\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m num_features == features.shape[\u001B[32m1\u001B[39m], shape_msg\n\u001B[32m    669\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m feature_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    670\u001B[39m     feature_names = np.array([labels[\u001B[33m\"\u001B[39m\u001B[33mFEATURE\u001B[39m\u001B[33m\"\u001B[39m] % \u001B[38;5;28mstr\u001B[39m(i) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_features)])\n",
      "\u001B[31mAssertionError\u001B[39m: The shape of the shap_values matrix does not match the shape of the provided data matrix."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "\n",
    "# ========================\n",
    "# FEATURE EXTRACTION\n",
    "# ========================\n",
    "def extract_features(file_path, n_mfcc=20, n_mels=128):\n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "    features = []\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    features.append(np.mean(mfcc, axis=1))\n",
    "    features.append(np.std(mfcc, axis=1))\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_db = librosa.power_to_db(mel)\n",
    "    features.append(np.mean(mel_db, axis=1))\n",
    "    features.append(np.std(mel_db, axis=1))\n",
    "\n",
    "    features.append(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))\n",
    "    features.append(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))\n",
    "    features.append(np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1))\n",
    "    features.append(np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)))\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features.append(np.mean(chroma, axis=1))\n",
    "    features.append(np.std(chroma, axis=1))\n",
    "\n",
    "    features.append(np.mean(librosa.feature.zero_crossing_rate(y)))\n",
    "    features.append(np.mean(librosa.feature.rms(y=y)))\n",
    "\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    features.append(np.mean(y_harmonic))\n",
    "    features.append(np.mean(y_percussive))\n",
    "\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    features.append(tempo)\n",
    "\n",
    "    return np.hstack(features)\n",
    "\n",
    "# ========================\n",
    "# LOAD DATA\n",
    "# ========================\n",
    "def load_dataset(data_path):\n",
    "    X, y = [], []\n",
    "    dummy_path = os.path.join(data_path, 'Real', 'real_1.wav')\n",
    "    feature_names = [f\"feature_{i}\" for i in range(len(extract_features(dummy_path)))]\n",
    "\n",
    "    for label in ['Real', 'Fake']:\n",
    "        class_path = os.path.join(data_path, label)\n",
    "        for file in os.listdir(class_path):\n",
    "            if file.endswith('.wav'):\n",
    "                path = os.path.join(class_path, file)\n",
    "                X.append(extract_features(path))\n",
    "                y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X_scaled, y, feature_names, scaler\n",
    "\n",
    "# ========================\n",
    "# EXPLANATION FUNCTIONS\n",
    "# ========================\n",
    "def explain_with_lime(model, X_train, X_sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    def predict_proba(x):\n",
    "        return np.hstack((1 - model.predict(x, verbose=0), model.predict(x, verbose=0)))\n",
    "\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification'\n",
    "    )\n",
    "\n",
    "    return explainer.explain_instance(X_sample, predict_fn=predict_proba, num_features=10)\n",
    "\n",
    "def explain_with_shap(model, X_train, X_sample, feature_names):\n",
    "    background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]\n",
    "    explainer = shap.DeepExplainer(model, background)\n",
    "    shap_values = explainer.shap_values(np.array([X_sample]))[0][0]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    shap.bar_plot(shap_values=shap_values, feature_names=feature_names, max_display=15)\n",
    "    plt.title(\"SHAP Feature Contributions\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def grad_cam_like_explanation(model, sample, feature_names):\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        prediction = model(sample_tensor)\n",
    "    gradients = tape.gradient(prediction, sample_tensor).numpy()[0]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.barh(feature_names, gradients)\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Input Gradient Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ========================\n",
    "# MAIN EXECUTION\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "    X, y, feature_names, _ = load_dataset(data_path)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = tf.keras.models.load_model('best_tabular_model.h5')\n",
    "\n",
    "    for i in np.random.choice(len(X_test), 3, replace=False):\n",
    "        sample = X_test[i]\n",
    "        pred_prob = model.predict(sample[np.newaxis])[0][0]\n",
    "        pred_class = 'Real' if pred_prob > 0.5 else 'Fake'\n",
    "        true_class = 'Real' if y_test[i] == 1 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"True: {true_class}, Predicted: {pred_class} ({pred_prob:.4f})\")\n",
    "\n",
    "        lime_exp = explain_with_lime(model, X_train, sample, feature_names)\n",
    "        lime_exp.show_in_notebook()\n",
    "\n",
    "        explain_with_shap(model, X_train, sample, feature_names)\n",
    "        grad_cam_like_explanation(model, sample, feature_names)\n",
    "\n",
    "        print(\"\\nTop LIME Features:\")\n",
    "        for feat, weight in lime_exp.as_list()[:10]:\n",
    "            print(f\"{feat}: {weight:.4f}\")\n"
   ],
   "id": "b0bf5b951cc0d7e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T06:28:28.476343Z",
     "start_time": "2025-04-22T06:28:26.108129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Move 20% of Real/Fake files from Data/ to a new Test/ directory\n",
    "def create_test_split(original_data_path, test_data_path, test_size=0.2):\n",
    "    os.makedirs(test_data_path, exist_ok=True)\n",
    "\n",
    "    for label in ['Real', 'Fake']:\n",
    "        src_dir = os.path.join(original_data_path, label)\n",
    "        dst_dir = os.path.join(test_data_path, label)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "        files = [f for f in os.listdir(src_dir) if f.endswith('.wav')]\n",
    "        _, test_files = train_test_split(files, test_size=test_size, random_state=42)\n",
    "\n",
    "        for f in test_files:\n",
    "            src_file = os.path.join(src_dir, f)\n",
    "            dst_file = os.path.join(dst_dir, f)\n",
    "            shutil.copy2(src_file, dst_file)\n",
    "\n",
    "    print(\"✅ Test dataset created in:\", test_data_path)\n",
    "\n",
    "# Example usage\n",
    "original_data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "test_data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Test/\"\n",
    "create_test_split(original_data_path, test_data_path)\n"
   ],
   "id": "2e11d6c59513beb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test dataset created in: c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Test/\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T06:28:53.236900Z",
     "start_time": "2025-04-22T06:28:44.114103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predict and explain on test samples from separate Test/ directory\n",
    "def predict_test_samples(model, test_data_path, scaler, feature_names, X_train):\n",
    "    for label in ['Real', 'Fake']:\n",
    "        class_dir = os.path.join(test_data_path, label)\n",
    "        if not os.path.exists(class_dir):\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(class_dir):\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, file)\n",
    "                features = extract_features(file_path)\n",
    "                features_scaled = scaler.transform([features])\n",
    "\n",
    "                pred = model.predict(features_scaled)[0][0]\n",
    "                pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "                print(f\"\\n🎵 File: {file} | True: {label} | Predicted: {pred_class} ({pred:.4f})\")\n",
    "\n",
    "                lime_exp = explain_with_lime(model, X_train, features_scaled[0], feature_names)\n",
    "                lime_exp.show_in_notebook()\n",
    "\n",
    "                explain_with_shap(model, X_train, features_scaled[0], feature_names)\n",
    "                grad_cam_like_explanation(model, features_scaled[0], feature_names)\n",
    "\n",
    "                print(\"\\n🔍 Top LIME features:\")\n",
    "                for feature, weight in lime_exp.as_list()[:5]:\n",
    "                    print(f\"{feature}: {weight:.4f}\")\n",
    "\n",
    "# Example usage\n",
    "predict_test_samples(model, test_data_path, scaler, feature_names, X_train)\n"
   ],
   "id": "e010b992552084e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 606ms/step\n",
      "\n",
      "🎵 File: real_1022.wav | True: Real | Predicted: Real (1.0000)\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m     26\u001B[39m                     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfeature\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mweight\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m \u001B[43mpredict_test_samples\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_data_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mpredict_test_samples\u001B[39m\u001B[34m(model, test_data_path, scaler, feature_names, X_train)\u001B[39m\n\u001B[32m     15\u001B[39m pred_class = \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m pred > \u001B[32m0.5\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m🎵 File: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | True: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabel\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | Predicted: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m lime_exp = \u001B[43mexplain_with_lime\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures_scaled\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m lime_exp.show_in_notebook()\n\u001B[32m     21\u001B[39m explain_with_shap(model, X_train, features_scaled[\u001B[32m0\u001B[39m], feature_names)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 108\u001B[39m, in \u001B[36mexplain_with_lime\u001B[39m\u001B[34m(model, X_train, X_sample, feature_names, class_names)\u001B[39m\n\u001B[32m    105\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mexplain_with_lime\u001B[39m(model, X_train, X_sample, feature_names, class_names=[\u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m]):\n\u001B[32m    106\u001B[39m     explainer = lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names,\n\u001B[32m    107\u001B[39m                                                   class_names=class_names, mode=\u001B[33m'\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m108\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredict_fn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:452\u001B[39m, in \u001B[36mLimeTabularExplainer.explain_instance\u001B[39m\u001B[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001B[39m\n\u001B[32m    448\u001B[39m     labels = [\u001B[32m0\u001B[39m]\n\u001B[32m    449\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels:\n\u001B[32m    450\u001B[39m     (ret_exp.intercept[label],\n\u001B[32m    451\u001B[39m      ret_exp.local_exp[label],\n\u001B[32m--> \u001B[39m\u001B[32m452\u001B[39m      ret_exp.score, ret_exp.local_pred) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbase\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m            \u001B[49m\u001B[43mscaled_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m            \u001B[49m\u001B[43myss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    455\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    462\u001B[39m     ret_exp.intercept[\u001B[32m1\u001B[39m] = ret_exp.intercept[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_base.py:182\u001B[39m, in \u001B[36mLimeBase.explain_instance_with_data\u001B[39m\u001B[34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001B[39;00m\n\u001B[32m    146\u001B[39m \n\u001B[32m    147\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \u001B[33;03m    local_pred is the prediction of the explanation model on the original instance\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    181\u001B[39m weights = \u001B[38;5;28mself\u001B[39m.kernel_fn(distances)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m labels_column = \u001B[43mneighborhood_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    183\u001B[39m used_features = \u001B[38;5;28mself\u001B[39m.feature_selection(neighborhood_data,\n\u001B[32m    184\u001B[39m                                        labels_column,\n\u001B[32m    185\u001B[39m                                        weights,\n\u001B[32m    186\u001B[39m                                        num_features,\n\u001B[32m    187\u001B[39m                                        feature_selection)\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mIndexError\u001B[39m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T06:30:37.368530Z",
     "start_time": "2025-04-22T06:30:37.242998Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b626bc6aaf1db162",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T06:18:46.940333Z",
     "start_time": "2025-04-22T06:18:44.441411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import shap\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load saved model and data\n",
    "model = load_model('best_tabular_model.h5')\n",
    "df = pd.read_csv('features_dataset.csv')  # <-- CSV with all features and labels\n",
    "\n",
    "X = df.drop(\"label\", axis=1).values\n",
    "y = df[\"label\"].values\n",
    "feature_names = df.columns[:-1]\n",
    "\n",
    "# Preprocess\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------\n",
    "# LIME EXPLANATION\n",
    "# ----------------------\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_train,\n",
    "    feature_names=feature_names.tolist(),\n",
    "    class_names=['Fake', 'Real'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "idx = np.random.randint(len(X_test))\n",
    "sample = X_test[idx]\n",
    "true_label = y_test[idx]\n",
    "prediction = model.predict(sample[np.newaxis])[0][0]\n",
    "pred_label = 'Real' if prediction > 0.5 else 'Fake'\n",
    "\n",
    "print(f\"\\n🔍 LIME Explanation - True: {'Real' if true_label else 'Fake'}, Pred: {pred_label} ({prediction:.2f})\")\n",
    "\n",
    "lime_exp = lime_explainer.explain_instance(\n",
    "    data_row=sample,\n",
    "    predict_fn=model.predict,\n",
    "    num_features=10\n",
    ")\n",
    "lime_exp.show_in_notebook()\n",
    "\n",
    "# ----------------------\n",
    "# SHAP EXPLANATION\n",
    "# ----------------------\n",
    "print(\"\\n🔍 SHAP Explanation\")\n",
    "shap.initjs()\n",
    "shap_explainer = shap.Explainer(model.predict, X_train[:100])\n",
    "shap_values = shap_explainer(sample[np.newaxis])\n",
    "\n",
    "shap.plots.waterfall(shap_values[0], max_display=10)\n",
    "plt.title(\"SHAP Explanation\")\n",
    "plt.show()\n",
    "\n",
    "# ----------------------\n",
    "# Grad-CAM-Like Explanation\n",
    "# ----------------------\n",
    "print(\"\\n🔍 Grad-CAM-like Explanation\")\n",
    "sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(sample_tensor)\n",
    "    prediction_tensor = model(sample_tensor)\n",
    "\n",
    "gradients = tape.gradient(prediction_tensor, sample_tensor).numpy()[0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, gradients)\n",
    "plt.title(\"Grad-CAM-like Feature Importance (Input Gradient)\")\n",
    "plt.xlabel(\"Gradient Magnitude\")\n",
    "plt.tight_layout()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ],
   "id": "27ba805be928b106",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'features_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# Load saved model and data\u001B[39;00m\n\u001B[32m     14\u001B[39m model = load_model(\u001B[33m'\u001B[39m\u001B[33mbest_tabular_model.h5\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mfeatures_dataset.csv\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# <-- CSV with all features and labels\u001B[39;00m\n\u001B[32m     17\u001B[39m X = df.drop(\u001B[33m\"\u001B[39m\u001B[33mlabel\u001B[39m\u001B[33m\"\u001B[39m, axis=\u001B[32m1\u001B[39m).values\n\u001B[32m     18\u001B[39m y = df[\u001B[33m\"\u001B[39m\u001B[33mlabel\u001B[39m\u001B[33m\"\u001B[39m].values\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'features_dataset.csv'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T06:20:28.598513Z",
     "start_time": "2025-04-22T06:20:17.919474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model('best_tabular_model.h5')\n",
    "\n",
    "# Load and preprocess your data\n",
    "    # Implement your data  logic here\n",
    "    # Should return X_train, X_test, y_train, y_test, feature_names,\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 1. Fixed LIME Explanation\n",
    "# =====================\n",
    "def lime_explanation(model, sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    # Create wrapper function that outputs probabilities for both classes\n",
    "    def predict_proba(x):\n",
    "        preds = model.predict(x, verbose=0)\n",
    "        # Convert single probability to two-class probabilities\n",
    "        return np.hstack([1-preds, preds])\n",
    "\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification'\n",
    "    )\n",
    "\n",
    "    exp = explainer.explain_instance(\n",
    "        sample,\n",
    "        predict_proba,  # Use our wrapper function\n",
    "        num_features=10\n",
    "    )\n",
    "\n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    exp.as_pyplot_figure()\n",
    "    plt.title(\"LIME Explanation\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return exp\n",
    "\n",
    "# =====================\n",
    "# 2. SHAP Explanation\n",
    "# =====================\n",
    "def shap_explanation(model, sample, background_samples=100):\n",
    "    # Create SHAP explainer\n",
    "    explainer = shap.Explainer(\n",
    "        model,\n",
    "        X_train[:background_samples]  # Use subset for background\n",
    "    )\n",
    "\n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer(sample.reshape(1, -1))\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    shap.plots.bar(shap_values[0], max_display=10)\n",
    "    plt.title(\"SHAP Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return shap_values\n",
    "\n",
    "# =====================\n",
    "# 3. Grad-CAM Style Explanation\n",
    "# =====================\n",
    "def grad_cam_explanation(model, sample, feature_names):\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "\n",
    "    # Get gradients of output w.r.t input\n",
    "    grads = tape.gradient(pred, sample_tensor).numpy()[0]\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(feature_names, grads)\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Grad-CAM Style Input Gradient Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return grads\n",
    "\n",
    "# =====================\n",
    "# Main Execution\n",
    "# =====================\n",
    "if __name__ == \"__main__\":\n",
    "    # Select random samples to explain\n",
    "    sample_indices = np.random.choice(len(X_test), 3, replace=False)\n",
    "\n",
    "    for idx in sample_indices:\n",
    "        sample = X_test[idx]\n",
    "        true_label = y_test[idx]\n",
    "        pred = model.predict(sample.reshape(1, -1))[0][0]\n",
    "        pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {idx}:\")\n",
    "        print(f\"True: {'Real' if true_label == 1 else 'Fake'}\")\n",
    "        print(f\"Predicted: {pred_class} ({pred:.4f})\")\n",
    "\n",
    "        # Generate explanations\n",
    "        print(\"\\nLIME Explanation:\")\n",
    "        lime_exp = lime_explanation(model, sample, feature_names)\n",
    "\n",
    "        print(\"\\nSHAP Explanation:\")\n",
    "        shap_vals = shap_explanation(model, sample)\n",
    "\n",
    "        print(\"\\nGrad-CAM Style Explanation:\")\n",
    "        gradients = grad_cam_explanation(model, sample, feature_names)\n",
    "\n",
    "        # Print top features from each method\n",
    "        print(\"\\nTop Contributing Features:\")\n",
    "        lime_features = sorted(lime_exp.as_list(), key=lambda x: abs(x[1]), reverse=True)[:5]\n",
    "\n",
    "        # Handle SHAP values differently since we're using the new API\n",
    "        print(\"\\nLIME Top Features:\")\n",
    "        for feat, weight in lime_features:\n",
    "            print(f\"{feat}: {weight:.4f}\")\n",
    "\n",
    "        print(\"\\nSHAP Top Features:\")\n",
    "        for feat, val in zip(feature_names, shap_vals.values[0,:,1]):\n",
    "            print(f\"{feat}: {val:.4f}\")\n",
    "\n",
    "        print(\"\\nGradient Top Features:\")\n",
    "        for feat, grad in zip(feature_names, gradients):\n",
    "            print(f\"{feat}: {grad:.4f}\")"
   ],
   "id": "ee55c7f31064ee62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2s/step\n",
      "\n",
      "Sample 91:\n",
      "True: Fake\n",
      "Predicted: Fake (0.0000)\n",
      "\n",
      "LIME Explanation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAP Explanation:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_evals=500 is too low for the Permutation explainer, it must be at least 2 * num_features + 1 = 671!",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 117\u001B[39m\n\u001B[32m    114\u001B[39m lime_exp = lime_explanation(model, sample, feature_names)\n\u001B[32m    116\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mSHAP Explanation:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m shap_vals = \u001B[43mshap_explanation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    119\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mGrad-CAM Style Explanation:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    120\u001B[39m gradients = grad_cam_explanation(model, sample, feature_names)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 61\u001B[39m, in \u001B[36mshap_explanation\u001B[39m\u001B[34m(model, sample, background_samples)\u001B[39m\n\u001B[32m     55\u001B[39m explainer = shap.Explainer(\n\u001B[32m     56\u001B[39m     model,\n\u001B[32m     57\u001B[39m     X_train[:background_samples]  \u001B[38;5;66;03m# Use subset for background\u001B[39;00m\n\u001B[32m     58\u001B[39m )\n\u001B[32m     60\u001B[39m \u001B[38;5;66;03m# Calculate SHAP values\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m shap_values = \u001B[43mexplainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     63\u001B[39m \u001B[38;5;66;03m# Visualization\u001B[39;00m\n\u001B[32m     64\u001B[39m plt.figure(figsize=(\u001B[32m12\u001B[39m, \u001B[32m6\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\shap\\explainers\\_permutation.py:100\u001B[39m, in \u001B[36mPermutationExplainer.__call__\u001B[39m\u001B[34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001B[39m\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\n\u001B[32m     90\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m     91\u001B[39m     *args,\n\u001B[32m   (...)\u001B[39m\u001B[32m     97\u001B[39m     silent=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     98\u001B[39m ):\n\u001B[32m     99\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m100\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    101\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    102\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_evals\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_evals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    103\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmain_effects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmain_effects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    104\u001B[39m \u001B[43m        \u001B[49m\u001B[43merror_bounds\u001B[49m\u001B[43m=\u001B[49m\u001B[43merror_bounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    105\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    106\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    107\u001B[39m \u001B[43m        \u001B[49m\u001B[43msilent\u001B[49m\u001B[43m=\u001B[49m\u001B[43msilent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    108\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\shap\\explainers\\_explainer.py:366\u001B[39m, in \u001B[36mExplainer.__call__\u001B[39m\u001B[34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001B[39m\n\u001B[32m    364\u001B[39m     feature_names = [[] \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(args))]\n\u001B[32m    365\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m row_args \u001B[38;5;129;01min\u001B[39;00m show_progress(\u001B[38;5;28mzip\u001B[39m(*args), num_rows, \u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m + \u001B[33m\"\u001B[39m\u001B[33m explainer\u001B[39m\u001B[33m\"\u001B[39m, silent):\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m     row_result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mexplain_row\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43mrow_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_evals\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_evals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    369\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmain_effects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmain_effects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    370\u001B[39m \u001B[43m        \u001B[49m\u001B[43merror_bounds\u001B[49m\u001B[43m=\u001B[49m\u001B[43merror_bounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    371\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    372\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    373\u001B[39m \u001B[43m        \u001B[49m\u001B[43msilent\u001B[49m\u001B[43m=\u001B[49m\u001B[43msilent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    374\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    375\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    376\u001B[39m     values.append(row_result.get(\u001B[33m\"\u001B[39m\u001B[33mvalues\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    377\u001B[39m     output_indices.append(row_result.get(\u001B[33m\"\u001B[39m\u001B[33moutput_indices\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\shap\\explainers\\_permutation.py:192\u001B[39m, in \u001B[36mPermutationExplainer.explain_row\u001B[39m\u001B[34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001B[39m\n\u001B[32m    189\u001B[39m     history_pos += \u001B[32m1\u001B[39m\n\u001B[32m    191\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m npermutations == \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m192\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    193\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mmax_evals=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmax_evals\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m is too low for the Permutation explainer, it must be at least 2 * num_features + 1 = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[32m2\u001B[39m\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(inds)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m!\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    194\u001B[39m     )\n\u001B[32m    196\u001B[39m expected_value = outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    198\u001B[39m \u001B[38;5;66;03m# compute the main effects if we need to\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: max_evals=500 is too low for the Permutation explainer, it must be at least 2 * num_features + 1 = 671!"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T06:15:09.526820Z",
     "start_time": "2025-04-22T06:15:01.824119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model('best_tabular_model.h5')\n",
    "\n",
    "# Load and preprocess your data\n",
    "def load_and_preprocess(data_path):\n",
    "    # Implement your data loading logic here\n",
    "    # Should return X_train, X_test, y_train, y_test, feature_names, scaler\n",
    "    pass\n",
    "\n",
    "data_path = \"c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\"\n",
    "X_train, X_test, y_train, y_test, feature_names, scaler = load_and_preprocess(data_path)\n",
    "\n",
    "# =====================\n",
    "# 1. Fixed LIME Explanation\n",
    "# =====================\n",
    "def lime_explanation(model, sample, feature_names, class_names=['Fake', 'Real']):\n",
    "    # Create wrapper function that outputs probabilities for both classes\n",
    "    def predict_proba(x):\n",
    "        preds = model.predict(x, verbose=0)\n",
    "        # Convert single probability to two-class probabilities\n",
    "        return np.hstack([1-preds, preds])\n",
    "\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        mode='classification'\n",
    "    )\n",
    "\n",
    "    exp = explainer.explain_instance(\n",
    "        sample,\n",
    "        predict_proba,  # Use our wrapper function\n",
    "        num_features=10\n",
    "    )\n",
    "\n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    exp.as_pyplot_figure()\n",
    "    plt.title(\"LIME Explanation\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return exp\n",
    "\n",
    "# =====================\n",
    "# 2. SHAP Explanation\n",
    "# =====================\n",
    "def shap_explanation(model, sample, background_samples=100):\n",
    "    # Create SHAP explainer\n",
    "    explainer = shap.Explainer(\n",
    "        model,\n",
    "        X_train[:background_samples]  # Use subset for background\n",
    "    )\n",
    "\n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer(sample.reshape(1, -1))\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    shap.plots.bar(shap_values[0], max_display=10)\n",
    "    plt.title(\"SHAP Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return shap_values\n",
    "\n",
    "# =====================\n",
    "# 3. Grad-CAM Style Explanation\n",
    "# =====================\n",
    "def grad_cam_explanation(model, sample, feature_names):\n",
    "    sample_tensor = tf.convert_to_tensor(sample.reshape(1, -1), dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sample_tensor)\n",
    "        pred = model(sample_tensor)\n",
    "\n",
    "    # Get gradients of output w.r.t input\n",
    "    grads = tape.gradient(pred, sample_tensor).numpy()[0]\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(feature_names, grads)\n",
    "    plt.xlabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Grad-CAM Style Input Gradient Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return grads\n",
    "\n",
    "# =====================\n",
    "# Main Execution\n",
    "# =====================\n",
    "if __name__ == \"__main__\":\n",
    "    # Select random samples to explain\n",
    "    sample_indices = np.random.choice(len(X_test), 3, replace=False)\n",
    "\n",
    "    for idx in sample_indices:\n",
    "        sample = X_test[idx]\n",
    "        true_label = y_test[idx]\n",
    "        pred = model.predict(sample.reshape(1, -1))[0][0]\n",
    "        pred_class = 'Real' if pred > 0.5 else 'Fake'\n",
    "\n",
    "        print(f\"\\nSample {idx}:\")\n",
    "        print(f\"True: {'Real' if true_label == 1 else 'Fake'}\")\n",
    "        print(f\"Predicted: {pred_class} ({pred:.4f})\")\n",
    "\n",
    "        # Generate explanations\n",
    "        print(\"\\nLIME Explanation:\")\n",
    "        lime_exp = lime_explanation(model, sample, feature_names)\n",
    "\n",
    "        print(\"\\nSHAP Explanation:\")\n",
    "        shap_vals = shap_explanation(model, sample)\n",
    "\n",
    "        print(\"\\nGrad-CAM Style Explanation:\")\n",
    "        gradients = grad_cam_explanation(model, sample, feature_names)\n",
    "\n",
    "        # Print top features from each method\n",
    "        print(\"\\nTop Contributing Features:\")\n",
    "        lime_features = sorted(lime_exp.as_list(), key=lambda x: abs(x[1]), reverse=True)[:5]\n",
    "\n",
    "        # Handle SHAP values differently since we're using the new API\n",
    "        print(\"\\nLIME Top Features:\")\n",
    "        for feat, weight in lime_features:\n",
    "            print(f\"{feat}: {weight:.4f}\")\n",
    "\n",
    "        print(\"\\nSHAP Top Features:\")\n",
    "        for feat, val in zip(feature_names, shap_vals.values[0,:,1]):\n",
    "            print(f\"{feat}: {val:.4f}\")\n",
    "\n",
    "        print(\"\\nGradient Top Features:\")\n",
    "        for feat, grad in zip(feature_names, gradients):\n",
    "            print(f\"{feat}: {grad:.4f}\")"
   ],
   "id": "12f15787bb4be1ac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 584ms/step\n",
      "\n",
      "Sample 302:\n",
      "True: Real\n",
      "Predicted: Real (1.0000)\n",
      "\n",
      "LIME Explanation:\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 116\u001B[39m\n\u001B[32m    114\u001B[39m \u001B[38;5;66;03m# Generate explanations\u001B[39;00m\n\u001B[32m    115\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mLIME Explanation:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m lime_exp = \u001B[43mlime_explanation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mSHAP Explanation:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    119\u001B[39m shap_vals = shap_explanation(model, sample)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 32\u001B[39m, in \u001B[36mlime_explanation\u001B[39m\u001B[34m(model, sample, feature_names, class_names)\u001B[39m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mlime_explanation\u001B[39m(model, sample, feature_names, class_names=[\u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m]):\n\u001B[32m     25\u001B[39m     explainer = lime_tabular.LimeTabularExplainer(\n\u001B[32m     26\u001B[39m         X_train,\n\u001B[32m     27\u001B[39m         feature_names=feature_names,\n\u001B[32m     28\u001B[39m         class_names=class_names,\n\u001B[32m     29\u001B[39m         mode=\u001B[33m'\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     30\u001B[39m     )\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m     exp = \u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     33\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\n\u001B[32m     36\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m     \u001B[38;5;66;03m# Visualization\u001B[39;00m\n\u001B[32m     39\u001B[39m     fig = plt.figure(figsize=(\u001B[32m10\u001B[39m, \u001B[32m5\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:452\u001B[39m, in \u001B[36mLimeTabularExplainer.explain_instance\u001B[39m\u001B[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001B[39m\n\u001B[32m    448\u001B[39m     labels = [\u001B[32m0\u001B[39m]\n\u001B[32m    449\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels:\n\u001B[32m    450\u001B[39m     (ret_exp.intercept[label],\n\u001B[32m    451\u001B[39m      ret_exp.local_exp[label],\n\u001B[32m--> \u001B[39m\u001B[32m452\u001B[39m      ret_exp.score, ret_exp.local_pred) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbase\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexplain_instance_with_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[43m            \u001B[49m\u001B[43mscaled_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    454\u001B[39m \u001B[43m            \u001B[49m\u001B[43myss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    455\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_regressor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    462\u001B[39m     ret_exp.intercept[\u001B[32m1\u001B[39m] = ret_exp.intercept[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\lime\\lime_base.py:182\u001B[39m, in \u001B[36mLimeBase.explain_instance_with_data\u001B[39m\u001B[34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001B[39;00m\n\u001B[32m    146\u001B[39m \n\u001B[32m    147\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \u001B[33;03m    local_pred is the prediction of the explanation model on the original instance\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    181\u001B[39m weights = \u001B[38;5;28mself\u001B[39m.kernel_fn(distances)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m labels_column = \u001B[43mneighborhood_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    183\u001B[39m used_features = \u001B[38;5;28mself\u001B[39m.feature_selection(neighborhood_data,\n\u001B[32m    184\u001B[39m                                        labels_column,\n\u001B[32m    185\u001B[39m                                        weights,\n\u001B[32m    186\u001B[39m                                        num_features,\n\u001B[32m    187\u001B[39m                                        feature_selection)\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_regressor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mIndexError\u001B[39m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d8b1c3fe5fd063"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T05:46:04.253927Z",
     "start_time": "2025-04-22T05:46:03.560774Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a5bfb9d5e689c997",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 143\u001B[39m\n\u001B[32m    141\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    142\u001B[39m     data_path = \u001B[33m\"\u001B[39m\u001B[33mc:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m143\u001B[39m     X, y, feature_names, scaler = \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    144\u001B[39m     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001B[32m0.2\u001B[39m, random_state=\u001B[32m42\u001B[39m)\n\u001B[32m    146\u001B[39m     model = create_tabular_model(X_train.shape[\u001B[32m1\u001B[39m])\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 63\u001B[39m, in \u001B[36mload_dataset\u001B[39m\u001B[34m(data_path)\u001B[39m\n\u001B[32m     61\u001B[39m X, y = [], []\n\u001B[32m     62\u001B[39m dummy_path = os.path.join(data_path, \u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mreal_1.wav\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m feature_names = [\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfeature_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdummy_path\u001B[49m\u001B[43m)\u001B[49m))]\n\u001B[32m     65\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m]:\n\u001B[32m     66\u001B[39m     class_path = os.path.join(data_path, label)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 54\u001B[39m, in \u001B[36mextract_features\u001B[39m\u001B[34m(file_path, n_mfcc, n_mels)\u001B[39m\n\u001B[32m     51\u001B[39m tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n\u001B[32m     52\u001B[39m features.append(tempo)  \u001B[38;5;66;03m# Using append for scalar value\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m54\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mValueError\u001B[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15,) + inhomogeneous part."
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T05:24:57.153592Z",
     "start_time": "2025-04-22T05:24:48.428015Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install shap",
   "id": "733b63b4367cfa84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Using cached shap-0.47.2-cp311-cp311-win_amd64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from shap) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from shap) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from shap) (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from shap) (24.2)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Using cached slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from shap) (0.61.2)\n",
      "Collecting cloudpickle (from shap)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from shap) (4.13.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from numba>=0.54->shap) (0.44.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from scikit-learn->shap) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\x-ai for music classification\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Using cached shap-0.47.2-cp311-cp311-win_amd64.whl (544 kB)\n",
      "Using cached slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: slicer, cloudpickle, shap\n",
      "Successfully installed cloudpickle-3.1.1 shap-0.47.2 slicer-0.0.8\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T05:28:19.384691Z",
     "start_time": "2025-04-22T05:28:18.796894Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "821b1f5b690f124c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_25496\\488601609.py:17: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=22050)\n",
      "C:\\Users\\adity\\X-AI for music classification\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/Real/example.wav'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mLibsndfileError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(path, sr, mono, offset, duration, dtype, res_type)\u001B[39m\n\u001B[32m    175\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m     y, sr_native = \u001B[43m__soundfile_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mduration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m sf.SoundFileRuntimeError \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    179\u001B[39m     \u001B[38;5;66;03m# If soundfile failed, try audioread instead\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001B[39m, in \u001B[36m__soundfile_load\u001B[39m\u001B[34m(path, offset, duration, dtype)\u001B[39m\n\u001B[32m    207\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    208\u001B[39m     \u001B[38;5;66;03m# Otherwise, create the soundfile object\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m209\u001B[39m     context = \u001B[43msf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSoundFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    211\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context \u001B[38;5;28;01mas\u001B[39;00m sf_desc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\soundfile.py:690\u001B[39m, in \u001B[36mSoundFile.__init__\u001B[39m\u001B[34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001B[39m\n\u001B[32m    688\u001B[39m \u001B[38;5;28mself\u001B[39m._info = _create_info_struct(file, mode, samplerate, channels,\n\u001B[32m    689\u001B[39m                                  \u001B[38;5;28mformat\u001B[39m, subtype, endian)\n\u001B[32m--> \u001B[39m\u001B[32m690\u001B[39m \u001B[38;5;28mself\u001B[39m._file = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_int\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosefd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    691\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mset\u001B[39m(mode).issuperset(\u001B[33m'\u001B[39m\u001B[33mr+\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.seekable():\n\u001B[32m    692\u001B[39m     \u001B[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\soundfile.py:1265\u001B[39m, in \u001B[36mSoundFile._open\u001B[39m\u001B[34m(self, file, mode_int, closefd)\u001B[39m\n\u001B[32m   1264\u001B[39m     err = _snd.sf_error(file_ptr)\n\u001B[32m-> \u001B[39m\u001B[32m1265\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m LibsndfileError(err, prefix=\u001B[33m\"\u001B[39m\u001B[33mError opening \u001B[39m\u001B[38;5;132;01m{0!r}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[33m\"\u001B[39m.format(\u001B[38;5;28mself\u001B[39m.name))\n\u001B[32m   1266\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m mode_int == _snd.SFM_WRITE:\n\u001B[32m   1267\u001B[39m     \u001B[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001B[39;00m\n\u001B[32m   1268\u001B[39m     \u001B[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001B[39;00m\n\u001B[32m   1269\u001B[39m     \u001B[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001B[39;00m\n",
      "\u001B[31mLibsndfileError\u001B[39m: Error opening 'c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/Real/example.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 176\u001B[39m\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    174\u001B[39m     \u001B[38;5;66;03m# Load and prepare data\u001B[39;00m\n\u001B[32m    175\u001B[39m     data_path = \u001B[33m\"\u001B[39m\u001B[33mc:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m     X, y, feature_names, scaler = \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    177\u001B[39m     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001B[32m0.2\u001B[39m, random_state=\u001B[32m42\u001B[39m)\n\u001B[32m    179\u001B[39m     \u001B[38;5;66;03m# Create and train model\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 82\u001B[39m, in \u001B[36mload_dataset\u001B[39m\u001B[34m(data_path)\u001B[39m\n\u001B[32m     79\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dummy_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     80\u001B[39m     dummy_path = os.path.join(data_path, \u001B[33m'\u001B[39m\u001B[33mFake/example.wav\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m82\u001B[39m dummy_features = \u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdummy_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     83\u001B[39m feature_names = [\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfeature_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(dummy_features))]\n\u001B[32m     85\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m'\u001B[39m\u001B[33mReal\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mFake\u001B[39m\u001B[33m'\u001B[39m]:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 17\u001B[39m, in \u001B[36mextract_features\u001B[39m\u001B[34m(file_path, n_mfcc, n_mels)\u001B[39m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mextract_features\u001B[39m(file_path, n_mfcc=\u001B[32m20\u001B[39m, n_mels=\u001B[32m128\u001B[39m):\n\u001B[32m     16\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Extract multiple audio features and combine into single feature vector\"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     y, sr = \u001B[43mlibrosa\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msr\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m22050\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m     features = []\n\u001B[32m     21\u001B[39m     \u001B[38;5;66;03m# MFCCs\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:184\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(path, sr, mono, offset, duration, dtype, res_type)\u001B[39m\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, (\u001B[38;5;28mstr\u001B[39m, pathlib.PurePath)):\n\u001B[32m    181\u001B[39m     warnings.warn(\n\u001B[32m    182\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mPySoundFile failed. Trying audioread instead.\u001B[39m\u001B[33m\"\u001B[39m, stacklevel=\u001B[32m2\u001B[39m\n\u001B[32m    183\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m184\u001B[39m     y, sr_native = \u001B[43m__audioread_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mduration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    185\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    186\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\decorator.py:235\u001B[39m, in \u001B[36mdecorate.<locals>.fun\u001B[39m\u001B[34m(*args, **kw)\u001B[39m\n\u001B[32m    233\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[32m    234\u001B[39m     args, kw = fix(args, kw, sig)\n\u001B[32m--> \u001B[39m\u001B[32m235\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcaller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m(\u001B[49m\u001B[43mextras\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\librosa\\util\\decorators.py:63\u001B[39m, in \u001B[36mdeprecated.<locals>.__wrapper\u001B[39m\u001B[34m(func, *args, **kwargs)\u001B[39m\n\u001B[32m     54\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001B[39;00m\n\u001B[32m     55\u001B[39m warnings.warn(\n\u001B[32m     56\u001B[39m     \u001B[33m\"\u001B[39m\u001B[38;5;132;01m{:s}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{:s}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[33mDeprecated as of librosa version \u001B[39m\u001B[38;5;132;01m{:s}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     57\u001B[39m     \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[33mIt will be removed in librosa version \u001B[39m\u001B[38;5;132;01m{:s}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m.format(\n\u001B[32m   (...)\u001B[39m\u001B[32m     61\u001B[39m     stacklevel=\u001B[32m3\u001B[39m,  \u001B[38;5;66;03m# Would be 2, but the decorator adds a level\u001B[39;00m\n\u001B[32m     62\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:240\u001B[39m, in \u001B[36m__audioread_load\u001B[39m\u001B[34m(path, offset, duration, dtype)\u001B[39m\n\u001B[32m    237\u001B[39m     reader = path\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    239\u001B[39m     \u001B[38;5;66;03m# If the input was not an audioread object, try to open it\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m     reader = \u001B[43maudioread\u001B[49m\u001B[43m.\u001B[49m\u001B[43maudio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m reader \u001B[38;5;28;01mas\u001B[39;00m input_file:\n\u001B[32m    243\u001B[39m     sr_native = input_file.samplerate\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\audioread\\__init__.py:127\u001B[39m, in \u001B[36maudio_open\u001B[39m\u001B[34m(path, backends)\u001B[39m\n\u001B[32m    125\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m BackendClass \u001B[38;5;129;01min\u001B[39;00m backends:\n\u001B[32m    126\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBackendClass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    128\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m DecodeError:\n\u001B[32m    129\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\X-AI for music classification\\.venv\\Lib\\site-packages\\audioread\\rawread.py:59\u001B[39m, in \u001B[36mRawAudioFile.__init__\u001B[39m\u001B[34m(self, filename)\u001B[39m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename):\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     \u001B[38;5;28mself\u001B[39m._fh = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     61\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     62\u001B[39m         \u001B[38;5;28mself\u001B[39m._file = aifc.open(\u001B[38;5;28mself\u001B[39m._fh)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'c:/Users/adity/Downloads/X_AI_for_fake_real_audio_detection/Data/Real/example.wav'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d384eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.11.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.3/1.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.13.1\n",
      "    Uninstalling keras-2.13.1:\n",
      "      Successfully uninstalled keras-2.13.1\n",
      "Successfully installed keras-2.11.0\n",
      "Requirement already satisfied: keras==2.11.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (2.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.11.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457e6edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.11.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0)\n",
      "ERROR: No matching distribution found for tensorflow==2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.11.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60420be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462ad71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.13.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0)\n",
      "ERROR: No matching distribution found for tensorflow==2.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall keras tensorflow\n",
    "!pip install tensorflow==2.13.0 keras==2.13.1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
